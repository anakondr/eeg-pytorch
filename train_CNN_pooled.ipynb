{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "#%matplotlib qt \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install moabb[full]\n",
    "# !pip install braindecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nu_smrutils import loaddat\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import mne\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: torch in c:\\users\\anna\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\anna\\anaconda3\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\anna\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\anna\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\anna\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\anna\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\anna\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\anna\\anaconda3\\lib\\site-packages (from torchvision) (1.25.1)\n",
      "Requirement already satisfied: requests in c:\\users\\anna\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\anna\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\anna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\anna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\anna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\anna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\anna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anna\\anaconda3\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "# !pip install moabb[full]\n",
    "# !pip install braindecode\n",
    "# !pip install matplotlib==3.7.1\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # itemname is one of : ['BNCI2014004', 'BNCI2014001', 'Weibo2014', 'Physionet']\n",
    "# itemname = 'BNCI2014004'\n",
    "# filename = dname[itemname]\n",
    "# iname = itemname + '__'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 22, 1001)\n",
      "(288,)\n"
     ]
    }
   ],
   "source": [
    "from moabb.datasets import (\n",
    "    BNCI2014001, \n",
    "    BNCI2014004, \n",
    "    PhysionetMI, \n",
    "    Weibo2014\n",
    ")\n",
    "from moabb.paradigms import LeftRightImagery\n",
    "\n",
    "# Preprocesses datasets and saves the results locally.\n",
    "# If local copyis available, returns\n",
    "class EEGDatasets:\n",
    "    # \n",
    "    def __init__(self, local_dir=None):\n",
    "        self.local_dir = local_dir or os.path.join(os.getcwd(), 'eeg-data')\n",
    "    \n",
    "    def moabb_dataset(self, name, subjects):\n",
    "        if  name == 'BNCI2014001':\n",
    "            raw_dataset = BNCI2014001()\n",
    "            paradigm = LeftRightImagery()\n",
    "            X, labels, meta = paradigm.get_data(dataset=raw_dataset, subjects=subjects)\n",
    "            return X, labels\n",
    "        elif  name == 'BNCI2014004':\n",
    "            raw_dataset = BNCI2014004()\n",
    "            paradigm = LeftRightImagery()\n",
    "            X, labels, meta = paradigm.get_data(dataset=raw_dataset, subjects=subjects)\n",
    "            return X, labels\n",
    "        else:\n",
    "            raise ValueError(f'unknown dataset name {name}')\n",
    "                    \n",
    "datasets = EEGDatasets()        \n",
    "itemname = 'BNCI2014001'\n",
    "iname = itemname + '__'   \n",
    "data, labels = datasets.moabb_dataset(itemname, [1])\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pooled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nu_smrutils import load_pooled, augment_dataset, crop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pooled1(data, labels, test_size=0.15):\n",
    "    \"\"\"\n",
    "    Creates pooled data from all subject specific EEG dataset.          \n",
    "\n",
    "    Parameters:\n",
    "    -------------------------\n",
    "    Input: a python list containing MNE EEG data objects. \n",
    "\n",
    "    For instance, a list with the following elements:    \n",
    "    [<Epochs  |   720 events, 'left_hand': 360  'right_hand': 360>,\n",
    "     <Epochs   |  680 events, 'left_hand': 340, 'right_hand': 340>]\n",
    "\n",
    "    Returns:\n",
    "    -------------------------\n",
    "    A dictionary :\n",
    "        X_train, X_valid, X_test: \n",
    "        np.array of shape >>>  (samples, channel, times), \n",
    "\n",
    "        Data labels: \n",
    "        y_train, y_valid, y_test\n",
    "    -------------------------\n",
    "    output = dict(xtrain = X_train, xvalid = X_valid, xtest = X_test,\n",
    "                  ytrain = y_train, yvalid = y_valid, ytest = y_test)\n",
    "    -------------------------    \n",
    "    \"\"\"\n",
    "\n",
    "    X = data\n",
    "    Y = (labels == 'right_hand').astype(int)\n",
    "\n",
    "    # split the data using sklearn split function\n",
    "    x_rest, x_test, y_rest, y_test =\\\n",
    "        train_test_split(X, Y, test_size=test_size, random_state=42,\n",
    "                         stratify=Y)\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid =\\\n",
    "        train_test_split(x_rest, y_rest, test_size=0.2, random_state=42,\n",
    "                         stratify=y_rest)\n",
    "\n",
    "    # Convert to Pytorch tensors\n",
    "    X_train, X_valid, X_test = map(torch.FloatTensor,(x_train, x_valid, x_test))\n",
    "    y_train, y_valid, y_test = map(torch.FloatTensor,(y_train, y_valid, y_test))\n",
    "\n",
    "    return dict(xtrain=X_train, xvalid=X_valid, xtest=X_test,\n",
    "                ytrain=y_train, yvalid=y_valid, ytest=y_test)\n",
    "\n",
    "dat = load_pooled1(data, labels, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['xtrain', 'xvalid', 'xtest', 'ytrain', 'yvalid', 'ytest'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([195, 22, 1001])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dat.keys())\n",
    "dat['xtrain'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "augdata = dict(std_dev = 0.01, multiple = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after data augmentation : torch.Size([390, 22, 1001])\n"
     ]
    }
   ],
   "source": [
    "xtrain, ytrain = augment_dataset(dat['xtrain'], dat['ytrain'], \n",
    "                                 augdata['std_dev'], augdata['multiple'])\n",
    "\n",
    "print(\"Shape after data augmentation :\", xtrain.shape)\n",
    "dat['xtrain'], dat['ytrain'] = xtrain, ytrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 80 # sampling frequency \n",
    "crop_len = 1.5 #or None\n",
    "crop = dict(fs = fs, crop_len = crop_len)\n",
    "\n",
    "#if crop['crop_len']:\n",
    "X_train,y_train = crop_data(crop['fs'],crop['crop_len'], \n",
    "                            dat['xtrain'], dat['ytrain'], \n",
    "                            xpercent = 50)\n",
    "\n",
    "X_valid,y_valid = crop_data(crop['fs'],crop['crop_len'], \n",
    "                            dat['xvalid'], dat['yvalid'], \n",
    "                            xpercent = 50)\n",
    "\n",
    "X_test, y_test  = crop_data(crop['fs'],crop['crop_len'], \n",
    "                            dat['xtest'], dat['ytest'], \n",
    "                            xpercent = 50)\n",
    "\n",
    "dat = dict(xtrain = X_train, xvalid = X_valid, xtest = X_test,\n",
    "           ytrain = y_train, yvalid = y_valid, ytest = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape after cropping : torch.Size([2730, 22, 180])\n"
     ]
    }
   ],
   "source": [
    "print('data shape after cropping :',dat['xtrain'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import TensorDataset, DataLoader  \n",
    "\n",
    "def get_data_loaders(dat, batch_size, EEGNET = None):    \n",
    "    # convert data dimensions to into to gray scale image format\n",
    "    if EEGNET: ### EEGNet model requires the last dimension to be 1 \n",
    "        ff = lambda dat: torch.unsqueeze(dat, dim = -1)    \n",
    "    else:\n",
    "        ff = lambda dat: torch.unsqueeze(dat, dim = 1)    \n",
    "    \n",
    "    x_train, x_valid, x_test = map(ff,(dat['xtrain'], dat['xvalid'],dat['xtest']))    \n",
    "    y_train, y_valid, y_test = dat['ytrain'], dat['yvalid'], dat['ytest']\n",
    "    print('Input data shape', x_train.shape)       \n",
    "    \n",
    "    # TensorDataset & Dataloader    \n",
    "    train_dat    = TensorDataset(x_train, y_train) \n",
    "    val_dat      = TensorDataset(x_valid, y_valid) \n",
    "    \n",
    "    train_loader = DataLoader(train_dat, batch_size = batch_size, shuffle = True, generator=torch.Generator(device='cuda'))\n",
    "    val_loader   = DataLoader(val_dat,   batch_size = batch_size, shuffle = False, generator=torch.Generator(device='cuda'))\n",
    "\n",
    "    output = dict(dset_loaders = {'train': train_loader, 'val': val_loader}, \n",
    "                  dset_sizes  =  {'train': len(x_train), 'val': len(x_valid)},\n",
    "                  test_data   =  {'x_test' : x_test, 'y_test' : y_test})          \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape torch.Size([2730, 1, 22, 180])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['dset_loaders', 'dset_sizes', 'test_data'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = get_data_loaders(dat, batch_size = 64)\n",
    "dat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check begin \n",
    "dset_loaders = dat['dset_loaders']\n",
    "dset_sizes = dat['dset_sizes']\n",
    "dset_sizes\n",
    "\n",
    "dtrain = dset_loaders['train']\n",
    "dval   = dset_loaders['val']\n",
    "\n",
    "dtr = iter(dtrain)\n",
    "dv  = iter(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 22, 180]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = next(dtr)\n",
    "print(inputs.shape, labels.shape)\n",
    "# Sanity check end "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class CNN2D(torch.nn.Module):  \n",
    "    def __init__(self, input_size, kernel_size, conv_channels, \n",
    "                 dense_size, dropout):         \n",
    "        super(CNN2D, self).__init__()                  \n",
    "        self.cconv   = []  \n",
    "        self.MaxPool = nn.MaxPool2d((1, 2), (1, 2))  \n",
    "        self.ReLU    = nn.ReLU()\n",
    "        self.Dropout = nn.Dropout(dropout)        \n",
    "        self.batchnorm = []                \n",
    "        # ############ batchnorm ###########\n",
    "        for jj in conv_channels:\n",
    "            self.batchnorm.append(nn.BatchNorm2d(jj, eps=0.001, momentum=0.01,\n",
    "                                                 affine=True, track_running_stats=True).cuda())     \n",
    "        ii = 0 ##### define CONV layer architecture: #####\n",
    "        for in_channels, out_channels in zip(conv_channels, conv_channels[1:]):                           \n",
    "            conv_i = torch.nn.Conv2d(in_channels = in_channels, out_channels = out_channels,\n",
    "                                     kernel_size = kernel_size[ii], #stride = (1, 2),\n",
    "                                     padding     = (kernel_size[ii][0]//2, kernel_size[ii][1]//2))            \n",
    "            self.cconv.append(conv_i)                \n",
    "            self.add_module('CNN_K{}_O{}'.format(kernel_size[ii], out_channels), conv_i)\n",
    "            ii += 1                            \n",
    "        self.flat_dim = self.get_output_dim(input_size, self.cconv)    \n",
    "        self.fc1 = torch.nn.Linear(self.flat_dim, dense_size)\n",
    "        self.fc2 = torch.nn.Linear(dense_size, 2)                \n",
    "\n",
    "    def get_output_dim(self, input_size, cconv):        \n",
    "        with torch.no_grad():\n",
    "            input = torch.ones(1,*input_size)              \n",
    "            for conv_i in cconv:                \n",
    "                input = self.MaxPool(conv_i(input))        \n",
    "                flatout = int(np.prod(input.size()[1:]))\n",
    "                print(\"Input shape : {} and flattened : {}\".format(input.shape, flatout))\n",
    "        return flatout \n",
    "        \n",
    "    def forward(self, input):        \n",
    "        for jj, conv_i in enumerate(self.cconv):\n",
    "            input = conv_i(input)\n",
    "            input = self.batchnorm[jj+1](input)\n",
    "            input = self.ReLU(input)        \n",
    "            input = self.MaxPool(input)                   \n",
    "        # flatten the CNN output     \n",
    "        out = input.view(-1, self.flat_dim) \n",
    "        out = self.fc1(out)                       \n",
    "        out = self.Dropout(out)        \n",
    "        out = self.fc2(out)      \n",
    "        return out        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your GPU device name : NVIDIA GeForce RTX 2080\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "torch.manual_seed(0)\n",
    "\n",
    "from nu_smrutils import train_model  \n",
    "\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if dev.type == 'cuda':\n",
    "   print('Your GPU device name :', torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 22, 180)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 150 \n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-4  \n",
    "batch_size = 64\n",
    "verbose = 1\n",
    "\n",
    "#% used to save the results table \n",
    "results = {}        \n",
    "table = pd.DataFrame(columns = ['Train_Acc', 'Val_Acc', 'Test_Acc', 'Epoch'])   \n",
    "\n",
    "#% get input size (channel x timepoints)\n",
    "input_size = (1, dat['test_data']['x_test'].shape[-2], \n",
    "                 dat['test_data']['x_test'].shape[-1])\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relate the **kernel width** hyperparameter to a temporal window in milliseconds    \n",
    "\n",
    "- If we want to convolve 100 ms >>> set time_window = 100 #ms\n",
    "- width = (time_window_of_interest * sampling_frequency)/one_second "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define kernel size in terms of ms length \n",
    "fs = 80 #Hz\n",
    "time_window = 100 #ms\n",
    "width = time_window*fs//1000  \n",
    "\n",
    "# width = 8 #timelength//chans         \n",
    "# convolution parameters \n",
    "h1, w1 = 3, 1\n",
    "h2, w2 = 3, 3\n",
    "h3, w3 = 3, 5       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one should run this script twice with ConvDown = True or False \n",
    "# to have different convolutional layer patterns  \n",
    "ConvDOWN = True  \n",
    "\n",
    "if ConvDOWN:            \n",
    "    params = {'conv_channels': [\n",
    "                                [1, 16, 8],                                               \n",
    "                                [1, 32, 16, 8],\n",
    "                                [1, 64, 32, 16, 8],\n",
    "                                [1, 128, 64, 32, 16, 8],\n",
    "                                [1, 256, 128, 64, 32, 16, 8]                                     \n",
    "                                ],                         \n",
    "\n",
    "              'kernel_size':    [[(h1, w1*width), (h1, w1*width), (h1, w1*width),\n",
    "                                  (h1, w1*width),(h1, w1*width),(h1, w1*width)],\n",
    "                                 \n",
    "                                 [(h2, w2*width), (h2, w2*width), (h2, w2*width),\n",
    "                                  (h2, w2*width),(h2, w2*width),(h2, w2*width)],\n",
    "                                 \n",
    "                                 [(h3, w3*width), (h3, w3*width), (h3, w3*width),\n",
    "                                  (h3, w3*width),(h3, w3*width),(h3, w3*width)]]                                                                      \n",
    "              }                      \n",
    "else:                      \n",
    "    params = {'conv_channels': [\n",
    "                                [1, 8, 16],                                                  \n",
    "                                [1, 8, 16, 32],\n",
    "                                [1, 8, 16, 32, 64],\n",
    "                                [1, 8, 16, 32, 64, 128],\n",
    "                                [1, 8, 16, 32, 64, 128, 256]\n",
    "                                ],      \t\t\n",
    "\n",
    "              'kernel_size':    [[(h1, w1*width), (h1, w1*width), (h1, w1*width),\n",
    "                                  (h1, w1*width),(h1, w1*width),(h1, w1*width)],\n",
    "                                 \n",
    "                                 [(h2, w2*width), (h2, w2*width), (h2, w2*width),\n",
    "                                  (h2, w2*width),(h2, w2*width),(h2, w2*width)],\n",
    "                                 \n",
    "                                 [(h3, w3*width), (h3, w3*width), (h3, w3*width),\n",
    "                                  (h3, w3*width),(h3, w3*width),(h3, w3*width)]]                     \n",
    "              }    \n",
    "keys = list(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## Training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##### C[1, 16, 8]_K(3, 8) #####\n",
      "Input shape : torch.Size([1, 16, 22, 90]) and flattened : 31680\n",
      "Input shape : torch.Size([1, 8, 22, 45]) and flattened : 7920\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 8)_O16): Conv2d(1, 16, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O8): Conv2d(16, 8, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (fc1): Linear(in_features=7920, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n",
      "train loss: 0.0209, acc: 0.5626\n",
      "val loss: 0.0133, acc: 0.5656\n",
      "Epoch 2/150\n",
      "train loss: 0.0104, acc: 0.6875\n",
      "val loss: 0.0206, acc: 0.5423\n",
      "Epoch 3/150\n",
      "train loss: 0.0082, acc: 0.7454\n",
      "val loss: 0.0173, acc: 0.5510\n",
      "Epoch 4/150\n",
      "train loss: 0.0070, acc: 0.7846\n",
      "val loss: 0.0152, acc: 0.6093\n",
      "Epoch 5/150\n",
      "train loss: 0.0055, acc: 0.8399\n",
      "val loss: 0.0154, acc: 0.6356\n",
      "Epoch 6/150\n",
      "train loss: 0.0044, acc: 0.8868\n",
      "val loss: 0.0169, acc: 0.6297\n",
      "Epoch 7/150\n",
      "train loss: 0.0045, acc: 0.8839\n",
      "val loss: 0.0168, acc: 0.6181\n",
      "Epoch 8/150\n",
      "train loss: 0.0031, acc: 0.9194\n",
      "val loss: 0.0213, acc: 0.6327\n",
      "Epoch 9/150\n",
      "train loss: 0.0021, acc: 0.9505\n",
      "val loss: 0.0220, acc: 0.6181\n",
      "Epoch 10/150\n",
      "train loss: 0.0038, acc: 0.8971\n",
      "val loss: 0.0319, acc: 0.5889\n",
      "Epoch 11/150\n",
      "train loss: 0.0047, acc: 0.8857\n",
      "val loss: 0.0211, acc: 0.6297\n",
      "Epoch 12/150\n",
      "train loss: 0.0012, acc: 0.9766\n",
      "val loss: 0.0221, acc: 0.6327\n",
      "Epoch 13/150\n",
      "train loss: 0.0005, acc: 0.9963\n",
      "val loss: 0.0239, acc: 0.6385\n",
      "Epoch 14/150\n",
      "train loss: 0.0002, acc: 1.0000\n",
      "val loss: 0.0252, acc: 0.6472\n",
      "Epoch 15/150\n",
      "train loss: 0.0002, acc: 0.9993\n",
      "val loss: 0.0262, acc: 0.6443\n",
      "Epoch 16/150\n",
      "train loss: 0.0001, acc: 1.0000\n",
      "val loss: 0.0274, acc: 0.6297\n",
      "Epoch 17/150\n",
      "train loss: 0.0001, acc: 1.0000\n",
      "val loss: 0.0276, acc: 0.6443\n",
      "Epoch 18/150\n",
      "train loss: 0.0001, acc: 1.0000\n",
      "val loss: 0.0282, acc: 0.6414\n",
      "Epoch 19/150\n",
      "train loss: 0.0001, acc: 1.0000\n",
      "val loss: 0.0282, acc: 0.6443\n",
      "Epoch 20/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0289, acc: 0.6385\n",
      "Epoch 21/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0296, acc: 0.6385\n",
      "Epoch 22/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0299, acc: 0.6501\n",
      "Epoch 23/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0303, acc: 0.6356\n",
      "Epoch 24/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0308, acc: 0.6356\n",
      "Epoch 25/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0308, acc: 0.6414\n",
      "Epoch 26/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0309, acc: 0.6414\n",
      "Epoch 27/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0314, acc: 0.6327\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0315, acc: 0.6327\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0318, acc: 0.6327\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0320, acc: 0.6356\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6414\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6385\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6385\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6356\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6356\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6385\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0329, acc: 0.6414\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0331, acc: 0.6385\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0330, acc: 0.6385\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0331, acc: 0.6356\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0332, acc: 0.6443\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0335, acc: 0.6385\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0333, acc: 0.6414\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0335, acc: 0.6414\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0334, acc: 0.6472\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0334, acc: 0.6531\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0335, acc: 0.6414\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0336, acc: 0.6443\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0338, acc: 0.6472\n",
      "Epoch 50/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0337, acc: 0.6414\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0336, acc: 0.6443\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0337, acc: 0.6501\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0338, acc: 0.6443\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0339, acc: 0.6385\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0338, acc: 0.6531\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0339, acc: 0.6385\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0337, acc: 0.6385\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0341, acc: 0.6560\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0341, acc: 0.6501\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0341, acc: 0.6501\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0341, acc: 0.6414\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0341, acc: 0.6385\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0338, acc: 0.6501\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0343, acc: 0.6501\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.6414\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0348, acc: 0.6356\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0357, acc: 0.6356\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0347, acc: 0.6472\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0344, acc: 0.6472\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0348, acc: 0.6531\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.6531\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.6472\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0344, acc: 0.6501\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0344, acc: 0.6589\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0345, acc: 0.6327\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0345, acc: 0.6443\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.6385\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0345, acc: 0.6560\n",
      "Epoch 79/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0347, acc: 0.6501\n",
      "Epoch 80/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0341, acc: 0.6472\n",
      "Epoch 81/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0342, acc: 0.6531\n",
      "Epoch 82/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0343, acc: 0.6589\n",
      "Epoch 83/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0343, acc: 0.6531\n",
      "Epoch 84/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0341, acc: 0.6414\n",
      "Epoch 85/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0343, acc: 0.6472\n",
      "Epoch 86/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0347, acc: 0.6589\n",
      "Epoch 87/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0343, acc: 0.6443\n",
      "Epoch 88/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0340, acc: 0.6385\n",
      "Epoch 89/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6414\n",
      "Epoch 90/150\n",
      "train loss: 0.0737, acc: 0.7886\n",
      "val loss: 0.0277, acc: 0.5627\n",
      "Epoch 91/150\n",
      "train loss: 0.0178, acc: 0.6407\n",
      "val loss: 0.0125, acc: 0.6093\n",
      "Epoch 92/150\n",
      "train loss: 0.0076, acc: 0.7612\n",
      "val loss: 0.0143, acc: 0.6210\n",
      "Epoch 93/150\n",
      "train loss: 0.0071, acc: 0.7850\n",
      "val loss: 0.0139, acc: 0.6327\n",
      "Epoch 94/150\n",
      "train loss: 0.0059, acc: 0.8194\n",
      "val loss: 0.0160, acc: 0.6356\n",
      "Epoch 95/150\n",
      "train loss: 0.0045, acc: 0.8707\n",
      "val loss: 0.0176, acc: 0.6239\n",
      "Epoch 96/150\n",
      "train loss: 0.0039, acc: 0.8989\n",
      "val loss: 0.0198, acc: 0.6443\n",
      "Epoch 97/150\n",
      "train loss: 0.0038, acc: 0.8989\n",
      "val loss: 0.0187, acc: 0.6472\n",
      "Epoch 98/150\n",
      "train loss: 0.0015, acc: 0.9707\n",
      "val loss: 0.0239, acc: 0.6356\n",
      "Epoch 99/150\n",
      "train loss: 0.0010, acc: 0.9828\n",
      "val loss: 0.0268, acc: 0.6327\n",
      "Epoch 100/150\n",
      "train loss: 0.0007, acc: 0.9905\n",
      "val loss: 0.0296, acc: 0.6531\n",
      "Epoch 101/150\n",
      "train loss: 0.0006, acc: 0.9912\n",
      "val loss: 0.0332, acc: 0.6268\n",
      "Epoch 102/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0003, acc: 0.9974\n",
      "val loss: 0.0332, acc: 0.6443\n",
      "Epoch 103/150\n",
      "train loss: 0.0002, acc: 0.9996\n",
      "val loss: 0.0355, acc: 0.6443\n",
      "Epoch 104/150\n",
      "train loss: 0.0001, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6560\n",
      "Epoch 105/150\n",
      "train loss: 0.0001, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6501\n",
      "Epoch 106/150\n",
      "train loss: 0.0001, acc: 1.0000\n",
      "val loss: 0.0384, acc: 0.6385\n",
      "Epoch 107/150\n",
      "train loss: 0.0001, acc: 1.0000\n",
      "val loss: 0.0377, acc: 0.6531\n",
      "Epoch 108/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6531\n",
      "Epoch 109/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0388, acc: 0.6501\n",
      "Epoch 110/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0392, acc: 0.6531\n",
      "Epoch 111/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0399, acc: 0.6531\n",
      "Epoch 112/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0400, acc: 0.6501\n",
      "Epoch 113/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6501\n",
      "Epoch 114/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0406, acc: 0.6385\n",
      "Epoch 115/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6443\n",
      "Epoch 116/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0410, acc: 0.6531\n",
      "Epoch 117/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0413, acc: 0.6531\n",
      "Epoch 118/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0412, acc: 0.6501\n",
      "Epoch 119/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0418, acc: 0.6531\n",
      "Epoch 120/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0418, acc: 0.6560\n",
      "Epoch 121/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0420, acc: 0.6589\n",
      "Epoch 122/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0420, acc: 0.6531\n",
      "Epoch 123/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0421, acc: 0.6472\n",
      "Epoch 124/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0421, acc: 0.6531\n",
      "Epoch 125/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0422, acc: 0.6531\n",
      "Epoch 126/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0418, acc: 0.6531\n",
      "Epoch 127/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6560\n",
      "Epoch 128/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0421, acc: 0.6472\n",
      "Epoch 129/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0419, acc: 0.6501\n",
      "Epoch 130/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0419, acc: 0.6501\n",
      "Epoch 131/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6618\n",
      "Epoch 132/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6472\n",
      "Epoch 133/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0430, acc: 0.6443\n",
      "Epoch 134/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0427, acc: 0.6501\n",
      "Epoch 135/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6472\n",
      "Epoch 136/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0427, acc: 0.6560\n",
      "Epoch 137/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6560\n",
      "Epoch 138/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6531\n",
      "Epoch 139/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6589\n",
      "Epoch 140/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6531\n",
      "Epoch 141/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6560\n",
      "Epoch 142/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0427, acc: 0.6501\n",
      "Epoch 143/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6531\n",
      "Epoch 144/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6531\n",
      "Epoch 145/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6472\n",
      "Epoch 146/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6443\n",
      "Epoch 147/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6472\n",
      "Epoch 148/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6501\n",
      "Epoch 149/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6385\n",
      "Epoch 150/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0421, acc: 0.6501\n",
      "Training complete in 0m 51s\n",
      "Best val Acc: 0.661808\n",
      "Best Epoch : 131\n",
      "Test Accuracy : 0.74\n",
      "                              Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)            1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)           0.952747  0.667638      0.69    107\n",
      "C[1, 16, 8]_K(3, 40)           0.906227  0.667638      0.71    136\n",
      "C[1, 32, 16, 8]_K(3, 8)        1.000000  0.690962      0.76     92\n",
      "C[1, 32, 16, 8]_K(3, 24)       0.762637  0.682216      0.74      8\n",
      "C[1, 32, 16, 8]_K(3, 40)       0.720513  0.679300      0.77      7\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)    0.899267  0.705539      0.76    134\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)   0.999634  0.685131      0.80    145\n",
      "\n",
      "\n",
      "##### C[1, 16, 8]_K(3, 24) #####\n",
      "Input shape : torch.Size([1, 16, 22, 90]) and flattened : 31680\n",
      "Input shape : torch.Size([1, 8, 22, 45]) and flattened : 7920\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 24)_O16): Conv2d(1, 16, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O8): Conv2d(16, 8, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (fc1): Linear(in_features=7920, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n",
      "train loss: 0.0495, acc: 0.5070\n",
      "val loss: 0.0138, acc: 0.5335\n",
      "Epoch 2/150\n",
      "train loss: 0.0118, acc: 0.5582\n",
      "val loss: 0.0126, acc: 0.5102\n",
      "Epoch 3/150\n",
      "train loss: 0.0103, acc: 0.6176\n",
      "val loss: 0.0120, acc: 0.5598\n",
      "Epoch 4/150\n",
      "train loss: 0.0091, acc: 0.6824\n",
      "val loss: 0.0126, acc: 0.5743\n",
      "Epoch 5/150\n",
      "train loss: 0.0083, acc: 0.7315\n",
      "val loss: 0.0117, acc: 0.6239\n",
      "Epoch 6/150\n",
      "train loss: 0.0077, acc: 0.7560\n",
      "val loss: 0.0139, acc: 0.6152\n",
      "Epoch 7/150\n",
      "train loss: 0.0068, acc: 0.7945\n",
      "val loss: 0.0140, acc: 0.6210\n",
      "Epoch 8/150\n",
      "train loss: 0.0060, acc: 0.8293\n",
      "val loss: 0.0145, acc: 0.6152\n",
      "Epoch 9/150\n",
      "train loss: 0.0051, acc: 0.8590\n",
      "val loss: 0.0144, acc: 0.6035\n",
      "Epoch 10/150\n",
      "train loss: 0.0049, acc: 0.8663\n",
      "val loss: 0.0174, acc: 0.5918\n",
      "Epoch 11/150\n",
      "train loss: 0.0039, acc: 0.8908\n",
      "val loss: 0.0179, acc: 0.6327\n",
      "Epoch 12/150\n",
      "train loss: 0.0030, acc: 0.9234\n",
      "val loss: 0.0213, acc: 0.6268\n",
      "Epoch 13/150\n",
      "train loss: 0.0024, acc: 0.9418\n",
      "val loss: 0.0241, acc: 0.6093\n",
      "Epoch 14/150\n",
      "train loss: 0.0017, acc: 0.9623\n",
      "val loss: 0.0255, acc: 0.6385\n",
      "Epoch 15/150\n",
      "train loss: 0.0015, acc: 0.9674\n",
      "val loss: 0.0282, acc: 0.6152\n",
      "Epoch 16/150\n",
      "train loss: 0.0014, acc: 0.9663\n",
      "val loss: 0.0320, acc: 0.6035\n",
      "Epoch 17/150\n",
      "train loss: 0.0020, acc: 0.9524\n",
      "val loss: 0.0296, acc: 0.6472\n",
      "Epoch 18/150\n",
      "train loss: 0.0018, acc: 0.9560\n",
      "val loss: 0.0304, acc: 0.5977\n",
      "Epoch 19/150\n",
      "train loss: 0.0011, acc: 0.9762\n",
      "val loss: 0.0307, acc: 0.6385\n",
      "Epoch 20/150\n",
      "train loss: 0.0009, acc: 0.9784\n",
      "val loss: 0.0335, acc: 0.5918\n",
      "Epoch 21/150\n",
      "train loss: 0.0005, acc: 0.9875\n",
      "val loss: 0.0346, acc: 0.6181\n",
      "Epoch 22/150\n",
      "train loss: 0.0002, acc: 0.9974\n",
      "val loss: 0.0353, acc: 0.6268\n",
      "Epoch 23/150\n",
      "train loss: 0.0001, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6268\n",
      "Epoch 24/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0386, acc: 0.6414\n",
      "Epoch 25/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0388, acc: 0.6239\n",
      "Epoch 26/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0395, acc: 0.6210\n",
      "Epoch 27/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0392, acc: 0.6327\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0395, acc: 0.6385\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0395, acc: 0.6385\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0398, acc: 0.6297\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0400, acc: 0.6327\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0402, acc: 0.6297\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6327\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0400, acc: 0.6268\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6356\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0402, acc: 0.6297\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6297\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0403, acc: 0.6268\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0403, acc: 0.6297\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0403, acc: 0.6297\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0402, acc: 0.6327\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6268\n",
      "Epoch 43/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0403, acc: 0.6297\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0403, acc: 0.6239\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0402, acc: 0.6268\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0403, acc: 0.6297\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6297\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0410, acc: 0.6239\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0409, acc: 0.6210\n",
      "Epoch 50/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6239\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6239\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6239\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6239\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6210\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6268\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6268\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6239\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0403, acc: 0.6239\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6268\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0402, acc: 0.6239\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0399, acc: 0.6239\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0400, acc: 0.6268\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6239\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6210\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6181\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6239\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0404, acc: 0.6297\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0402, acc: 0.6210\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0404, acc: 0.6239\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0398, acc: 0.6297\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0408, acc: 0.6093\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6152\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6181\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0404, acc: 0.6210\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0404, acc: 0.6181\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6152\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0406, acc: 0.6210\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0403, acc: 0.6181\n",
      "Epoch 79/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6152\n",
      "Epoch 80/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0404, acc: 0.6210\n",
      "Epoch 81/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0404, acc: 0.6122\n",
      "Epoch 82/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0406, acc: 0.6239\n",
      "Epoch 83/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6122\n",
      "Epoch 84/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0404, acc: 0.6122\n",
      "Epoch 85/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6152\n",
      "Epoch 86/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0406, acc: 0.6152\n",
      "Epoch 87/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0399, acc: 0.6093\n",
      "Epoch 88/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6035\n",
      "Epoch 89/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0410, acc: 0.6181\n",
      "Epoch 90/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0404, acc: 0.6152\n",
      "Epoch 91/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6122\n",
      "Epoch 92/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0406, acc: 0.6122\n",
      "Epoch 93/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6093\n",
      "Epoch 94/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6122\n",
      "Epoch 95/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0400, acc: 0.6093\n",
      "Epoch 96/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0402, acc: 0.6064\n",
      "Epoch 97/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0399, acc: 0.6122\n",
      "Epoch 98/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0404, acc: 0.6093\n",
      "Epoch 99/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6122\n",
      "Epoch 100/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0408, acc: 0.6152\n",
      "Epoch 101/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6152\n",
      "Epoch 102/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0408, acc: 0.6122\n",
      "Epoch 103/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0406, acc: 0.6093\n",
      "Epoch 104/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0406, acc: 0.6122\n",
      "Epoch 105/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0414, acc: 0.6035\n",
      "Epoch 106/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0406, acc: 0.6006\n",
      "Epoch 107/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0406, acc: 0.6006\n",
      "Epoch 108/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0414, acc: 0.6006\n",
      "Epoch 109/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0422, acc: 0.6210\n",
      "Epoch 110/150\n",
      "train loss: 0.0783, acc: 0.6623\n",
      "val loss: 0.0162, acc: 0.6239\n",
      "Epoch 111/150\n",
      "train loss: 0.0115, acc: 0.6788\n",
      "val loss: 0.0122, acc: 0.6531\n",
      "Epoch 112/150\n",
      "train loss: 0.0080, acc: 0.7612\n",
      "val loss: 0.0141, acc: 0.6297\n",
      "Epoch 113/150\n",
      "train loss: 0.0074, acc: 0.7780\n",
      "val loss: 0.0130, acc: 0.6414\n",
      "Epoch 114/150\n",
      "train loss: 0.0068, acc: 0.8092\n",
      "val loss: 0.0141, acc: 0.6239\n",
      "Epoch 115/150\n",
      "train loss: 0.0050, acc: 0.8604\n",
      "val loss: 0.0172, acc: 0.6356\n",
      "Epoch 116/150\n",
      "train loss: 0.0043, acc: 0.8846\n",
      "val loss: 0.0185, acc: 0.6210\n",
      "Epoch 117/150\n",
      "train loss: 0.0031, acc: 0.9125\n",
      "val loss: 0.0214, acc: 0.6356\n",
      "Epoch 118/150\n",
      "train loss: 0.0025, acc: 0.9355\n",
      "val loss: 0.0228, acc: 0.6385\n",
      "Epoch 119/150\n",
      "train loss: 0.0018, acc: 0.9582\n",
      "val loss: 0.0256, acc: 0.6210\n",
      "Epoch 120/150\n",
      "train loss: 0.0013, acc: 0.9692\n",
      "val loss: 0.0284, acc: 0.6239\n",
      "Epoch 121/150\n",
      "train loss: 0.0009, acc: 0.9788\n",
      "val loss: 0.0332, acc: 0.6239\n",
      "Epoch 122/150\n",
      "train loss: 0.0006, acc: 0.9868\n",
      "val loss: 0.0322, acc: 0.6501\n",
      "Epoch 123/150\n",
      "train loss: 0.0008, acc: 0.9777\n",
      "val loss: 0.0337, acc: 0.6443\n",
      "Epoch 124/150\n",
      "train loss: 0.0004, acc: 0.9919\n",
      "val loss: 0.0324, acc: 0.6414\n",
      "Epoch 125/150\n",
      "train loss: 0.0004, acc: 0.9938\n",
      "val loss: 0.0365, acc: 0.6676\n",
      "Epoch 126/150\n",
      "train loss: 0.0003, acc: 0.9934\n",
      "val loss: 0.0358, acc: 0.6443\n",
      "Epoch 127/150\n",
      "train loss: 0.0003, acc: 0.9956\n",
      "val loss: 0.0402, acc: 0.6531\n",
      "Epoch 128/150\n",
      "train loss: 0.0002, acc: 0.9971\n",
      "val loss: 0.0445, acc: 0.6181\n",
      "Epoch 129/150\n",
      "train loss: 0.0002, acc: 0.9963\n",
      "val loss: 0.0450, acc: 0.6297\n",
      "Epoch 130/150\n",
      "train loss: 0.0002, acc: 0.9949\n",
      "val loss: 0.0446, acc: 0.6472\n",
      "Epoch 131/150\n",
      "train loss: 0.0002, acc: 0.9978\n",
      "val loss: 0.0435, acc: 0.6385\n",
      "Epoch 132/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0428, acc: 0.6589\n",
      "Epoch 133/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6589\n",
      "Epoch 134/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6647\n",
      "Epoch 135/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6647\n",
      "Epoch 136/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0430, acc: 0.6647\n",
      "Epoch 137/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0429, acc: 0.6589\n",
      "Epoch 138/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0426, acc: 0.6589\n",
      "Epoch 139/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0427, acc: 0.6647\n",
      "Epoch 140/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6618\n",
      "Epoch 141/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6618\n",
      "Epoch 142/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6647\n",
      "Epoch 143/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0429, acc: 0.6647\n",
      "Epoch 144/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0427, acc: 0.6560\n",
      "Epoch 145/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0429, acc: 0.6647\n",
      "Epoch 146/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0427, acc: 0.6618\n",
      "Epoch 147/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6676\n",
      "Epoch 148/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0427, acc: 0.6676\n",
      "Epoch 149/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6560\n",
      "Epoch 150/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6647\n",
      "Training complete in 1m 22s\n",
      "Best val Acc: 0.667638\n",
      "Best Epoch : 125\n",
      "Test Accuracy : 0.68\n",
      "                              Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)            1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)           0.993773  0.667638      0.68    125\n",
      "C[1, 16, 8]_K(3, 40)           0.906227  0.667638      0.71    136\n",
      "C[1, 32, 16, 8]_K(3, 8)        1.000000  0.690962      0.76     92\n",
      "C[1, 32, 16, 8]_K(3, 24)       0.762637  0.682216      0.74      8\n",
      "C[1, 32, 16, 8]_K(3, 40)       0.720513  0.679300      0.77      7\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)    0.899267  0.705539      0.76    134\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)   0.999634  0.685131      0.80    145\n",
      "\n",
      "\n",
      "##### C[1, 16, 8]_K(3, 40) #####\n",
      "Input shape : torch.Size([1, 16, 22, 90]) and flattened : 31680\n",
      "Input shape : torch.Size([1, 8, 22, 45]) and flattened : 7920\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 40)_O16): Conv2d(1, 16, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O8): Conv2d(16, 8, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (fc1): Linear(in_features=7920, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0453, acc: 0.5077\n",
      "val loss: 0.0169, acc: 0.4869\n",
      "Epoch 2/150\n",
      "train loss: 0.0122, acc: 0.5755\n",
      "val loss: 0.0137, acc: 0.5219\n",
      "Epoch 3/150\n",
      "train loss: 0.0103, acc: 0.6253\n",
      "val loss: 0.0152, acc: 0.5248\n",
      "Epoch 4/150\n",
      "train loss: 0.0099, acc: 0.6524\n",
      "val loss: 0.0123, acc: 0.5685\n",
      "Epoch 5/150\n",
      "train loss: 0.0081, acc: 0.7425\n",
      "val loss: 0.0129, acc: 0.6152\n",
      "Epoch 6/150\n",
      "train loss: 0.0076, acc: 0.7608\n",
      "val loss: 0.0133, acc: 0.5802\n",
      "Epoch 7/150\n",
      "train loss: 0.0062, acc: 0.8253\n",
      "val loss: 0.0166, acc: 0.5948\n",
      "Epoch 8/150\n",
      "train loss: 0.0063, acc: 0.8165\n",
      "val loss: 0.0144, acc: 0.6472\n",
      "Epoch 9/150\n",
      "train loss: 0.0054, acc: 0.8407\n",
      "val loss: 0.0181, acc: 0.6356\n",
      "Epoch 10/150\n",
      "train loss: 0.0051, acc: 0.8535\n",
      "val loss: 0.0172, acc: 0.6239\n",
      "Epoch 11/150\n",
      "train loss: 0.0031, acc: 0.9249\n",
      "val loss: 0.0207, acc: 0.5948\n",
      "Epoch 12/150\n",
      "train loss: 0.0025, acc: 0.9333\n",
      "val loss: 0.0251, acc: 0.6064\n",
      "Epoch 13/150\n",
      "train loss: 0.0031, acc: 0.9161\n",
      "val loss: 0.0254, acc: 0.5860\n",
      "Epoch 14/150\n",
      "train loss: 0.0028, acc: 0.9253\n",
      "val loss: 0.0249, acc: 0.6210\n",
      "Epoch 15/150\n",
      "train loss: 0.0015, acc: 0.9637\n",
      "val loss: 0.0266, acc: 0.6210\n",
      "Epoch 16/150\n",
      "train loss: 0.0010, acc: 0.9777\n",
      "val loss: 0.0323, acc: 0.6210\n",
      "Epoch 17/150\n",
      "train loss: 0.0008, acc: 0.9850\n",
      "val loss: 0.0324, acc: 0.6385\n",
      "Epoch 18/150\n",
      "train loss: 0.0006, acc: 0.9879\n",
      "val loss: 0.0349, acc: 0.6239\n",
      "Epoch 19/150\n",
      "train loss: 0.0005, acc: 0.9912\n",
      "val loss: 0.0355, acc: 0.6297\n",
      "Epoch 20/150\n",
      "train loss: 0.0007, acc: 0.9839\n",
      "val loss: 0.0402, acc: 0.6093\n",
      "Epoch 21/150\n",
      "train loss: 0.0019, acc: 0.9575\n",
      "val loss: 0.0385, acc: 0.6297\n",
      "Epoch 22/150\n",
      "train loss: 0.0028, acc: 0.9399\n",
      "val loss: 0.0393, acc: 0.6152\n",
      "Epoch 23/150\n",
      "train loss: 0.0018, acc: 0.9571\n",
      "val loss: 0.0350, acc: 0.6210\n",
      "Epoch 24/150\n",
      "train loss: 0.0008, acc: 0.9813\n",
      "val loss: 0.0408, acc: 0.6064\n",
      "Epoch 25/150\n",
      "train loss: 0.0003, acc: 0.9952\n",
      "val loss: 0.0424, acc: 0.6268\n",
      "Epoch 26/150\n",
      "train loss: 0.0002, acc: 0.9974\n",
      "val loss: 0.0413, acc: 0.6239\n",
      "Epoch 27/150\n",
      "train loss: 0.0001, acc: 1.0000\n",
      "val loss: 0.0412, acc: 0.6414\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0427, acc: 0.6414\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0430, acc: 0.6443\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0434, acc: 0.6327\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0433, acc: 0.6472\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0443, acc: 0.6297\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0444, acc: 0.6327\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0441, acc: 0.6414\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0441, acc: 0.6472\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0443, acc: 0.6472\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0445, acc: 0.6414\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0450, acc: 0.6414\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0450, acc: 0.6414\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0453, acc: 0.6414\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0453, acc: 0.6443\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6414\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0452, acc: 0.6472\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0455, acc: 0.6385\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0455, acc: 0.6414\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0455, acc: 0.6414\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0453, acc: 0.6414\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0455, acc: 0.6356\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6414\n",
      "Epoch 50/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0455, acc: 0.6356\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0455, acc: 0.6385\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0456, acc: 0.6414\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0456, acc: 0.6414\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0456, acc: 0.6385\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0457, acc: 0.6385\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0457, acc: 0.6385\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6356\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0460, acc: 0.6356\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0460, acc: 0.6356\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0459, acc: 0.6414\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0460, acc: 0.6443\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6385\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0457, acc: 0.6385\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0461, acc: 0.6414\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0463, acc: 0.6443\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0459, acc: 0.6414\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6356\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6385\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0460, acc: 0.6356\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6414\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0453, acc: 0.6414\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0459, acc: 0.6414\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0457, acc: 0.6385\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6297\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6472\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0453, acc: 0.6472\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6385\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0456, acc: 0.6443\n",
      "Epoch 79/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6385\n",
      "Epoch 80/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0456, acc: 0.6356\n",
      "Epoch 81/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0460, acc: 0.6443\n",
      "Epoch 82/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0457, acc: 0.6385\n",
      "Epoch 83/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0459, acc: 0.6414\n",
      "Epoch 84/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6385\n",
      "Epoch 85/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0463, acc: 0.6443\n",
      "Epoch 86/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0452, acc: 0.6414\n",
      "Epoch 87/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0456, acc: 0.6414\n",
      "Epoch 88/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0453, acc: 0.6443\n",
      "Epoch 89/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0453, acc: 0.6472\n",
      "Epoch 90/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0452, acc: 0.6443\n",
      "Epoch 91/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0451, acc: 0.6501\n",
      "Epoch 92/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6472\n",
      "Epoch 93/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6414\n",
      "Epoch 94/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0452, acc: 0.6385\n",
      "Epoch 95/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0457, acc: 0.6443\n",
      "Epoch 96/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0451, acc: 0.6356\n",
      "Epoch 97/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0451, acc: 0.6414\n",
      "Epoch 98/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0452, acc: 0.6356\n",
      "Epoch 99/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6443\n",
      "Epoch 100/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0459, acc: 0.6414\n",
      "Epoch 101/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0449, acc: 0.6414\n",
      "Epoch 102/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0455, acc: 0.6414\n",
      "Epoch 103/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0453, acc: 0.6443\n",
      "Epoch 104/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0457, acc: 0.6443\n",
      "Epoch 105/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0453, acc: 0.6472\n",
      "Epoch 106/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0449, acc: 0.6501\n",
      "Epoch 107/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0451, acc: 0.6472\n",
      "Epoch 108/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0452, acc: 0.6472\n",
      "Epoch 109/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0448, acc: 0.6443\n",
      "Epoch 110/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0447, acc: 0.6297\n",
      "Epoch 111/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6297\n",
      "Epoch 112/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0453, acc: 0.6472\n",
      "Epoch 113/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0459, acc: 0.6327\n",
      "Epoch 114/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0459, acc: 0.6472\n",
      "Epoch 115/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0453, acc: 0.6472\n",
      "Epoch 116/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6443\n",
      "Epoch 117/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6385\n",
      "Epoch 118/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0460, acc: 0.6414\n",
      "Epoch 119/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0459, acc: 0.6268\n",
      "Epoch 120/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0452, acc: 0.6385\n",
      "Epoch 121/150\n",
      "train loss: 0.0761, acc: 0.7502\n",
      "val loss: 0.0583, acc: 0.4927\n",
      "Epoch 122/150\n",
      "train loss: 0.0177, acc: 0.6359\n",
      "val loss: 0.0124, acc: 0.6327\n",
      "Epoch 123/150\n",
      "train loss: 0.0083, acc: 0.7403\n",
      "val loss: 0.0132, acc: 0.6443\n",
      "Epoch 124/150\n",
      "train loss: 0.0071, acc: 0.7828\n",
      "val loss: 0.0126, acc: 0.6239\n",
      "Epoch 125/150\n",
      "train loss: 0.0068, acc: 0.7985\n",
      "val loss: 0.0127, acc: 0.6414\n",
      "Epoch 126/150\n",
      "train loss: 0.0058, acc: 0.8396\n",
      "val loss: 0.0148, acc: 0.6385\n",
      "Epoch 127/150\n",
      "train loss: 0.0052, acc: 0.8524\n",
      "val loss: 0.0156, acc: 0.6385\n",
      "Epoch 128/150\n",
      "train loss: 0.0040, acc: 0.8897\n",
      "val loss: 0.0179, acc: 0.6676\n",
      "Epoch 129/150\n",
      "train loss: 0.0030, acc: 0.9231\n",
      "val loss: 0.0212, acc: 0.6356\n",
      "Epoch 130/150\n",
      "train loss: 0.0026, acc: 0.9311\n",
      "val loss: 0.0235, acc: 0.6327\n",
      "Epoch 131/150\n",
      "train loss: 0.0023, acc: 0.9396\n",
      "val loss: 0.0245, acc: 0.6443\n",
      "Epoch 132/150\n",
      "train loss: 0.0012, acc: 0.9755\n",
      "val loss: 0.0302, acc: 0.6472\n",
      "Epoch 133/150\n",
      "train loss: 0.0008, acc: 0.9864\n",
      "val loss: 0.0310, acc: 0.6414\n",
      "Epoch 134/150\n",
      "train loss: 0.0005, acc: 0.9912\n",
      "val loss: 0.0341, acc: 0.6560\n",
      "Epoch 135/150\n",
      "train loss: 0.0006, acc: 0.9879\n",
      "val loss: 0.0377, acc: 0.6414\n",
      "Epoch 136/150\n",
      "train loss: 0.0007, acc: 0.9828\n",
      "val loss: 0.0368, acc: 0.6472\n",
      "Epoch 137/150\n",
      "train loss: 0.0006, acc: 0.9872\n",
      "val loss: 0.0425, acc: 0.6443\n",
      "Epoch 138/150\n",
      "train loss: 0.0004, acc: 0.9923\n",
      "val loss: 0.0446, acc: 0.6297\n",
      "Epoch 139/150\n",
      "train loss: 0.0002, acc: 0.9967\n",
      "val loss: 0.0425, acc: 0.6472\n",
      "Epoch 140/150\n",
      "train loss: 0.0001, acc: 0.9996\n",
      "val loss: 0.0455, acc: 0.6531\n",
      "Epoch 141/150\n",
      "train loss: 0.0001, acc: 0.9996\n",
      "val loss: 0.0447, acc: 0.6356\n",
      "Epoch 142/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0459, acc: 0.6327\n",
      "Epoch 143/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0465, acc: 0.6414\n",
      "Epoch 144/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0472, acc: 0.6268\n",
      "Epoch 145/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0462, acc: 0.6472\n",
      "Epoch 146/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0470, acc: 0.6385\n",
      "Epoch 147/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0465, acc: 0.6210\n",
      "Epoch 148/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0475, acc: 0.6385\n",
      "Epoch 149/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0474, acc: 0.6239\n",
      "Epoch 150/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.6327\n",
      "Training complete in 2m 28s\n",
      "Best val Acc: 0.667638\n",
      "Best Epoch : 128\n",
      "Test Accuracy : 0.7\n",
      "                              Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)            1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)           0.993773  0.667638      0.68    125\n",
      "C[1, 16, 8]_K(3, 40)           0.889744  0.667638      0.70    128\n",
      "C[1, 32, 16, 8]_K(3, 8)        1.000000  0.690962      0.76     92\n",
      "C[1, 32, 16, 8]_K(3, 24)       0.762637  0.682216      0.74      8\n",
      "C[1, 32, 16, 8]_K(3, 40)       0.720513  0.679300      0.77      7\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)    0.899267  0.705539      0.76    134\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)   0.999634  0.685131      0.80    145\n",
      "\n",
      "\n",
      "##### C[1, 32, 16, 8]_K(3, 8) #####\n",
      "Input shape : torch.Size([1, 32, 22, 90]) and flattened : 63360\n",
      "Input shape : torch.Size([1, 16, 22, 45]) and flattened : 15840\n",
      "Input shape : torch.Size([1, 8, 22, 23]) and flattened : 4048\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 8)_O32): Conv2d(1, 32, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O16): Conv2d(32, 16, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O8): Conv2d(16, 8, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (fc1): Linear(in_features=4048, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n",
      "train loss: 0.0288, acc: 0.4989\n",
      "val loss: 0.0132, acc: 0.5277\n",
      "Epoch 2/150\n",
      "train loss: 0.0117, acc: 0.5553\n",
      "val loss: 0.0136, acc: 0.5131\n",
      "Epoch 3/150\n",
      "train loss: 0.0104, acc: 0.6205\n",
      "val loss: 0.0121, acc: 0.6122\n",
      "Epoch 4/150\n",
      "train loss: 0.0091, acc: 0.6886\n",
      "val loss: 0.0120, acc: 0.6122\n",
      "Epoch 5/150\n",
      "train loss: 0.0084, acc: 0.7249\n",
      "val loss: 0.0126, acc: 0.6297\n",
      "Epoch 6/150\n",
      "train loss: 0.0080, acc: 0.7326\n",
      "val loss: 0.0119, acc: 0.6356\n",
      "Epoch 7/150\n",
      "train loss: 0.0068, acc: 0.7974\n",
      "val loss: 0.0121, acc: 0.6472\n",
      "Epoch 8/150\n",
      "train loss: 0.0068, acc: 0.7956\n",
      "val loss: 0.0138, acc: 0.6152\n",
      "Epoch 9/150\n",
      "train loss: 0.0052, acc: 0.8590\n",
      "val loss: 0.0129, acc: 0.6706\n",
      "Epoch 10/150\n",
      "train loss: 0.0046, acc: 0.8747\n",
      "val loss: 0.0156, acc: 0.6560\n",
      "Epoch 11/150\n",
      "train loss: 0.0038, acc: 0.8963\n",
      "val loss: 0.0188, acc: 0.6181\n",
      "Epoch 12/150\n",
      "train loss: 0.0032, acc: 0.9132\n",
      "val loss: 0.0208, acc: 0.6501\n",
      "Epoch 13/150\n",
      "train loss: 0.0021, acc: 0.9527\n",
      "val loss: 0.0197, acc: 0.6676\n",
      "Epoch 14/150\n",
      "train loss: 0.0018, acc: 0.9553\n",
      "val loss: 0.0199, acc: 0.6880\n",
      "Epoch 15/150\n",
      "train loss: 0.0011, acc: 0.9788\n",
      "val loss: 0.0241, acc: 0.6706\n",
      "Epoch 16/150\n",
      "train loss: 0.0008, acc: 0.9835\n",
      "val loss: 0.0265, acc: 0.6618\n",
      "Epoch 17/150\n",
      "train loss: 0.0006, acc: 0.9886\n",
      "val loss: 0.0274, acc: 0.6472\n",
      "Epoch 18/150\n",
      "train loss: 0.0003, acc: 0.9971\n",
      "val loss: 0.0279, acc: 0.6706\n",
      "Epoch 19/150\n",
      "train loss: 0.0001, acc: 1.0000\n",
      "val loss: 0.0292, acc: 0.6793\n",
      "Epoch 20/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0300, acc: 0.6618\n",
      "Epoch 21/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0296, acc: 0.6676\n",
      "Epoch 22/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0301, acc: 0.6676\n",
      "Epoch 23/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0304, acc: 0.6618\n",
      "Epoch 24/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0309, acc: 0.6531\n",
      "Epoch 25/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0311, acc: 0.6647\n",
      "Epoch 26/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0312, acc: 0.6676\n",
      "Epoch 27/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0314, acc: 0.6676\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0316, acc: 0.6735\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0319, acc: 0.6764\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0319, acc: 0.6676\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0321, acc: 0.6735\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6647\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0321, acc: 0.6589\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6735\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6706\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6618\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.6764\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6531\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6560\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6647\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6589\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6676\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6618\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6793\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6647\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6647\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6706\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6793\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6764\n",
      "Epoch 50/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6589\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.6735\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6706\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0329, acc: 0.6764\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6706\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6706\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6706\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6618\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6647\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6706\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6764\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6647\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6706\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6676\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6647\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6618\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6706\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6676\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6676\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6618\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6706\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6647\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6676\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6706\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6589\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0321, acc: 0.6618\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6589\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6676\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0321, acc: 0.6647\n",
      "Epoch 79/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0321, acc: 0.6618\n",
      "Epoch 80/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6735\n",
      "Epoch 81/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0320, acc: 0.6589\n",
      "Epoch 82/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6647\n",
      "Epoch 83/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0317, acc: 0.6676\n",
      "Epoch 84/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0321, acc: 0.6560\n",
      "Epoch 85/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0318, acc: 0.6735\n",
      "Epoch 86/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6676\n",
      "Epoch 87/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0320, acc: 0.6706\n",
      "Epoch 88/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0320, acc: 0.6676\n",
      "Epoch 89/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0319, acc: 0.6676\n",
      "Epoch 90/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0320, acc: 0.6618\n",
      "Epoch 91/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0320, acc: 0.6676\n",
      "Epoch 92/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6647\n",
      "Epoch 93/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0321, acc: 0.6560\n",
      "Epoch 94/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6560\n",
      "Epoch 95/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0320, acc: 0.6589\n",
      "Epoch 96/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0319, acc: 0.6647\n",
      "Epoch 97/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0317, acc: 0.6735\n",
      "Epoch 98/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0315, acc: 0.6764\n",
      "Epoch 99/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0319, acc: 0.6618\n",
      "Epoch 100/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0323, acc: 0.6676\n",
      "Epoch 101/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0320, acc: 0.6706\n",
      "Epoch 102/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0320, acc: 0.6560\n",
      "Epoch 103/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0321, acc: 0.6647\n",
      "Epoch 104/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0319, acc: 0.6501\n",
      "Epoch 105/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0320, acc: 0.6618\n",
      "Epoch 106/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0319, acc: 0.6589\n",
      "Epoch 107/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0318, acc: 0.6676\n",
      "Epoch 108/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6618\n",
      "Epoch 109/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0320, acc: 0.6589\n",
      "Epoch 110/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0320, acc: 0.6618\n",
      "Epoch 111/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0319, acc: 0.6589\n",
      "Epoch 112/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0318, acc: 0.6589\n",
      "Epoch 113/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0315, acc: 0.6647\n",
      "Epoch 114/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6706\n",
      "Epoch 115/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0317, acc: 0.6560\n",
      "Epoch 116/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0321, acc: 0.6501\n",
      "Epoch 117/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0321, acc: 0.6589\n",
      "Epoch 118/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0315, acc: 0.6501\n",
      "Epoch 119/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0319, acc: 0.6589\n",
      "Epoch 120/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0319, acc: 0.6589\n",
      "Epoch 121/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0321, acc: 0.6531\n",
      "Epoch 122/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0319, acc: 0.6560\n",
      "Epoch 123/150\n",
      "train loss: 0.0596, acc: 0.8447\n",
      "val loss: 0.0635, acc: 0.5102\n",
      "Epoch 124/150\n",
      "train loss: 0.0210, acc: 0.5198\n",
      "val loss: 0.0141, acc: 0.5423\n",
      "Epoch 125/150\n",
      "train loss: 0.0108, acc: 0.5912\n",
      "val loss: 0.0125, acc: 0.6093\n",
      "Epoch 126/150\n",
      "train loss: 0.0100, acc: 0.6399\n",
      "val loss: 0.0114, acc: 0.6181\n",
      "Epoch 127/150\n",
      "train loss: 0.0094, acc: 0.6846\n",
      "val loss: 0.0119, acc: 0.6356\n",
      "Epoch 128/150\n",
      "train loss: 0.0090, acc: 0.7004\n",
      "val loss: 0.0118, acc: 0.6035\n",
      "Epoch 129/150\n",
      "train loss: 0.0087, acc: 0.7147\n",
      "val loss: 0.0125, acc: 0.6297\n",
      "Epoch 130/150\n",
      "train loss: 0.0085, acc: 0.7293\n",
      "val loss: 0.0122, acc: 0.6239\n",
      "Epoch 131/150\n",
      "train loss: 0.0083, acc: 0.7392\n",
      "val loss: 0.0122, acc: 0.6239\n",
      "Epoch 132/150\n",
      "train loss: 0.0076, acc: 0.7681\n",
      "val loss: 0.0126, acc: 0.6414\n",
      "Epoch 133/150\n",
      "train loss: 0.0077, acc: 0.7575\n",
      "val loss: 0.0126, acc: 0.6268\n",
      "Epoch 134/150\n",
      "train loss: 0.0074, acc: 0.7711\n",
      "val loss: 0.0123, acc: 0.6356\n",
      "Epoch 135/150\n",
      "train loss: 0.0073, acc: 0.7835\n",
      "val loss: 0.0132, acc: 0.6268\n",
      "Epoch 136/150\n",
      "train loss: 0.0069, acc: 0.7930\n",
      "val loss: 0.0138, acc: 0.6152\n",
      "Epoch 137/150\n",
      "train loss: 0.0067, acc: 0.8022\n",
      "val loss: 0.0133, acc: 0.6414\n",
      "Epoch 138/150\n",
      "train loss: 0.0062, acc: 0.8147\n",
      "val loss: 0.0142, acc: 0.6385\n",
      "Epoch 139/150\n",
      "train loss: 0.0059, acc: 0.8227\n",
      "val loss: 0.0141, acc: 0.6618\n",
      "Epoch 140/150\n",
      "train loss: 0.0054, acc: 0.8524\n",
      "val loss: 0.0145, acc: 0.6706\n",
      "Epoch 141/150\n",
      "train loss: 0.0050, acc: 0.8615\n",
      "val loss: 0.0150, acc: 0.6501\n",
      "Epoch 142/150\n",
      "train loss: 0.0043, acc: 0.8802\n",
      "val loss: 0.0167, acc: 0.6443\n",
      "Epoch 143/150\n",
      "train loss: 0.0043, acc: 0.8864\n",
      "val loss: 0.0187, acc: 0.6239\n",
      "Epoch 144/150\n",
      "train loss: 0.0036, acc: 0.8963\n",
      "val loss: 0.0187, acc: 0.6385\n",
      "Epoch 145/150\n",
      "train loss: 0.0029, acc: 0.9242\n",
      "val loss: 0.0200, acc: 0.6472\n",
      "Epoch 146/150\n",
      "train loss: 0.0035, acc: 0.9048\n",
      "val loss: 0.0232, acc: 0.6414\n",
      "Epoch 147/150\n",
      "train loss: 0.0021, acc: 0.9469\n",
      "val loss: 0.0251, acc: 0.6210\n",
      "Epoch 148/150\n",
      "train loss: 0.0011, acc: 0.9777\n",
      "val loss: 0.0278, acc: 0.6356\n",
      "Epoch 149/150\n",
      "train loss: 0.0012, acc: 0.9678\n",
      "val loss: 0.0298, acc: 0.6239\n",
      "Epoch 150/150\n",
      "train loss: 0.0007, acc: 0.9846\n",
      "val loss: 0.0324, acc: 0.6297\n",
      "Training complete in 1m 29s\n",
      "Best val Acc: 0.688047\n",
      "Best Epoch : 14\n",
      "Test Accuracy : 0.78\n",
      "                              Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)            1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)           0.993773  0.667638      0.68    125\n",
      "C[1, 16, 8]_K(3, 40)           0.889744  0.667638      0.70    128\n",
      "C[1, 32, 16, 8]_K(3, 8)        0.955311  0.688047      0.78     14\n",
      "C[1, 32, 16, 8]_K(3, 24)       0.762637  0.682216      0.74      8\n",
      "C[1, 32, 16, 8]_K(3, 40)       0.720513  0.679300      0.77      7\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)    0.899267  0.705539      0.76    134\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)   0.999634  0.685131      0.80    145\n",
      "\n",
      "\n",
      "##### C[1, 32, 16, 8]_K(3, 24) #####\n",
      "Input shape : torch.Size([1, 32, 22, 90]) and flattened : 63360\n",
      "Input shape : torch.Size([1, 16, 22, 45]) and flattened : 15840\n",
      "Input shape : torch.Size([1, 8, 22, 23]) and flattened : 4048\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 24)_O32): Conv2d(1, 32, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O16): Conv2d(32, 16, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O8): Conv2d(16, 8, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (fc1): Linear(in_features=4048, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0303, acc: 0.5143\n",
      "val loss: 0.0146, acc: 0.5160\n",
      "Epoch 2/150\n",
      "train loss: 0.0125, acc: 0.5209\n",
      "val loss: 0.0130, acc: 0.5452\n",
      "Epoch 3/150\n",
      "train loss: 0.0112, acc: 0.5637\n",
      "val loss: 0.0128, acc: 0.5306\n",
      "Epoch 4/150\n",
      "train loss: 0.0103, acc: 0.6172\n",
      "val loss: 0.0115, acc: 0.6268\n",
      "Epoch 5/150\n",
      "train loss: 0.0094, acc: 0.6714\n",
      "val loss: 0.0117, acc: 0.6327\n",
      "Epoch 6/150\n",
      "train loss: 0.0087, acc: 0.7172\n",
      "val loss: 0.0131, acc: 0.6035\n",
      "Epoch 7/150\n",
      "train loss: 0.0085, acc: 0.7201\n",
      "val loss: 0.0126, acc: 0.6239\n",
      "Epoch 8/150\n",
      "train loss: 0.0075, acc: 0.7663\n",
      "val loss: 0.0127, acc: 0.6210\n",
      "Epoch 9/150\n",
      "train loss: 0.0072, acc: 0.7864\n",
      "val loss: 0.0123, acc: 0.6210\n",
      "Epoch 10/150\n",
      "train loss: 0.0058, acc: 0.8385\n",
      "val loss: 0.0130, acc: 0.6385\n",
      "Epoch 11/150\n",
      "train loss: 0.0048, acc: 0.8777\n",
      "val loss: 0.0155, acc: 0.6268\n",
      "Epoch 12/150\n",
      "train loss: 0.0051, acc: 0.8564\n",
      "val loss: 0.0179, acc: 0.6268\n",
      "Epoch 13/150\n",
      "train loss: 0.0034, acc: 0.9154\n",
      "val loss: 0.0185, acc: 0.6647\n",
      "Epoch 14/150\n",
      "train loss: 0.0015, acc: 0.9696\n",
      "val loss: 0.0207, acc: 0.6443\n",
      "Epoch 15/150\n",
      "train loss: 0.0010, acc: 0.9788\n",
      "val loss: 0.0266, acc: 0.6327\n",
      "Epoch 16/150\n",
      "train loss: 0.0008, acc: 0.9857\n",
      "val loss: 0.0254, acc: 0.6414\n",
      "Epoch 17/150\n",
      "train loss: 0.0005, acc: 0.9916\n",
      "val loss: 0.0322, acc: 0.6385\n",
      "Epoch 18/150\n",
      "train loss: 0.0008, acc: 0.9824\n",
      "val loss: 0.0315, acc: 0.6472\n",
      "Epoch 19/150\n",
      "train loss: 0.0015, acc: 0.9630\n",
      "val loss: 0.0370, acc: 0.6443\n",
      "Epoch 20/150\n",
      "train loss: 0.0022, acc: 0.9495\n",
      "val loss: 0.0282, acc: 0.6560\n",
      "Epoch 21/150\n",
      "train loss: 0.0011, acc: 0.9736\n",
      "val loss: 0.0331, acc: 0.6443\n",
      "Epoch 22/150\n",
      "train loss: 0.0005, acc: 0.9916\n",
      "val loss: 0.0297, acc: 0.6414\n",
      "Epoch 23/150\n",
      "train loss: 0.0001, acc: 0.9982\n",
      "val loss: 0.0335, acc: 0.6268\n",
      "Epoch 24/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0334, acc: 0.6385\n",
      "Epoch 25/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0337, acc: 0.6356\n",
      "Epoch 26/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0341, acc: 0.6443\n",
      "Epoch 27/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0341, acc: 0.6501\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0345, acc: 0.6531\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0347, acc: 0.6560\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0351, acc: 0.6531\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0353, acc: 0.6560\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.6531\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0356, acc: 0.6531\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0356, acc: 0.6472\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0357, acc: 0.6531\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0358, acc: 0.6531\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0359, acc: 0.6589\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0359, acc: 0.6501\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0360, acc: 0.6531\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0361, acc: 0.6501\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0362, acc: 0.6531\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6531\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0362, acc: 0.6531\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6501\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6589\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6560\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6531\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6560\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6560\n",
      "Epoch 50/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6531\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6560\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6589\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6589\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6589\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6531\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6589\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6589\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6501\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6589\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6501\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6531\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6531\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6531\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6531\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6531\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6589\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6589\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0362, acc: 0.6472\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6501\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6560\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6589\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0362, acc: 0.6560\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0362, acc: 0.6560\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6560\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6589\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0362, acc: 0.6531\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6531\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6560\n",
      "Epoch 79/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6531\n",
      "Epoch 80/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6560\n",
      "Epoch 81/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6560\n",
      "Epoch 82/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0366, acc: 0.6531\n",
      "Epoch 83/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0366, acc: 0.6560\n",
      "Epoch 84/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6472\n",
      "Epoch 85/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6531\n",
      "Epoch 86/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6560\n",
      "Epoch 87/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6560\n",
      "Epoch 88/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6443\n",
      "Epoch 89/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6560\n",
      "Epoch 90/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6560\n",
      "Epoch 91/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6589\n",
      "Epoch 92/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6560\n",
      "Epoch 93/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6560\n",
      "Epoch 94/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0367, acc: 0.6501\n",
      "Epoch 95/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6531\n",
      "Epoch 96/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0366, acc: 0.6560\n",
      "Epoch 97/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0367, acc: 0.6501\n",
      "Epoch 98/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6560\n",
      "Epoch 99/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0367, acc: 0.6472\n",
      "Epoch 100/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6560\n",
      "Epoch 101/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0366, acc: 0.6531\n",
      "Epoch 102/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6443\n",
      "Epoch 103/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6589\n",
      "Epoch 104/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0367, acc: 0.6501\n",
      "Epoch 105/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6589\n",
      "Epoch 106/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6531\n",
      "Epoch 107/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6443\n",
      "Epoch 108/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6618\n",
      "Epoch 109/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6560\n",
      "Epoch 110/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6501\n",
      "Epoch 111/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0366, acc: 0.6531\n",
      "Epoch 112/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0367, acc: 0.6560\n",
      "Epoch 113/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0367, acc: 0.6501\n",
      "Epoch 114/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0367, acc: 0.6531\n",
      "Epoch 115/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6356\n",
      "Epoch 116/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6443\n",
      "Epoch 117/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6385\n",
      "Epoch 118/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0366, acc: 0.6501\n",
      "Epoch 119/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6531\n",
      "Epoch 120/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6618\n",
      "Epoch 121/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6385\n",
      "Epoch 122/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0367, acc: 0.6618\n",
      "Epoch 123/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0370, acc: 0.6560\n",
      "Epoch 124/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6501\n",
      "Epoch 125/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0373, acc: 0.6560\n",
      "Epoch 126/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6501\n",
      "Epoch 127/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0370, acc: 0.6443\n",
      "Epoch 128/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0376, acc: 0.6472\n",
      "Epoch 129/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6531\n",
      "Epoch 130/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0375, acc: 0.6589\n",
      "Epoch 131/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6531\n",
      "Epoch 132/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6443\n",
      "Epoch 133/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0375, acc: 0.6356\n",
      "Epoch 134/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0379, acc: 0.6385\n",
      "Epoch 135/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6385\n",
      "Epoch 136/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6414\n",
      "Epoch 137/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6414\n",
      "Epoch 138/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6239\n",
      "Epoch 139/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6356\n",
      "Epoch 140/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0373, acc: 0.6327\n",
      "Epoch 141/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0380, acc: 0.6443\n",
      "Epoch 142/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0376, acc: 0.6414\n",
      "Epoch 143/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0382, acc: 0.6414\n",
      "Epoch 144/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0378, acc: 0.6356\n",
      "Epoch 145/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0378, acc: 0.6472\n",
      "Epoch 146/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0383, acc: 0.6356\n",
      "Epoch 147/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6327\n",
      "Epoch 148/150\n",
      "train loss: 0.0720, acc: 0.6344\n",
      "val loss: 0.0184, acc: 0.5102\n",
      "Epoch 149/150\n",
      "train loss: 0.0151, acc: 0.5516\n",
      "val loss: 0.0129, acc: 0.6239\n",
      "Epoch 150/150\n",
      "train loss: 0.0109, acc: 0.6410\n",
      "val loss: 0.0116, acc: 0.6181\n",
      "Training complete in 2m 2s\n",
      "Best val Acc: 0.664723\n",
      "Best Epoch : 13\n",
      "Test Accuracy : 0.76\n",
      "                              Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)            1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)           0.993773  0.667638      0.68    125\n",
      "C[1, 16, 8]_K(3, 40)           0.889744  0.667638      0.70    128\n",
      "C[1, 32, 16, 8]_K(3, 8)        0.955311  0.688047      0.78     14\n",
      "C[1, 32, 16, 8]_K(3, 24)       0.915385  0.664723      0.76     13\n",
      "C[1, 32, 16, 8]_K(3, 40)       0.720513  0.679300      0.77      7\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)    0.899267  0.705539      0.76    134\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)   0.999634  0.685131      0.80    145\n",
      "\n",
      "\n",
      "##### C[1, 32, 16, 8]_K(3, 40) #####\n",
      "Input shape : torch.Size([1, 32, 22, 90]) and flattened : 63360\n",
      "Input shape : torch.Size([1, 16, 22, 45]) and flattened : 15840\n",
      "Input shape : torch.Size([1, 8, 22, 23]) and flattened : 4048\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 40)_O32): Conv2d(1, 32, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O16): Conv2d(32, 16, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O8): Conv2d(16, 8, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (fc1): Linear(in_features=4048, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n",
      "train loss: 0.0205, acc: 0.5110\n",
      "val loss: 0.0126, acc: 0.5743\n",
      "Epoch 2/150\n",
      "train loss: 0.0126, acc: 0.5491\n",
      "val loss: 0.0128, acc: 0.5306\n",
      "Epoch 3/150\n",
      "train loss: 0.0115, acc: 0.5773\n",
      "val loss: 0.0123, acc: 0.5481\n",
      "Epoch 4/150\n",
      "train loss: 0.0103, acc: 0.6414\n",
      "val loss: 0.0118, acc: 0.5977\n",
      "Epoch 5/150\n",
      "train loss: 0.0091, acc: 0.6912\n",
      "val loss: 0.0121, acc: 0.5948\n",
      "Epoch 6/150\n",
      "train loss: 0.0085, acc: 0.7161\n",
      "val loss: 0.0114, acc: 0.6560\n",
      "Epoch 7/150\n",
      "train loss: 0.0075, acc: 0.7659\n",
      "val loss: 0.0119, acc: 0.6268\n",
      "Epoch 8/150\n",
      "train loss: 0.0068, acc: 0.8066\n",
      "val loss: 0.0142, acc: 0.6181\n",
      "Epoch 9/150\n",
      "train loss: 0.0062, acc: 0.8227\n",
      "val loss: 0.0148, acc: 0.6501\n",
      "Epoch 10/150\n",
      "train loss: 0.0050, acc: 0.8641\n",
      "val loss: 0.0152, acc: 0.6443\n",
      "Epoch 11/150\n",
      "train loss: 0.0033, acc: 0.9143\n",
      "val loss: 0.0191, acc: 0.6122\n",
      "Epoch 12/150\n",
      "train loss: 0.0021, acc: 0.9542\n",
      "val loss: 0.0218, acc: 0.6268\n",
      "Epoch 13/150\n",
      "train loss: 0.0016, acc: 0.9612\n",
      "val loss: 0.0235, acc: 0.6414\n",
      "Epoch 14/150\n",
      "train loss: 0.0011, acc: 0.9780\n",
      "val loss: 0.0267, acc: 0.6385\n",
      "Epoch 15/150\n",
      "train loss: 0.0013, acc: 0.9718\n",
      "val loss: 0.0270, acc: 0.6385\n",
      "Epoch 16/150\n",
      "train loss: 0.0008, acc: 0.9791\n",
      "val loss: 0.0315, acc: 0.6327\n",
      "Epoch 17/150\n",
      "train loss: 0.0007, acc: 0.9861\n",
      "val loss: 0.0321, acc: 0.6210\n",
      "Epoch 18/150\n",
      "train loss: 0.0012, acc: 0.9725\n",
      "val loss: 0.0336, acc: 0.6443\n",
      "Epoch 19/150\n",
      "train loss: 0.0022, acc: 0.9520\n",
      "val loss: 0.0264, acc: 0.6618\n",
      "Epoch 20/150\n",
      "train loss: 0.0009, acc: 0.9828\n",
      "val loss: 0.0306, acc: 0.6443\n",
      "Epoch 21/150\n",
      "train loss: 0.0002, acc: 0.9963\n",
      "val loss: 0.0338, acc: 0.6385\n",
      "Epoch 22/150\n",
      "train loss: 0.0001, acc: 0.9982\n",
      "val loss: 0.0339, acc: 0.6501\n",
      "Epoch 23/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0359, acc: 0.6385\n",
      "Epoch 24/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6297\n",
      "Epoch 25/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6297\n",
      "Epoch 26/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0377, acc: 0.6297\n",
      "Epoch 27/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0378, acc: 0.6268\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0381, acc: 0.6268\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0382, acc: 0.6297\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0384, acc: 0.6327\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6297\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6327\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0386, acc: 0.6297\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0388, acc: 0.6327\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0389, acc: 0.6239\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0391, acc: 0.6239\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0391, acc: 0.6268\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0392, acc: 0.6268\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0391, acc: 0.6327\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0392, acc: 0.6239\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0391, acc: 0.6268\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0391, acc: 0.6268\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0392, acc: 0.6268\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0391, acc: 0.6297\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0390, acc: 0.6268\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0388, acc: 0.6297\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0389, acc: 0.6268\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0387, acc: 0.6297\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0389, acc: 0.6268\n",
      "Epoch 50/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0388, acc: 0.6268\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0387, acc: 0.6297\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0386, acc: 0.6327\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6356\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0386, acc: 0.6356\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0386, acc: 0.6327\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6356\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6356\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0384, acc: 0.6385\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0383, acc: 0.6356\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0383, acc: 0.6356\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0383, acc: 0.6356\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0382, acc: 0.6356\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0381, acc: 0.6356\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0380, acc: 0.6356\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0379, acc: 0.6385\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0379, acc: 0.6385\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0380, acc: 0.6327\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0378, acc: 0.6356\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0377, acc: 0.6356\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0377, acc: 0.6327\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0377, acc: 0.6327\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0376, acc: 0.6327\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0375, acc: 0.6327\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0377, acc: 0.6327\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0376, acc: 0.6327\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6327\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0375, acc: 0.6327\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0375, acc: 0.6327\n",
      "Epoch 79/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6327\n",
      "Epoch 80/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0373, acc: 0.6327\n",
      "Epoch 81/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6327\n",
      "Epoch 82/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0373, acc: 0.6297\n",
      "Epoch 83/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6297\n",
      "Epoch 84/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6327\n",
      "Epoch 85/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0370, acc: 0.6327\n",
      "Epoch 86/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6356\n",
      "Epoch 87/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6297\n",
      "Epoch 88/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0373, acc: 0.6327\n",
      "Epoch 89/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6297\n",
      "Epoch 90/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6327\n",
      "Epoch 91/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0370, acc: 0.6297\n",
      "Epoch 92/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6297\n",
      "Epoch 93/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6327\n",
      "Epoch 94/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6327\n",
      "Epoch 95/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0370, acc: 0.6297\n",
      "Epoch 96/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6297\n",
      "Epoch 97/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6297\n",
      "Epoch 98/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6268\n",
      "Epoch 99/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6268\n",
      "Epoch 100/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6297\n",
      "Epoch 101/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6297\n",
      "Epoch 102/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6268\n",
      "Epoch 103/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6268\n",
      "Epoch 104/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6297\n",
      "Epoch 105/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6268\n",
      "Epoch 106/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0370, acc: 0.6297\n",
      "Epoch 107/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0370, acc: 0.6297\n",
      "Epoch 108/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0370, acc: 0.6297\n",
      "Epoch 109/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6356\n",
      "Epoch 110/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6327\n",
      "Epoch 111/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6414\n",
      "Epoch 112/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6327\n",
      "Epoch 113/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0373, acc: 0.6327\n",
      "Epoch 114/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0370, acc: 0.6239\n",
      "Epoch 115/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6268\n",
      "Epoch 116/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6297\n",
      "Epoch 117/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6356\n",
      "Epoch 118/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0375, acc: 0.6385\n",
      "Epoch 119/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6356\n",
      "Epoch 120/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0377, acc: 0.6385\n",
      "Epoch 121/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0378, acc: 0.6385\n",
      "Epoch 122/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0375, acc: 0.6327\n",
      "Epoch 123/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0379, acc: 0.6443\n",
      "Epoch 124/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0376, acc: 0.6152\n",
      "Epoch 125/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0376, acc: 0.6268\n",
      "Epoch 126/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0377, acc: 0.6385\n",
      "Epoch 127/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0379, acc: 0.6297\n",
      "Epoch 128/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0381, acc: 0.6327\n",
      "Epoch 129/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0382, acc: 0.6327\n",
      "Epoch 130/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0386, acc: 0.6327\n",
      "Epoch 131/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6268\n",
      "Epoch 132/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6239\n",
      "Epoch 133/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0381, acc: 0.6268\n",
      "Epoch 134/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6327\n",
      "Epoch 135/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0387, acc: 0.6385\n",
      "Epoch 136/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0388, acc: 0.6356\n",
      "Epoch 137/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0384, acc: 0.6414\n",
      "Epoch 138/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0382, acc: 0.6297\n",
      "Epoch 139/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0381, acc: 0.6414\n",
      "Epoch 140/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6414\n",
      "Epoch 141/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0384, acc: 0.6327\n",
      "Epoch 142/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0376, acc: 0.6472\n",
      "Epoch 143/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0376, acc: 0.6385\n",
      "Epoch 144/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6327\n",
      "Epoch 145/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0387, acc: 0.6385\n",
      "Epoch 146/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0382, acc: 0.6297\n",
      "Epoch 147/150\n",
      "train loss: 0.0325, acc: 0.7194\n",
      "val loss: 0.0201, acc: 0.5102\n",
      "Epoch 148/150\n",
      "train loss: 0.0135, acc: 0.5260\n",
      "val loss: 0.0120, acc: 0.5510\n",
      "Epoch 149/150\n",
      "train loss: 0.0108, acc: 0.5736\n",
      "val loss: 0.0125, acc: 0.5190\n",
      "Epoch 150/150\n",
      "train loss: 0.0109, acc: 0.5784\n",
      "val loss: 0.0119, acc: 0.5831\n",
      "Training complete in 5m 14s\n",
      "Best val Acc: 0.661808\n",
      "Best Epoch : 19\n",
      "Test Accuracy : 0.66\n",
      "                              Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)            1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)           0.993773  0.667638      0.68    125\n",
      "C[1, 16, 8]_K(3, 40)           0.889744  0.667638      0.70    128\n",
      "C[1, 32, 16, 8]_K(3, 8)        0.955311  0.688047      0.78     14\n",
      "C[1, 32, 16, 8]_K(3, 24)       0.915385  0.664723      0.76     13\n",
      "C[1, 32, 16, 8]_K(3, 40)       0.952015  0.661808      0.66     19\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)    0.899267  0.705539      0.76    134\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)   0.999634  0.685131      0.80    145\n",
      "\n",
      "\n",
      "##### C[1, 64, 32, 16, 8]_K(3, 8) #####\n",
      "Input shape : torch.Size([1, 64, 22, 90]) and flattened : 126720\n",
      "Input shape : torch.Size([1, 32, 22, 45]) and flattened : 31680\n",
      "Input shape : torch.Size([1, 16, 22, 23]) and flattened : 8096\n",
      "Input shape : torch.Size([1, 8, 22, 12]) and flattened : 2112\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 8)_O64): Conv2d(1, 64, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O32): Conv2d(64, 32, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O16): Conv2d(32, 16, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O8): Conv2d(16, 8, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (fc1): Linear(in_features=2112, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0144, acc: 0.5363\n",
      "val loss: 0.0126, acc: 0.5335\n",
      "Epoch 2/150\n",
      "train loss: 0.0108, acc: 0.5799\n",
      "val loss: 0.0115, acc: 0.5948\n",
      "Epoch 3/150\n",
      "train loss: 0.0095, acc: 0.6773\n",
      "val loss: 0.0120, acc: 0.6210\n",
      "Epoch 4/150\n",
      "train loss: 0.0079, acc: 0.7440\n",
      "val loss: 0.0121, acc: 0.6210\n",
      "Epoch 5/150\n",
      "train loss: 0.0070, acc: 0.7857\n",
      "val loss: 0.0113, acc: 0.6472\n",
      "Epoch 6/150\n",
      "train loss: 0.0069, acc: 0.8044\n",
      "val loss: 0.0134, acc: 0.6181\n",
      "Epoch 7/150\n",
      "train loss: 0.0049, acc: 0.8670\n",
      "val loss: 0.0150, acc: 0.6064\n",
      "Epoch 8/150\n",
      "train loss: 0.0044, acc: 0.8802\n",
      "val loss: 0.0187, acc: 0.6268\n",
      "Epoch 9/150\n",
      "train loss: 0.0023, acc: 0.9513\n",
      "val loss: 0.0192, acc: 0.6385\n",
      "Epoch 10/150\n",
      "train loss: 0.0014, acc: 0.9692\n",
      "val loss: 0.0216, acc: 0.6327\n",
      "Epoch 11/150\n",
      "train loss: 0.0007, acc: 0.9868\n",
      "val loss: 0.0236, acc: 0.6589\n",
      "Epoch 12/150\n",
      "train loss: 0.0005, acc: 0.9894\n",
      "val loss: 0.0263, acc: 0.6210\n",
      "Epoch 13/150\n",
      "train loss: 0.0004, acc: 0.9905\n",
      "val loss: 0.0303, acc: 0.6356\n",
      "Epoch 14/150\n",
      "train loss: 0.0004, acc: 0.9927\n",
      "val loss: 0.0312, acc: 0.6268\n",
      "Epoch 15/150\n",
      "train loss: 0.0003, acc: 0.9960\n",
      "val loss: 0.0306, acc: 0.6268\n",
      "Epoch 16/150\n",
      "train loss: 0.0003, acc: 0.9938\n",
      "val loss: 0.0368, acc: 0.5977\n",
      "Epoch 17/150\n",
      "train loss: 0.0001, acc: 0.9982\n",
      "val loss: 0.0347, acc: 0.6181\n",
      "Epoch 18/150\n",
      "train loss: 0.0001, acc: 0.9996\n",
      "val loss: 0.0362, acc: 0.6152\n",
      "Epoch 19/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0361, acc: 0.6210\n",
      "Epoch 20/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6239\n",
      "Epoch 21/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6239\n",
      "Epoch 22/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6210\n",
      "Epoch 23/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6210\n",
      "Epoch 24/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6239\n",
      "Epoch 25/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0373, acc: 0.6239\n",
      "Epoch 26/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6152\n",
      "Epoch 27/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6181\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0373, acc: 0.6181\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0373, acc: 0.6268\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6181\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6210\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6152\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0373, acc: 0.6181\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0373, acc: 0.6152\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6181\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6210\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6181\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6268\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6210\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6181\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6239\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6239\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0367, acc: 0.6181\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0366, acc: 0.6210\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6297\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.6181\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0361, acc: 0.6297\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0361, acc: 0.6152\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0361, acc: 0.6239\n",
      "Epoch 50/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0360, acc: 0.6210\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0358, acc: 0.6239\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0357, acc: 0.6268\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0357, acc: 0.6268\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0356, acc: 0.6268\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.6297\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0354, acc: 0.6268\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0353, acc: 0.6268\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0352, acc: 0.6297\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0350, acc: 0.6268\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0349, acc: 0.6268\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0348, acc: 0.6297\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0348, acc: 0.6297\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0348, acc: 0.6268\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0347, acc: 0.6297\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.6297\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.6210\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0344, acc: 0.6239\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0342, acc: 0.6210\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0343, acc: 0.6268\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0341, acc: 0.6181\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0339, acc: 0.6210\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0339, acc: 0.6239\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0338, acc: 0.6239\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0338, acc: 0.6210\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0336, acc: 0.6181\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0335, acc: 0.6210\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0335, acc: 0.6297\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0333, acc: 0.6210\n",
      "Epoch 79/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0333, acc: 0.6327\n",
      "Epoch 80/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0333, acc: 0.6297\n",
      "Epoch 81/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0333, acc: 0.6297\n",
      "Epoch 82/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0330, acc: 0.6268\n",
      "Epoch 83/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0330, acc: 0.6181\n",
      "Epoch 84/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.6268\n",
      "Epoch 85/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0331, acc: 0.6268\n",
      "Epoch 86/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0329, acc: 0.6181\n",
      "Epoch 87/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0329, acc: 0.6385\n",
      "Epoch 88/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6327\n",
      "Epoch 89/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.6268\n",
      "Epoch 90/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6297\n",
      "Epoch 91/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0329, acc: 0.6327\n",
      "Epoch 92/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6297\n",
      "Epoch 93/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6356\n",
      "Epoch 94/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6268\n",
      "Epoch 95/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.6297\n",
      "Epoch 96/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6268\n",
      "Epoch 97/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6210\n",
      "Epoch 98/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6443\n",
      "Epoch 99/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6443\n",
      "Epoch 100/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6327\n",
      "Epoch 101/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6385\n",
      "Epoch 102/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0323, acc: 0.6385\n",
      "Epoch 103/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6327\n",
      "Epoch 104/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6385\n",
      "Epoch 105/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6385\n",
      "Epoch 106/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6297\n",
      "Epoch 107/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6297\n",
      "Epoch 108/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0323, acc: 0.6443\n",
      "Epoch 109/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6443\n",
      "Epoch 110/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6356\n",
      "Epoch 111/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6356\n",
      "Epoch 112/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.6327\n",
      "Epoch 113/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0322, acc: 0.6443\n",
      "Epoch 114/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0321, acc: 0.6443\n",
      "Epoch 115/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6443\n",
      "Epoch 116/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6414\n",
      "Epoch 117/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.6356\n",
      "Epoch 118/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6268\n",
      "Epoch 119/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0332, acc: 0.6327\n",
      "Epoch 120/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.6501\n",
      "Epoch 121/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0329, acc: 0.6443\n",
      "Epoch 122/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6356\n",
      "Epoch 123/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6356\n",
      "Epoch 124/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6472\n",
      "Epoch 125/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6414\n",
      "Epoch 126/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0318, acc: 0.6618\n",
      "Epoch 127/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0323, acc: 0.6472\n",
      "Epoch 128/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0337, acc: 0.6443\n",
      "Epoch 129/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0339, acc: 0.6297\n",
      "Epoch 130/150\n",
      "train loss: 0.0456, acc: 0.7088\n",
      "val loss: 0.0178, acc: 0.4898\n",
      "Epoch 131/150\n",
      "train loss: 0.0132, acc: 0.5062\n",
      "val loss: 0.0122, acc: 0.5627\n",
      "Epoch 132/150\n",
      "train loss: 0.0114, acc: 0.5388\n",
      "val loss: 0.0127, acc: 0.5539\n",
      "Epoch 133/150\n",
      "train loss: 0.0112, acc: 0.5454\n",
      "val loss: 0.0121, acc: 0.5569\n",
      "Epoch 134/150\n",
      "train loss: 0.0109, acc: 0.5659\n",
      "val loss: 0.0120, acc: 0.5656\n",
      "Epoch 135/150\n",
      "train loss: 0.0104, acc: 0.6103\n",
      "val loss: 0.0118, acc: 0.5656\n",
      "Epoch 136/150\n",
      "train loss: 0.0104, acc: 0.6066\n",
      "val loss: 0.0117, acc: 0.6064\n",
      "Epoch 137/150\n",
      "train loss: 0.0100, acc: 0.6399\n",
      "val loss: 0.0143, acc: 0.5539\n",
      "Epoch 138/150\n",
      "train loss: 0.0099, acc: 0.6509\n",
      "val loss: 0.0117, acc: 0.6443\n",
      "Epoch 139/150\n",
      "train loss: 0.0093, acc: 0.6842\n",
      "val loss: 0.0119, acc: 0.5977\n",
      "Epoch 140/150\n",
      "train loss: 0.0090, acc: 0.6993\n",
      "val loss: 0.0116, acc: 0.6560\n",
      "Epoch 141/150\n",
      "train loss: 0.0090, acc: 0.7000\n",
      "val loss: 0.0127, acc: 0.6268\n",
      "Epoch 142/150\n",
      "train loss: 0.0092, acc: 0.6974\n",
      "val loss: 0.0114, acc: 0.6356\n",
      "Epoch 143/150\n",
      "train loss: 0.0084, acc: 0.7381\n",
      "val loss: 0.0115, acc: 0.6531\n",
      "Epoch 144/150\n",
      "train loss: 0.0082, acc: 0.7476\n",
      "val loss: 0.0123, acc: 0.6356\n",
      "Epoch 145/150\n",
      "train loss: 0.0078, acc: 0.7458\n",
      "val loss: 0.0117, acc: 0.6735\n",
      "Epoch 146/150\n",
      "train loss: 0.0074, acc: 0.7780\n",
      "val loss: 0.0121, acc: 0.6443\n",
      "Epoch 147/150\n",
      "train loss: 0.0070, acc: 0.8051\n",
      "val loss: 0.0128, acc: 0.6735\n",
      "Epoch 148/150\n",
      "train loss: 0.0065, acc: 0.8158\n",
      "val loss: 0.0153, acc: 0.6472\n",
      "Epoch 149/150\n",
      "train loss: 0.0058, acc: 0.8264\n",
      "val loss: 0.0146, acc: 0.6385\n",
      "Epoch 150/150\n",
      "train loss: 0.0051, acc: 0.8634\n",
      "val loss: 0.0133, acc: 0.6764\n",
      "Training complete in 2m 54s\n",
      "Best val Acc: 0.676385\n",
      "Best Epoch : 150\n",
      "Test Accuracy : 0.72\n",
      "                              Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)            1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)           0.993773  0.667638      0.68    125\n",
      "C[1, 16, 8]_K(3, 40)           0.889744  0.667638      0.70    128\n",
      "C[1, 32, 16, 8]_K(3, 8)        0.955311  0.688047      0.78     14\n",
      "C[1, 32, 16, 8]_K(3, 24)       0.915385  0.664723      0.76     13\n",
      "C[1, 32, 16, 8]_K(3, 40)       0.952015  0.661808      0.66     19\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)    0.863370  0.676385      0.72    150\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)   0.999634  0.685131      0.80    145\n",
      "\n",
      "\n",
      "##### C[1, 64, 32, 16, 8]_K(3, 24) #####\n",
      "Input shape : torch.Size([1, 64, 22, 90]) and flattened : 126720\n",
      "Input shape : torch.Size([1, 32, 22, 45]) and flattened : 31680\n",
      "Input shape : torch.Size([1, 16, 22, 23]) and flattened : 8096\n",
      "Input shape : torch.Size([1, 8, 22, 12]) and flattened : 2112\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 24)_O64): Conv2d(1, 64, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O32): Conv2d(64, 32, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O16): Conv2d(32, 16, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O8): Conv2d(16, 8, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (fc1): Linear(in_features=2112, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n",
      "train loss: 0.0168, acc: 0.5110\n",
      "val loss: 0.0121, acc: 0.5452\n",
      "Epoch 2/150\n",
      "train loss: 0.0116, acc: 0.5366\n",
      "val loss: 0.0120, acc: 0.5656\n",
      "Epoch 3/150\n",
      "train loss: 0.0109, acc: 0.5509\n",
      "val loss: 0.0119, acc: 0.5714\n",
      "Epoch 4/150\n",
      "train loss: 0.0105, acc: 0.5912\n",
      "val loss: 0.0119, acc: 0.6268\n",
      "Epoch 5/150\n",
      "train loss: 0.0097, acc: 0.6524\n",
      "val loss: 0.0111, acc: 0.6239\n",
      "Epoch 6/150\n",
      "train loss: 0.0087, acc: 0.7154\n",
      "val loss: 0.0107, acc: 0.6531\n",
      "Epoch 7/150\n",
      "train loss: 0.0082, acc: 0.7352\n",
      "val loss: 0.0105, acc: 0.6531\n",
      "Epoch 8/150\n",
      "train loss: 0.0075, acc: 0.7747\n",
      "val loss: 0.0114, acc: 0.6443\n",
      "Epoch 9/150\n",
      "train loss: 0.0065, acc: 0.8103\n",
      "val loss: 0.0115, acc: 0.6647\n",
      "Epoch 10/150\n",
      "train loss: 0.0054, acc: 0.8527\n",
      "val loss: 0.0211, acc: 0.5918\n",
      "Epoch 11/150\n",
      "train loss: 0.0050, acc: 0.8648\n",
      "val loss: 0.0158, acc: 0.6880\n",
      "Epoch 12/150\n",
      "train loss: 0.0026, acc: 0.9370\n",
      "val loss: 0.0244, acc: 0.6764\n",
      "Epoch 13/150\n",
      "train loss: 0.0023, acc: 0.9436\n",
      "val loss: 0.0223, acc: 0.6880\n",
      "Epoch 14/150\n",
      "train loss: 0.0014, acc: 0.9656\n",
      "val loss: 0.0220, acc: 0.7055\n",
      "Epoch 15/150\n",
      "train loss: 0.0008, acc: 0.9810\n",
      "val loss: 0.0261, acc: 0.7114\n",
      "Epoch 16/150\n",
      "train loss: 0.0006, acc: 0.9864\n",
      "val loss: 0.0311, acc: 0.7055\n",
      "Epoch 17/150\n",
      "train loss: 0.0005, acc: 0.9864\n",
      "val loss: 0.0368, acc: 0.6501\n",
      "Epoch 18/150\n",
      "train loss: 0.0002, acc: 0.9963\n",
      "val loss: 0.0359, acc: 0.6997\n",
      "Epoch 19/150\n",
      "train loss: 0.0001, acc: 0.9978\n",
      "val loss: 0.0381, acc: 0.7085\n",
      "Epoch 20/150\n",
      "train loss: 0.0002, acc: 0.9956\n",
      "val loss: 0.0332, acc: 0.6880\n",
      "Epoch 21/150\n",
      "train loss: 0.0003, acc: 0.9934\n",
      "val loss: 0.0353, acc: 0.7143\n",
      "Epoch 22/150\n",
      "train loss: 0.0006, acc: 0.9864\n",
      "val loss: 0.0423, acc: 0.6706\n",
      "Epoch 23/150\n",
      "train loss: 0.0024, acc: 0.9447\n",
      "val loss: 0.0254, acc: 0.6735\n",
      "Epoch 24/150\n",
      "train loss: 0.0008, acc: 0.9821\n",
      "val loss: 0.0318, acc: 0.6880\n",
      "Epoch 25/150\n",
      "train loss: 0.0002, acc: 0.9934\n",
      "val loss: 0.0360, acc: 0.6851\n",
      "Epoch 26/150\n",
      "train loss: 0.0001, acc: 0.9989\n",
      "val loss: 0.0339, acc: 0.7201\n",
      "Epoch 27/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.7085\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0340, acc: 0.7114\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0344, acc: 0.7085\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.7085\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0348, acc: 0.7026\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0350, acc: 0.6997\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0352, acc: 0.7026\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0353, acc: 0.6997\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0354, acc: 0.6997\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.7026\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.7026\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.7026\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.7026\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.7055\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.6997\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0356, acc: 0.7026\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0356, acc: 0.7085\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0357, acc: 0.7085\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0356, acc: 0.7114\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.7114\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.7085\n",
      "Epoch 48/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0354, acc: 0.7114\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0354, acc: 0.7143\n",
      "Epoch 50/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.7143\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0354, acc: 0.7114\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0353, acc: 0.7114\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0353, acc: 0.7201\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0352, acc: 0.7143\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0351, acc: 0.7172\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0351, acc: 0.7172\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0350, acc: 0.7172\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0349, acc: 0.7201\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0348, acc: 0.7114\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0347, acc: 0.7172\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.7172\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.7172\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0345, acc: 0.7143\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0345, acc: 0.7172\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0344, acc: 0.7114\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0343, acc: 0.7085\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0343, acc: 0.7114\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0342, acc: 0.7230\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0342, acc: 0.7172\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0341, acc: 0.7172\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0340, acc: 0.7201\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0339, acc: 0.7201\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0339, acc: 0.7143\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0337, acc: 0.7172\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0338, acc: 0.7143\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0336, acc: 0.7172\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0335, acc: 0.7172\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0335, acc: 0.7143\n",
      "Epoch 79/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0334, acc: 0.7143\n",
      "Epoch 80/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0333, acc: 0.7143\n",
      "Epoch 81/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0332, acc: 0.7114\n",
      "Epoch 82/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0331, acc: 0.7172\n",
      "Epoch 83/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0332, acc: 0.7143\n",
      "Epoch 84/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0333, acc: 0.7085\n",
      "Epoch 85/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0330, acc: 0.7172\n",
      "Epoch 86/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0331, acc: 0.7143\n",
      "Epoch 87/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0330, acc: 0.7143\n",
      "Epoch 88/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0331, acc: 0.7055\n",
      "Epoch 89/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0330, acc: 0.7085\n",
      "Epoch 90/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0329, acc: 0.7143\n",
      "Epoch 91/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.7172\n",
      "Epoch 92/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.7085\n",
      "Epoch 93/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.7085\n",
      "Epoch 94/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.7055\n",
      "Epoch 95/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.7114\n",
      "Epoch 96/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.7026\n",
      "Epoch 97/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.7172\n",
      "Epoch 98/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.7085\n",
      "Epoch 99/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.7026\n",
      "Epoch 100/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6997\n",
      "Epoch 101/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0323, acc: 0.7114\n",
      "Epoch 102/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0323, acc: 0.7143\n",
      "Epoch 103/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.7055\n",
      "Epoch 104/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0324, acc: 0.6939\n",
      "Epoch 105/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0323, acc: 0.7055\n",
      "Epoch 106/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6997\n",
      "Epoch 107/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6997\n",
      "Epoch 108/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6997\n",
      "Epoch 109/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.7026\n",
      "Epoch 110/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.7026\n",
      "Epoch 111/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.7026\n",
      "Epoch 112/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6968\n",
      "Epoch 113/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6968\n",
      "Epoch 114/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.7026\n",
      "Epoch 115/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.7026\n",
      "Epoch 116/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.7026\n",
      "Epoch 117/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0327, acc: 0.6910\n",
      "Epoch 118/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0330, acc: 0.6997\n",
      "Epoch 119/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0326, acc: 0.6910\n",
      "Epoch 120/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0331, acc: 0.6968\n",
      "Epoch 121/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0325, acc: 0.6910\n",
      "Epoch 122/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0331, acc: 0.6880\n",
      "Epoch 123/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0332, acc: 0.6910\n",
      "Epoch 124/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.6939\n",
      "Epoch 125/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0338, acc: 0.6793\n",
      "Epoch 126/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0329, acc: 0.6793\n",
      "Epoch 127/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0332, acc: 0.6735\n",
      "Epoch 128/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.6822\n",
      "Epoch 129/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0332, acc: 0.6851\n",
      "Epoch 130/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0328, acc: 0.6793\n",
      "Epoch 131/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0347, acc: 0.6706\n",
      "Epoch 132/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0330, acc: 0.6589\n",
      "Epoch 133/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.6822\n",
      "Epoch 134/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0349, acc: 0.6764\n",
      "Epoch 135/150\n",
      "train loss: 0.0102, acc: 0.9707\n",
      "val loss: 0.0919, acc: 0.5102\n",
      "Epoch 136/150\n",
      "train loss: 0.0185, acc: 0.5022\n",
      "val loss: 0.0123, acc: 0.5131\n",
      "Epoch 137/150\n",
      "train loss: 0.0115, acc: 0.5220\n",
      "val loss: 0.0122, acc: 0.5277\n",
      "Epoch 138/150\n",
      "train loss: 0.0111, acc: 0.5227\n",
      "val loss: 0.0122, acc: 0.5219\n",
      "Epoch 139/150\n",
      "train loss: 0.0112, acc: 0.5359\n",
      "val loss: 0.0125, acc: 0.5160\n",
      "Epoch 140/150\n",
      "train loss: 0.0110, acc: 0.5322\n",
      "val loss: 0.0120, acc: 0.5364\n",
      "Epoch 141/150\n",
      "train loss: 0.0108, acc: 0.5458\n",
      "val loss: 0.0119, acc: 0.5802\n",
      "Epoch 142/150\n",
      "train loss: 0.0108, acc: 0.5744\n",
      "val loss: 0.0118, acc: 0.5598\n",
      "Epoch 143/150\n",
      "train loss: 0.0104, acc: 0.5853\n",
      "val loss: 0.0114, acc: 0.6064\n",
      "Epoch 144/150\n",
      "train loss: 0.0098, acc: 0.6516\n",
      "val loss: 0.0117, acc: 0.5977\n",
      "Epoch 145/150\n",
      "train loss: 0.0091, acc: 0.6890\n",
      "val loss: 0.0113, acc: 0.6356\n",
      "Epoch 146/150\n",
      "train loss: 0.0085, acc: 0.7267\n",
      "val loss: 0.0112, acc: 0.6385\n",
      "Epoch 147/150\n",
      "train loss: 0.0080, acc: 0.7403\n",
      "val loss: 0.0105, acc: 0.6414\n",
      "Epoch 148/150\n",
      "train loss: 0.0074, acc: 0.7799\n",
      "val loss: 0.0124, acc: 0.6589\n",
      "Epoch 149/150\n",
      "train loss: 0.0069, acc: 0.8018\n",
      "val loss: 0.0128, acc: 0.6297\n",
      "Epoch 150/150\n",
      "train loss: 0.0062, acc: 0.8256\n",
      "val loss: 0.0114, acc: 0.6764\n",
      "Training complete in 6m 39s\n",
      "Best val Acc: 0.723032\n",
      "Best Epoch : 68\n",
      "Test Accuracy : 0.71\n",
      "                              Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)            1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)           0.993773  0.667638      0.68    125\n",
      "C[1, 16, 8]_K(3, 40)           0.889744  0.667638      0.70    128\n",
      "C[1, 32, 16, 8]_K(3, 8)        0.955311  0.688047      0.78     14\n",
      "C[1, 32, 16, 8]_K(3, 24)       0.915385  0.664723      0.76     13\n",
      "C[1, 32, 16, 8]_K(3, 40)       0.952015  0.661808      0.66     19\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)    0.863370  0.676385      0.72    150\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)   1.000000  0.723032      0.71     68\n",
      "\n",
      "\n",
      "##### C[1, 64, 32, 16, 8]_K(3, 40) #####\n",
      "Input shape : torch.Size([1, 64, 22, 90]) and flattened : 126720\n",
      "Input shape : torch.Size([1, 32, 22, 45]) and flattened : 31680\n",
      "Input shape : torch.Size([1, 16, 22, 23]) and flattened : 8096\n",
      "Input shape : torch.Size([1, 8, 22, 12]) and flattened : 2112\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 40)_O64): Conv2d(1, 64, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O32): Conv2d(64, 32, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O16): Conv2d(32, 16, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O8): Conv2d(16, 8, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (fc1): Linear(in_features=2112, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0138, acc: 0.5117\n",
      "val loss: 0.0126, acc: 0.4927\n",
      "Epoch 2/150\n",
      "train loss: 0.0118, acc: 0.5216\n",
      "val loss: 0.0132, acc: 0.5131\n",
      "Epoch 3/150\n",
      "train loss: 0.0109, acc: 0.5557\n",
      "val loss: 0.0118, acc: 0.5714\n",
      "Epoch 4/150\n",
      "train loss: 0.0100, acc: 0.6275\n",
      "val loss: 0.0111, acc: 0.6385\n",
      "Epoch 5/150\n",
      "train loss: 0.0092, acc: 0.6714\n",
      "val loss: 0.0112, acc: 0.6880\n",
      "Epoch 6/150\n",
      "train loss: 0.0084, acc: 0.7190\n",
      "val loss: 0.0108, acc: 0.6706\n",
      "Epoch 7/150\n",
      "train loss: 0.0079, acc: 0.7557\n",
      "val loss: 0.0111, acc: 0.6647\n",
      "Epoch 8/150\n",
      "train loss: 0.0068, acc: 0.8114\n",
      "val loss: 0.0125, acc: 0.6647\n",
      "Epoch 9/150\n",
      "train loss: 0.0057, acc: 0.8447\n",
      "val loss: 0.0120, acc: 0.6793\n",
      "Epoch 10/150\n",
      "train loss: 0.0044, acc: 0.8875\n",
      "val loss: 0.0163, acc: 0.6618\n",
      "Epoch 11/150\n",
      "train loss: 0.0033, acc: 0.9117\n",
      "val loss: 0.0248, acc: 0.6385\n",
      "Epoch 12/150\n",
      "train loss: 0.0018, acc: 0.9549\n",
      "val loss: 0.0250, acc: 0.6822\n",
      "Epoch 13/150\n",
      "train loss: 0.0008, acc: 0.9832\n",
      "val loss: 0.0294, acc: 0.6501\n",
      "Epoch 14/150\n",
      "train loss: 0.0005, acc: 0.9890\n",
      "val loss: 0.0357, acc: 0.6297\n",
      "Epoch 15/150\n",
      "train loss: 0.0003, acc: 0.9945\n",
      "val loss: 0.0406, acc: 0.6327\n",
      "Epoch 16/150\n",
      "train loss: 0.0007, acc: 0.9828\n",
      "val loss: 0.0364, acc: 0.6472\n",
      "Epoch 17/150\n",
      "train loss: 0.0013, acc: 0.9685\n",
      "val loss: 0.0327, acc: 0.6210\n",
      "Epoch 18/150\n",
      "train loss: 0.0010, acc: 0.9799\n",
      "val loss: 0.0417, acc: 0.6327\n",
      "Epoch 19/150\n",
      "train loss: 0.0005, acc: 0.9894\n",
      "val loss: 0.0413, acc: 0.6618\n",
      "Epoch 20/150\n",
      "train loss: 0.0003, acc: 0.9934\n",
      "val loss: 0.0454, acc: 0.6501\n",
      "Epoch 21/150\n",
      "train loss: 0.0001, acc: 0.9967\n",
      "val loss: 0.0449, acc: 0.6239\n",
      "Epoch 22/150\n",
      "train loss: 0.0001, acc: 0.9971\n",
      "val loss: 0.0497, acc: 0.6268\n",
      "Epoch 23/150\n",
      "train loss: 0.0001, acc: 0.9967\n",
      "val loss: 0.0459, acc: 0.6327\n",
      "Epoch 24/150\n",
      "train loss: 0.0000, acc: 0.9996\n",
      "val loss: 0.0499, acc: 0.6268\n",
      "Epoch 25/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0536, acc: 0.6443\n",
      "Epoch 26/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0539, acc: 0.6385\n",
      "Epoch 27/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0537, acc: 0.6327\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0537, acc: 0.6327\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0538, acc: 0.6327\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0537, acc: 0.6327\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0535, acc: 0.6385\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0535, acc: 0.6327\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0533, acc: 0.6414\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0532, acc: 0.6385\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0530, acc: 0.6385\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0528, acc: 0.6414\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0526, acc: 0.6356\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0526, acc: 0.6385\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0524, acc: 0.6443\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0523, acc: 0.6385\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0520, acc: 0.6443\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0518, acc: 0.6414\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0517, acc: 0.6443\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0515, acc: 0.6414\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0513, acc: 0.6443\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0510, acc: 0.6443\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0508, acc: 0.6443\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0505, acc: 0.6443\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0503, acc: 0.6414\n",
      "Epoch 50/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0502, acc: 0.6414\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0500, acc: 0.6385\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0498, acc: 0.6414\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0496, acc: 0.6443\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0493, acc: 0.6443\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0491, acc: 0.6414\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0490, acc: 0.6443\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0487, acc: 0.6414\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0487, acc: 0.6443\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0485, acc: 0.6385\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0483, acc: 0.6385\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0480, acc: 0.6356\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0479, acc: 0.6356\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0478, acc: 0.6356\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0476, acc: 0.6327\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.6385\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0472, acc: 0.6356\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0469, acc: 0.6385\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0468, acc: 0.6414\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0464, acc: 0.6414\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0464, acc: 0.6385\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0463, acc: 0.6356\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0460, acc: 0.6356\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0461, acc: 0.6356\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6414\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0456, acc: 0.6414\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6356\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0452, acc: 0.6414\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0452, acc: 0.6414\n",
      "Epoch 79/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0450, acc: 0.6385\n",
      "Epoch 80/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0449, acc: 0.6443\n",
      "Epoch 81/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0448, acc: 0.6472\n",
      "Epoch 82/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0448, acc: 0.6414\n",
      "Epoch 83/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0446, acc: 0.6443\n",
      "Epoch 84/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0445, acc: 0.6443\n",
      "Epoch 85/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0444, acc: 0.6443\n",
      "Epoch 86/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0441, acc: 0.6414\n",
      "Epoch 87/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0441, acc: 0.6443\n",
      "Epoch 88/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0438, acc: 0.6414\n",
      "Epoch 89/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0438, acc: 0.6385\n",
      "Epoch 90/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0435, acc: 0.6385\n",
      "Epoch 91/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0436, acc: 0.6385\n",
      "Epoch 92/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0433, acc: 0.6414\n",
      "Epoch 93/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0437, acc: 0.6356\n",
      "Epoch 94/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0431, acc: 0.6327\n",
      "Epoch 95/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0431, acc: 0.6414\n",
      "Epoch 96/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0429, acc: 0.6356\n",
      "Epoch 97/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0430, acc: 0.6327\n",
      "Epoch 98/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0429, acc: 0.6327\n",
      "Epoch 99/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0427, acc: 0.6327\n",
      "Epoch 100/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6327\n",
      "Epoch 101/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6327\n",
      "Epoch 102/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6385\n",
      "Epoch 103/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0421, acc: 0.6297\n",
      "Epoch 104/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0421, acc: 0.6356\n",
      "Epoch 105/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0422, acc: 0.6356\n",
      "Epoch 106/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0420, acc: 0.6327\n",
      "Epoch 107/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0417, acc: 0.6356\n",
      "Epoch 108/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0415, acc: 0.6327\n",
      "Epoch 109/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0414, acc: 0.6327\n",
      "Epoch 110/150\n",
      "train loss: 0.0000, acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.0421, acc: 0.6268\n",
      "Epoch 111/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0418, acc: 0.6297\n",
      "Epoch 112/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0415, acc: 0.6268\n",
      "Epoch 113/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0411, acc: 0.6297\n",
      "Epoch 114/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0409, acc: 0.6239\n",
      "Epoch 115/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0411, acc: 0.6356\n",
      "Epoch 116/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6239\n",
      "Epoch 117/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0426, acc: 0.6327\n",
      "Epoch 118/150\n",
      "train loss: 0.0167, acc: 0.6791\n",
      "val loss: 0.0137, acc: 0.5743\n",
      "Epoch 119/150\n",
      "train loss: 0.0106, acc: 0.6403\n",
      "val loss: 0.0118, acc: 0.6764\n",
      "Epoch 120/150\n",
      "train loss: 0.0091, acc: 0.6927\n",
      "val loss: 0.0111, acc: 0.6618\n",
      "Epoch 121/150\n",
      "train loss: 0.0089, acc: 0.7106\n",
      "val loss: 0.0107, acc: 0.6589\n",
      "Epoch 122/150\n",
      "train loss: 0.0088, acc: 0.7066\n",
      "val loss: 0.0107, acc: 0.6997\n",
      "Epoch 123/150\n",
      "train loss: 0.0083, acc: 0.7264\n",
      "val loss: 0.0105, acc: 0.6939\n",
      "Epoch 124/150\n",
      "train loss: 0.0079, acc: 0.7520\n",
      "val loss: 0.0128, acc: 0.6297\n",
      "Epoch 125/150\n",
      "train loss: 0.0076, acc: 0.7703\n",
      "val loss: 0.0108, acc: 0.6735\n",
      "Epoch 126/150\n",
      "train loss: 0.0070, acc: 0.7905\n",
      "val loss: 0.0112, acc: 0.6939\n",
      "Epoch 127/150\n",
      "train loss: 0.0062, acc: 0.8286\n",
      "val loss: 0.0134, acc: 0.6647\n",
      "Epoch 128/150\n",
      "train loss: 0.0054, acc: 0.8575\n",
      "val loss: 0.0148, acc: 0.6472\n",
      "Epoch 129/150\n",
      "train loss: 0.0045, acc: 0.8857\n",
      "val loss: 0.0158, acc: 0.6793\n",
      "Epoch 130/150\n",
      "train loss: 0.0048, acc: 0.8681\n",
      "val loss: 0.0139, acc: 0.6647\n",
      "Epoch 131/150\n",
      "train loss: 0.0028, acc: 0.9355\n",
      "val loss: 0.0214, acc: 0.6501\n",
      "Epoch 132/150\n",
      "train loss: 0.0019, acc: 0.9560\n",
      "val loss: 0.0240, acc: 0.6472\n",
      "Epoch 133/150\n",
      "train loss: 0.0021, acc: 0.9451\n",
      "val loss: 0.0224, acc: 0.6647\n",
      "Epoch 134/150\n",
      "train loss: 0.0017, acc: 0.9546\n",
      "val loss: 0.0295, acc: 0.6589\n",
      "Epoch 135/150\n",
      "train loss: 0.0008, acc: 0.9850\n",
      "val loss: 0.0324, acc: 0.6735\n",
      "Epoch 136/150\n",
      "train loss: 0.0002, acc: 0.9963\n",
      "val loss: 0.0395, acc: 0.6268\n",
      "Epoch 137/150\n",
      "train loss: 0.0004, acc: 0.9919\n",
      "val loss: 0.0383, acc: 0.6385\n",
      "Epoch 138/150\n",
      "train loss: 0.0016, acc: 0.9692\n",
      "val loss: 0.0299, acc: 0.6560\n",
      "Epoch 139/150\n",
      "train loss: 0.0007, acc: 0.9813\n",
      "val loss: 0.0361, acc: 0.6443\n",
      "Epoch 140/150\n",
      "train loss: 0.0003, acc: 0.9934\n",
      "val loss: 0.0398, acc: 0.6356\n",
      "Epoch 141/150\n",
      "train loss: 0.0001, acc: 0.9993\n",
      "val loss: 0.0444, acc: 0.6531\n",
      "Epoch 142/150\n",
      "train loss: 0.0001, acc: 0.9989\n",
      "val loss: 0.0435, acc: 0.6443\n",
      "Epoch 143/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6472\n",
      "Epoch 144/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0459, acc: 0.6297\n",
      "Epoch 145/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0461, acc: 0.6385\n",
      "Epoch 146/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0462, acc: 0.6356\n",
      "Epoch 147/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0463, acc: 0.6356\n",
      "Epoch 148/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0463, acc: 0.6385\n",
      "Epoch 149/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0464, acc: 0.6385\n",
      "Epoch 150/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0464, acc: 0.6385\n",
      "Training complete in 15m 26s\n",
      "Best val Acc: 0.699708\n",
      "Best Epoch : 122\n",
      "Test Accuracy : 0.75\n",
      "                              Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)            1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)           0.993773  0.667638      0.68    125\n",
      "C[1, 16, 8]_K(3, 40)           0.889744  0.667638      0.70    128\n",
      "C[1, 32, 16, 8]_K(3, 8)        0.955311  0.688047      0.78     14\n",
      "C[1, 32, 16, 8]_K(3, 24)       0.915385  0.664723      0.76     13\n",
      "C[1, 32, 16, 8]_K(3, 40)       0.952015  0.661808      0.66     19\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)    0.863370  0.676385      0.72    150\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)   1.000000  0.723032      0.71     68\n",
      "C[1, 64, 32, 16, 8]_K(3, 40)   0.706593  0.699708      0.75    122\n",
      "\n",
      "\n",
      "##### C[1, 128, 64, 32, 16, 8]_K(3, 8) #####\n",
      "Input shape : torch.Size([1, 128, 22, 90]) and flattened : 253440\n",
      "Input shape : torch.Size([1, 64, 22, 45]) and flattened : 63360\n",
      "Input shape : torch.Size([1, 32, 22, 23]) and flattened : 16192\n",
      "Input shape : torch.Size([1, 16, 22, 12]) and flattened : 4224\n",
      "Input shape : torch.Size([1, 8, 22, 6]) and flattened : 1056\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 8)_O128): Conv2d(1, 128, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O64): Conv2d(128, 64, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O32): Conv2d(64, 32, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O16): Conv2d(32, 16, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O8): Conv2d(16, 8, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (fc1): Linear(in_features=1056, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n",
      "train loss: 0.0121, acc: 0.5165\n",
      "val loss: 0.0120, acc: 0.5306\n",
      "Epoch 2/150\n",
      "train loss: 0.0109, acc: 0.5582\n",
      "val loss: 0.0125, acc: 0.5073\n",
      "Epoch 3/150\n",
      "train loss: 0.0103, acc: 0.6231\n",
      "val loss: 0.0118, acc: 0.6152\n",
      "Epoch 4/150\n",
      "train loss: 0.0080, acc: 0.7451\n",
      "val loss: 0.0120, acc: 0.6064\n",
      "Epoch 5/150\n",
      "train loss: 0.0061, acc: 0.8315\n",
      "val loss: 0.0147, acc: 0.5918\n",
      "Epoch 6/150\n",
      "train loss: 0.0042, acc: 0.8897\n",
      "val loss: 0.0158, acc: 0.6210\n",
      "Epoch 7/150\n",
      "train loss: 0.0024, acc: 0.9392\n",
      "val loss: 0.0193, acc: 0.6006\n",
      "Epoch 8/150\n",
      "train loss: 0.0013, acc: 0.9696\n",
      "val loss: 0.0233, acc: 0.6122\n",
      "Epoch 9/150\n",
      "train loss: 0.0008, acc: 0.9857\n",
      "val loss: 0.0264, acc: 0.6181\n",
      "Epoch 10/150\n",
      "train loss: 0.0003, acc: 0.9938\n",
      "val loss: 0.0302, acc: 0.6093\n",
      "Epoch 11/150\n",
      "train loss: 0.0001, acc: 0.9996\n",
      "val loss: 0.0326, acc: 0.6006\n",
      "Epoch 12/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0342, acc: 0.5918\n",
      "Epoch 13/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0345, acc: 0.6035\n",
      "Epoch 14/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0353, acc: 0.6006\n",
      "Epoch 15/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.5977\n",
      "Epoch 16/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0357, acc: 0.6006\n",
      "Epoch 17/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0360, acc: 0.5977\n",
      "Epoch 18/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0362, acc: 0.5948\n",
      "Epoch 19/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0363, acc: 0.5948\n",
      "Epoch 20/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.5948\n",
      "Epoch 21/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.5948\n",
      "Epoch 22/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0367, acc: 0.5948\n",
      "Epoch 23/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.5948\n",
      "Epoch 24/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.5977\n",
      "Epoch 25/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0367, acc: 0.5977\n",
      "Epoch 26/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0367, acc: 0.5977\n",
      "Epoch 27/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6006\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.5977\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6006\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6006\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.5977\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6006\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6006\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6035\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0369, acc: 0.6035\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6035\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0368, acc: 0.6006\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0367, acc: 0.6035\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0366, acc: 0.6035\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0366, acc: 0.6035\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6035\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0366, acc: 0.6064\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6064\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0365, acc: 0.6064\n",
      "Epoch 45/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6035\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6064\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6006\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.5977\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0362, acc: 0.6035\n",
      "Epoch 50/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0362, acc: 0.6035\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0361, acc: 0.5977\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0360, acc: 0.5948\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0359, acc: 0.5918\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0358, acc: 0.5889\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0358, acc: 0.5889\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0358, acc: 0.5889\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0359, acc: 0.5918\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0358, acc: 0.5889\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0357, acc: 0.5948\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.5889\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0353, acc: 0.5948\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.6035\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0355, acc: 0.5918\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0352, acc: 0.5977\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0352, acc: 0.5860\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0352, acc: 0.5831\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0350, acc: 0.5831\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0348, acc: 0.5918\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0348, acc: 0.5889\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0347, acc: 0.5977\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0347, acc: 0.5948\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0344, acc: 0.5977\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.6006\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0343, acc: 0.6006\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.5977\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0346, acc: 0.6006\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0351, acc: 0.6064\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0344, acc: 0.5860\n",
      "Epoch 79/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0339, acc: 0.6006\n",
      "Epoch 80/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0342, acc: 0.6064\n",
      "Epoch 81/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0345, acc: 0.6006\n",
      "Epoch 82/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0344, acc: 0.5948\n",
      "Epoch 83/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0350, acc: 0.6035\n",
      "Epoch 84/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0343, acc: 0.5889\n",
      "Epoch 85/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0340, acc: 0.6122\n",
      "Epoch 86/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0339, acc: 0.6210\n",
      "Epoch 87/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0338, acc: 0.6210\n",
      "Epoch 88/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0348, acc: 0.6152\n",
      "Epoch 89/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0338, acc: 0.6093\n",
      "Epoch 90/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0351, acc: 0.5948\n",
      "Epoch 91/150\n",
      "train loss: 0.0223, acc: 0.6634\n",
      "val loss: 0.0138, acc: 0.4985\n",
      "Epoch 92/150\n",
      "train loss: 0.0113, acc: 0.5150\n",
      "val loss: 0.0121, acc: 0.5423\n",
      "Epoch 93/150\n",
      "train loss: 0.0110, acc: 0.5271\n",
      "val loss: 0.0122, acc: 0.5423\n",
      "Epoch 94/150\n",
      "train loss: 0.0104, acc: 0.5960\n",
      "val loss: 0.0120, acc: 0.5598\n",
      "Epoch 95/150\n",
      "train loss: 0.0095, acc: 0.6700\n",
      "val loss: 0.0133, acc: 0.5714\n",
      "Epoch 96/150\n",
      "train loss: 0.0087, acc: 0.7128\n",
      "val loss: 0.0116, acc: 0.6501\n",
      "Epoch 97/150\n",
      "train loss: 0.0080, acc: 0.7513\n",
      "val loss: 0.0116, acc: 0.6268\n",
      "Epoch 98/150\n",
      "train loss: 0.0067, acc: 0.8011\n",
      "val loss: 0.0169, acc: 0.5860\n",
      "Epoch 99/150\n",
      "train loss: 0.0059, acc: 0.8348\n",
      "val loss: 0.0144, acc: 0.6501\n",
      "Epoch 100/150\n",
      "train loss: 0.0043, acc: 0.8864\n",
      "val loss: 0.0150, acc: 0.6851\n",
      "Epoch 101/150\n",
      "train loss: 0.0024, acc: 0.9432\n",
      "val loss: 0.0206, acc: 0.6618\n",
      "Epoch 102/150\n",
      "train loss: 0.0024, acc: 0.9403\n",
      "val loss: 0.0218, acc: 0.5948\n",
      "Epoch 103/150\n",
      "train loss: 0.0019, acc: 0.9535\n",
      "val loss: 0.0243, acc: 0.6531\n",
      "Epoch 104/150\n",
      "train loss: 0.0007, acc: 0.9853\n",
      "val loss: 0.0259, acc: 0.6589\n",
      "Epoch 105/150\n",
      "train loss: 0.0004, acc: 0.9908\n",
      "val loss: 0.0295, acc: 0.6327\n",
      "Epoch 106/150\n",
      "train loss: 0.0009, acc: 0.9795\n",
      "val loss: 0.0304, acc: 0.6414\n",
      "Epoch 107/150\n",
      "train loss: 0.0011, acc: 0.9773\n",
      "val loss: 0.0329, acc: 0.6443\n",
      "Epoch 108/150\n",
      "train loss: 0.0003, acc: 0.9952\n",
      "val loss: 0.0318, acc: 0.6210\n",
      "Epoch 109/150\n",
      "train loss: 0.0001, acc: 0.9996\n",
      "val loss: 0.0359, acc: 0.6152\n",
      "Epoch 110/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0364, acc: 0.6239\n",
      "Epoch 111/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6385\n",
      "Epoch 112/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0372, acc: 0.6327\n",
      "Epoch 113/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0377, acc: 0.6268\n",
      "Epoch 114/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0383, acc: 0.6210\n",
      "Epoch 115/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0378, acc: 0.6181\n",
      "Epoch 116/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0382, acc: 0.6181\n",
      "Epoch 117/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6181\n",
      "Epoch 118/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0384, acc: 0.6181\n",
      "Epoch 119/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6181\n",
      "Epoch 120/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0382, acc: 0.6239\n",
      "Epoch 121/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0382, acc: 0.6268\n",
      "Epoch 122/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0383, acc: 0.6239\n",
      "Epoch 123/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6297\n",
      "Epoch 124/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0384, acc: 0.6239\n",
      "Epoch 125/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0381, acc: 0.6239\n",
      "Epoch 126/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0383, acc: 0.6268\n",
      "Epoch 127/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0380, acc: 0.6327\n",
      "Epoch 128/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0383, acc: 0.6327\n",
      "Epoch 129/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0382, acc: 0.6239\n",
      "Epoch 130/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0381, acc: 0.6239\n",
      "Epoch 131/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0381, acc: 0.6210\n",
      "Epoch 132/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0381, acc: 0.6210\n",
      "Epoch 133/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0381, acc: 0.6210\n",
      "Epoch 134/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0380, acc: 0.6239\n",
      "Epoch 135/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0381, acc: 0.6239\n",
      "Epoch 136/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0380, acc: 0.6239\n",
      "Epoch 137/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0378, acc: 0.6297\n",
      "Epoch 138/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0376, acc: 0.6327\n",
      "Epoch 139/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0378, acc: 0.6268\n",
      "Epoch 140/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0378, acc: 0.6268\n",
      "Epoch 141/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0376, acc: 0.6239\n",
      "Epoch 142/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0381, acc: 0.6239\n",
      "Epoch 143/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6297\n",
      "Epoch 144/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0381, acc: 0.6239\n",
      "Epoch 145/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0379, acc: 0.6239\n",
      "Epoch 146/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0373, acc: 0.6268\n",
      "Epoch 147/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6268\n",
      "Epoch 148/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0375, acc: 0.6152\n",
      "Epoch 149/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0371, acc: 0.6093\n",
      "Epoch 150/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0374, acc: 0.6152\n",
      "Training complete in 10m 6s\n",
      "Best val Acc: 0.685131\n",
      "Best Epoch : 100\n",
      "Test Accuracy : 0.66\n",
      "                                  Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)                1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)               0.993773  0.667638      0.68    125\n",
      "C[1, 16, 8]_K(3, 40)               0.889744  0.667638      0.70    128\n",
      "C[1, 32, 16, 8]_K(3, 8)            0.955311  0.688047      0.78     14\n",
      "C[1, 32, 16, 8]_K(3, 24)           0.915385  0.664723      0.76     13\n",
      "C[1, 32, 16, 8]_K(3, 40)           0.952015  0.661808      0.66     19\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)        0.863370  0.676385      0.72    150\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)       1.000000  0.723032      0.71     68\n",
      "C[1, 64, 32, 16, 8]_K(3, 40)       0.706593  0.699708      0.75    122\n",
      "C[1, 128, 64, 32, 16, 8]_K(3, 8)   0.886447  0.685131      0.66    100\n",
      "\n",
      "\n",
      "##### C[1, 128, 64, 32, 16, 8]_K(3, 24) #####\n",
      "Input shape : torch.Size([1, 128, 22, 90]) and flattened : 253440\n",
      "Input shape : torch.Size([1, 64, 22, 45]) and flattened : 63360\n",
      "Input shape : torch.Size([1, 32, 22, 23]) and flattened : 16192\n",
      "Input shape : torch.Size([1, 16, 22, 12]) and flattened : 4224\n",
      "Input shape : torch.Size([1, 8, 22, 6]) and flattened : 1056\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 24)_O128): Conv2d(1, 128, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O64): Conv2d(128, 64, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O32): Conv2d(64, 32, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O16): Conv2d(32, 16, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O8): Conv2d(16, 8, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (fc1): Linear(in_features=1056, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0125, acc: 0.4927\n",
      "val loss: 0.0124, acc: 0.4956\n",
      "Epoch 2/150\n",
      "train loss: 0.0112, acc: 0.5172\n",
      "val loss: 0.0122, acc: 0.4985\n",
      "Epoch 3/150\n",
      "train loss: 0.0110, acc: 0.5260\n",
      "val loss: 0.0119, acc: 0.5481\n",
      "Epoch 4/150\n",
      "train loss: 0.0106, acc: 0.5703\n",
      "val loss: 0.0117, acc: 0.5773\n",
      "Epoch 5/150\n",
      "train loss: 0.0092, acc: 0.6857\n",
      "val loss: 0.0112, acc: 0.6531\n",
      "Epoch 6/150\n",
      "train loss: 0.0079, acc: 0.7601\n",
      "val loss: 0.0110, acc: 0.6851\n",
      "Epoch 7/150\n",
      "train loss: 0.0069, acc: 0.7993\n",
      "val loss: 0.0107, acc: 0.6822\n",
      "Epoch 8/150\n",
      "train loss: 0.0056, acc: 0.8451\n",
      "val loss: 0.0129, acc: 0.6968\n",
      "Epoch 9/150\n",
      "train loss: 0.0036, acc: 0.9106\n",
      "val loss: 0.0161, acc: 0.6880\n",
      "Epoch 10/150\n",
      "train loss: 0.0019, acc: 0.9557\n",
      "val loss: 0.0222, acc: 0.6851\n",
      "Epoch 11/150\n",
      "train loss: 0.0010, acc: 0.9755\n",
      "val loss: 0.0257, acc: 0.6910\n",
      "Epoch 12/150\n",
      "train loss: 0.0013, acc: 0.9707\n",
      "val loss: 0.0272, acc: 0.6589\n",
      "Epoch 13/150\n",
      "train loss: 0.0005, acc: 0.9886\n",
      "val loss: 0.0304, acc: 0.6706\n",
      "Epoch 14/150\n",
      "train loss: 0.0002, acc: 0.9967\n",
      "val loss: 0.0372, acc: 0.6589\n",
      "Epoch 15/150\n",
      "train loss: 0.0001, acc: 0.9993\n",
      "val loss: 0.0378, acc: 0.6851\n",
      "Epoch 16/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0376, acc: 0.6676\n",
      "Epoch 17/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0388, acc: 0.6589\n",
      "Epoch 18/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0392, acc: 0.6676\n",
      "Epoch 19/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0396, acc: 0.6735\n",
      "Epoch 20/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0398, acc: 0.6706\n",
      "Epoch 21/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0400, acc: 0.6706\n",
      "Epoch 22/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6764\n",
      "Epoch 23/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0402, acc: 0.6764\n",
      "Epoch 24/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0404, acc: 0.6764\n",
      "Epoch 25/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0404, acc: 0.6793\n",
      "Epoch 26/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6793\n",
      "Epoch 27/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0406, acc: 0.6764\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6793\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6793\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0408, acc: 0.6793\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6764\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6822\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6764\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6764\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6793\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6764\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6764\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0406, acc: 0.6735\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6764\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0406, acc: 0.6764\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0405, acc: 0.6764\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0403, acc: 0.6764\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0403, acc: 0.6764\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0403, acc: 0.6793\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0402, acc: 0.6793\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0402, acc: 0.6793\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6735\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6735\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0401, acc: 0.6735\n",
      "Epoch 50/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0400, acc: 0.6793\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0399, acc: 0.6764\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0399, acc: 0.6764\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0398, acc: 0.6676\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0398, acc: 0.6676\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0397, acc: 0.6764\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0396, acc: 0.6706\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0396, acc: 0.6706\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0395, acc: 0.6647\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0394, acc: 0.6618\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0395, acc: 0.6618\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0395, acc: 0.6676\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0394, acc: 0.6676\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0395, acc: 0.6764\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0393, acc: 0.6706\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0392, acc: 0.6706\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0392, acc: 0.6676\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0390, acc: 0.6735\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0391, acc: 0.6735\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0388, acc: 0.6735\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0390, acc: 0.6647\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0389, acc: 0.6822\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0390, acc: 0.6764\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0388, acc: 0.6851\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0389, acc: 0.6793\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0385, acc: 0.6851\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0386, acc: 0.6851\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0388, acc: 0.6822\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0384, acc: 0.6880\n",
      "Epoch 79/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0386, acc: 0.6910\n",
      "Epoch 80/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0380, acc: 0.6851\n",
      "Epoch 81/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0389, acc: 0.6910\n",
      "Epoch 82/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0386, acc: 0.6851\n",
      "Epoch 83/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0386, acc: 0.6793\n",
      "Epoch 84/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0379, acc: 0.6822\n",
      "Epoch 85/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0384, acc: 0.6764\n",
      "Epoch 86/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0391, acc: 0.6793\n",
      "Epoch 87/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0383, acc: 0.6822\n",
      "Epoch 88/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0387, acc: 0.6706\n",
      "Epoch 89/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0388, acc: 0.6706\n",
      "Epoch 90/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0390, acc: 0.6851\n",
      "Epoch 91/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0383, acc: 0.6647\n",
      "Epoch 92/150\n",
      "train loss: 0.0130, acc: 0.7092\n",
      "val loss: 0.0138, acc: 0.5102\n",
      "Epoch 93/150\n",
      "train loss: 0.0116, acc: 0.5037\n",
      "val loss: 0.0125, acc: 0.5160\n",
      "Epoch 94/150\n",
      "train loss: 0.0113, acc: 0.5242\n",
      "val loss: 0.0122, acc: 0.5394\n",
      "Epoch 95/150\n",
      "train loss: 0.0110, acc: 0.5359\n",
      "val loss: 0.0118, acc: 0.5539\n",
      "Epoch 96/150\n",
      "train loss: 0.0103, acc: 0.5963\n",
      "val loss: 0.0125, acc: 0.5743\n",
      "Epoch 97/150\n",
      "train loss: 0.0098, acc: 0.6289\n",
      "val loss: 0.0113, acc: 0.6472\n",
      "Epoch 98/150\n",
      "train loss: 0.0094, acc: 0.6707\n",
      "val loss: 0.0113, acc: 0.6268\n",
      "Epoch 99/150\n",
      "train loss: 0.0086, acc: 0.7154\n",
      "val loss: 0.0106, acc: 0.6851\n",
      "Epoch 100/150\n",
      "train loss: 0.0083, acc: 0.7355\n",
      "val loss: 0.0111, acc: 0.6764\n",
      "Epoch 101/150\n",
      "train loss: 0.0077, acc: 0.7685\n",
      "val loss: 0.0111, acc: 0.6647\n",
      "Epoch 102/150\n",
      "train loss: 0.0075, acc: 0.7645\n",
      "val loss: 0.0121, acc: 0.6589\n",
      "Epoch 103/150\n",
      "train loss: 0.0062, acc: 0.8223\n",
      "val loss: 0.0135, acc: 0.6414\n",
      "Epoch 104/150\n",
      "train loss: 0.0053, acc: 0.8498\n",
      "val loss: 0.0144, acc: 0.6910\n",
      "Epoch 105/150\n",
      "train loss: 0.0046, acc: 0.8729\n",
      "val loss: 0.0144, acc: 0.6764\n",
      "Epoch 106/150\n",
      "train loss: 0.0030, acc: 0.9264\n",
      "val loss: 0.0233, acc: 0.6910\n",
      "Epoch 107/150\n",
      "train loss: 0.0031, acc: 0.9190\n",
      "val loss: 0.0195, acc: 0.6735\n",
      "Epoch 108/150\n",
      "train loss: 0.0013, acc: 0.9696\n",
      "val loss: 0.0297, acc: 0.6297\n",
      "Epoch 109/150\n",
      "train loss: 0.0010, acc: 0.9780\n",
      "val loss: 0.0321, acc: 0.6531\n",
      "Epoch 110/150\n",
      "train loss: 0.0012, acc: 0.9703\n",
      "val loss: 0.0295, acc: 0.7055\n",
      "Epoch 111/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0007, acc: 0.9850\n",
      "val loss: 0.0328, acc: 0.6880\n",
      "Epoch 112/150\n",
      "train loss: 0.0005, acc: 0.9901\n",
      "val loss: 0.0363, acc: 0.7026\n",
      "Epoch 113/150\n",
      "train loss: 0.0004, acc: 0.9905\n",
      "val loss: 0.0374, acc: 0.6735\n",
      "Epoch 114/150\n",
      "train loss: 0.0002, acc: 0.9967\n",
      "val loss: 0.0474, acc: 0.6385\n",
      "Epoch 115/150\n",
      "train loss: 0.0001, acc: 0.9993\n",
      "val loss: 0.0448, acc: 0.6822\n",
      "Epoch 116/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0479, acc: 0.6589\n",
      "Epoch 117/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0480, acc: 0.6676\n",
      "Epoch 118/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0484, acc: 0.6618\n",
      "Epoch 119/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0489, acc: 0.6647\n",
      "Epoch 120/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0487, acc: 0.6647\n",
      "Epoch 121/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0490, acc: 0.6647\n",
      "Epoch 122/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0489, acc: 0.6647\n",
      "Epoch 123/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0487, acc: 0.6618\n",
      "Epoch 124/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0487, acc: 0.6647\n",
      "Epoch 125/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0486, acc: 0.6618\n",
      "Epoch 126/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0487, acc: 0.6618\n",
      "Epoch 127/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0487, acc: 0.6647\n",
      "Epoch 128/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0487, acc: 0.6647\n",
      "Epoch 129/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0485, acc: 0.6618\n",
      "Epoch 130/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0490, acc: 0.6618\n",
      "Epoch 131/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0485, acc: 0.6676\n",
      "Epoch 132/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0485, acc: 0.6647\n",
      "Epoch 133/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0483, acc: 0.6676\n",
      "Epoch 134/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0484, acc: 0.6676\n",
      "Epoch 135/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0480, acc: 0.6706\n",
      "Epoch 136/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0481, acc: 0.6676\n",
      "Epoch 137/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0480, acc: 0.6735\n",
      "Epoch 138/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0480, acc: 0.6735\n",
      "Epoch 139/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0479, acc: 0.6706\n",
      "Epoch 140/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0479, acc: 0.6735\n",
      "Epoch 141/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0475, acc: 0.6735\n",
      "Epoch 142/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0469, acc: 0.6706\n",
      "Epoch 143/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0471, acc: 0.6706\n",
      "Epoch 144/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0469, acc: 0.6735\n",
      "Epoch 145/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0467, acc: 0.6735\n",
      "Epoch 146/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0463, acc: 0.6735\n",
      "Epoch 147/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0465, acc: 0.6735\n",
      "Epoch 148/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0462, acc: 0.6764\n",
      "Epoch 149/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0460, acc: 0.6706\n",
      "Epoch 150/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0456, acc: 0.6676\n",
      "Training complete in 11m 26s\n",
      "Best val Acc: 0.705539\n",
      "Best Epoch : 110\n",
      "Test Accuracy : 0.79\n",
      "                                   Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)                 1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)                0.993773  0.667638      0.68    125\n",
      "C[1, 16, 8]_K(3, 40)                0.889744  0.667638      0.70    128\n",
      "C[1, 32, 16, 8]_K(3, 8)             0.955311  0.688047      0.78     14\n",
      "C[1, 32, 16, 8]_K(3, 24)            0.915385  0.664723      0.76     13\n",
      "C[1, 32, 16, 8]_K(3, 40)            0.952015  0.661808      0.66     19\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)         0.863370  0.676385      0.72    150\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)        1.000000  0.723032      0.71     68\n",
      "C[1, 64, 32, 16, 8]_K(3, 40)        0.706593  0.699708      0.75    122\n",
      "C[1, 128, 64, 32, 16, 8]_K(3, 8)    0.886447  0.685131      0.66    100\n",
      "C[1, 128, 64, 32, 16, 8]_K(3, 24)   0.970330  0.705539      0.79    110\n",
      "\n",
      "\n",
      "##### C[1, 128, 64, 32, 16, 8]_K(3, 40) #####\n",
      "Input shape : torch.Size([1, 128, 22, 90]) and flattened : 253440\n",
      "Input shape : torch.Size([1, 64, 22, 45]) and flattened : 63360\n",
      "Input shape : torch.Size([1, 32, 22, 23]) and flattened : 16192\n",
      "Input shape : torch.Size([1, 16, 22, 12]) and flattened : 4224\n",
      "Input shape : torch.Size([1, 8, 22, 6]) and flattened : 1056\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 40)_O128): Conv2d(1, 128, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O64): Conv2d(128, 64, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O32): Conv2d(64, 32, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O16): Conv2d(32, 16, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O8): Conv2d(16, 8, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (fc1): Linear(in_features=1056, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n",
      "train loss: 0.0127, acc: 0.5066\n",
      "val loss: 0.0122, acc: 0.5160\n",
      "Epoch 2/150\n",
      "train loss: 0.0111, acc: 0.5381\n",
      "val loss: 0.0120, acc: 0.5335\n",
      "Epoch 3/150\n",
      "train loss: 0.0110, acc: 0.5322\n",
      "val loss: 0.0121, acc: 0.5102\n",
      "Epoch 4/150\n",
      "train loss: 0.0111, acc: 0.5264\n",
      "val loss: 0.0119, acc: 0.5743\n",
      "Epoch 5/150\n",
      "train loss: 0.0104, acc: 0.6037\n",
      "val loss: 0.0111, acc: 0.6472\n",
      "Epoch 6/150\n",
      "train loss: 0.0091, acc: 0.6916\n",
      "val loss: 0.0121, acc: 0.6268\n",
      "Epoch 7/150\n",
      "train loss: 0.0085, acc: 0.7190\n",
      "val loss: 0.0123, acc: 0.6414\n",
      "Epoch 8/150\n",
      "train loss: 0.0077, acc: 0.7681\n",
      "val loss: 0.0129, acc: 0.6385\n",
      "Epoch 9/150\n",
      "train loss: 0.0069, acc: 0.8004\n",
      "val loss: 0.0125, acc: 0.6589\n",
      "Epoch 10/150\n",
      "train loss: 0.0047, acc: 0.8718\n",
      "val loss: 0.0140, acc: 0.6793\n",
      "Epoch 11/150\n",
      "train loss: 0.0035, acc: 0.9139\n",
      "val loss: 0.0209, acc: 0.6618\n",
      "Epoch 12/150\n",
      "train loss: 0.0018, acc: 0.9615\n",
      "val loss: 0.0249, acc: 0.6531\n",
      "Epoch 13/150\n",
      "train loss: 0.0024, acc: 0.9392\n",
      "val loss: 0.0248, acc: 0.6764\n",
      "Epoch 14/150\n",
      "train loss: 0.0007, acc: 0.9853\n",
      "val loss: 0.0295, acc: 0.6676\n",
      "Epoch 15/150\n",
      "train loss: 0.0006, acc: 0.9846\n",
      "val loss: 0.0338, acc: 0.6851\n",
      "Epoch 16/150\n",
      "train loss: 0.0005, acc: 0.9912\n",
      "val loss: 0.0306, acc: 0.6880\n",
      "Epoch 17/150\n",
      "train loss: 0.0008, acc: 0.9817\n",
      "val loss: 0.0272, acc: 0.6647\n",
      "Epoch 18/150\n",
      "train loss: 0.0005, acc: 0.9868\n",
      "val loss: 0.0410, acc: 0.6793\n",
      "Epoch 19/150\n",
      "train loss: 0.0006, acc: 0.9864\n",
      "val loss: 0.0350, acc: 0.6880\n",
      "Epoch 20/150\n",
      "train loss: 0.0001, acc: 0.9974\n",
      "val loss: 0.0421, acc: 0.6676\n",
      "Epoch 21/150\n",
      "train loss: 0.0004, acc: 0.9905\n",
      "val loss: 0.0392, acc: 0.6910\n",
      "Epoch 22/150\n",
      "train loss: 0.0004, acc: 0.9927\n",
      "val loss: 0.0435, acc: 0.6851\n",
      "Epoch 23/150\n",
      "train loss: 0.0003, acc: 0.9949\n",
      "val loss: 0.0506, acc: 0.6764\n",
      "Epoch 24/150\n",
      "train loss: 0.0005, acc: 0.9868\n",
      "val loss: 0.0400, acc: 0.6851\n",
      "Epoch 25/150\n",
      "train loss: 0.0003, acc: 0.9934\n",
      "val loss: 0.0521, acc: 0.6501\n",
      "Epoch 26/150\n",
      "train loss: 0.0005, acc: 0.9905\n",
      "val loss: 0.0456, acc: 0.6851\n",
      "Epoch 27/150\n",
      "train loss: 0.0005, acc: 0.9879\n",
      "val loss: 0.0359, acc: 0.6997\n",
      "Epoch 28/150\n",
      "train loss: 0.0008, acc: 0.9850\n",
      "val loss: 0.0341, acc: 0.6327\n",
      "Epoch 29/150\n",
      "train loss: 0.0004, acc: 0.9901\n",
      "val loss: 0.0386, acc: 0.6589\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0422, acc: 0.6618\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0437, acc: 0.6618\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0444, acc: 0.6618\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0448, acc: 0.6618\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0451, acc: 0.6618\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6589\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0457, acc: 0.6647\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6647\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0460, acc: 0.6647\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0461, acc: 0.6647\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0461, acc: 0.6589\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0462, acc: 0.6589\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.0462, acc: 0.6647\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0462, acc: 0.6589\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0462, acc: 0.6589\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0462, acc: 0.6647\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0462, acc: 0.6647\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0461, acc: 0.6647\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0461, acc: 0.6618\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0460, acc: 0.6589\n",
      "Epoch 50/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0459, acc: 0.6589\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0459, acc: 0.6589\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6589\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.6618\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0457, acc: 0.6618\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0456, acc: 0.6618\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0455, acc: 0.6589\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6618\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6647\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0454, acc: 0.6618\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0452, acc: 0.6589\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0452, acc: 0.6589\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0451, acc: 0.6560\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0449, acc: 0.6618\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0448, acc: 0.6589\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0448, acc: 0.6560\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0447, acc: 0.6560\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0446, acc: 0.6560\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0444, acc: 0.6589\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0443, acc: 0.6647\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0444, acc: 0.6647\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0443, acc: 0.6618\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0442, acc: 0.6560\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0442, acc: 0.6589\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0440, acc: 0.6560\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0438, acc: 0.6589\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0436, acc: 0.6618\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0437, acc: 0.6531\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0435, acc: 0.6560\n",
      "Epoch 79/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0433, acc: 0.6618\n",
      "Epoch 80/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0432, acc: 0.6618\n",
      "Epoch 81/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0431, acc: 0.6647\n",
      "Epoch 82/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0430, acc: 0.6647\n",
      "Epoch 83/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0429, acc: 0.6647\n",
      "Epoch 84/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0430, acc: 0.6560\n",
      "Epoch 85/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0428, acc: 0.6531\n",
      "Epoch 86/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0428, acc: 0.6560\n",
      "Epoch 87/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0427, acc: 0.6531\n",
      "Epoch 88/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0426, acc: 0.6647\n",
      "Epoch 89/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6706\n",
      "Epoch 90/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6589\n",
      "Epoch 91/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0426, acc: 0.6764\n",
      "Epoch 92/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6618\n",
      "Epoch 93/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6647\n",
      "Epoch 94/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6706\n",
      "Epoch 95/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0419, acc: 0.6706\n",
      "Epoch 96/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0417, acc: 0.6706\n",
      "Epoch 97/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0414, acc: 0.6618\n",
      "Epoch 98/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0415, acc: 0.6589\n",
      "Epoch 99/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0419, acc: 0.6618\n",
      "Epoch 100/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0413, acc: 0.6501\n",
      "Epoch 101/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0404, acc: 0.6706\n",
      "Epoch 102/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0408, acc: 0.6589\n",
      "Epoch 103/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0407, acc: 0.6560\n",
      "Epoch 104/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0403, acc: 0.6560\n",
      "Epoch 105/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0400, acc: 0.6618\n",
      "Epoch 106/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0393, acc: 0.6501\n",
      "Epoch 107/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0398, acc: 0.6676\n",
      "Epoch 108/150\n",
      "train loss: 0.0075, acc: 0.8520\n",
      "val loss: 0.0138, acc: 0.5306\n",
      "Epoch 109/150\n",
      "train loss: 0.0118, acc: 0.5275\n",
      "val loss: 0.0120, acc: 0.5598\n",
      "Epoch 110/150\n",
      "train loss: 0.0100, acc: 0.6245\n",
      "val loss: 0.0113, acc: 0.6880\n",
      "Epoch 111/150\n",
      "train loss: 0.0093, acc: 0.6832\n",
      "val loss: 0.0108, acc: 0.6968\n",
      "Epoch 112/150\n",
      "train loss: 0.0087, acc: 0.7194\n",
      "val loss: 0.0108, acc: 0.6414\n",
      "Epoch 113/150\n",
      "train loss: 0.0083, acc: 0.7326\n",
      "val loss: 0.0111, acc: 0.6501\n",
      "Epoch 114/150\n",
      "train loss: 0.0079, acc: 0.7531\n",
      "val loss: 0.0138, acc: 0.6735\n",
      "Epoch 115/150\n",
      "train loss: 0.0070, acc: 0.8037\n",
      "val loss: 0.0120, acc: 0.6443\n",
      "Epoch 116/150\n",
      "train loss: 0.0062, acc: 0.8245\n",
      "val loss: 0.0127, acc: 0.6618\n",
      "Epoch 117/150\n",
      "train loss: 0.0059, acc: 0.8374\n",
      "val loss: 0.0143, acc: 0.6414\n",
      "Epoch 118/150\n",
      "train loss: 0.0043, acc: 0.8905\n",
      "val loss: 0.0138, acc: 0.6764\n",
      "Epoch 119/150\n",
      "train loss: 0.0027, acc: 0.9319\n",
      "val loss: 0.0290, acc: 0.6327\n",
      "Epoch 120/150\n",
      "train loss: 0.0022, acc: 0.9480\n",
      "val loss: 0.0326, acc: 0.6297\n",
      "Epoch 121/150\n",
      "train loss: 0.0017, acc: 0.9582\n",
      "val loss: 0.0274, acc: 0.6356\n",
      "Epoch 122/150\n",
      "train loss: 0.0008, acc: 0.9842\n",
      "val loss: 0.0405, acc: 0.6443\n",
      "Epoch 123/150\n",
      "train loss: 0.0006, acc: 0.9868\n",
      "val loss: 0.0381, acc: 0.6443\n",
      "Epoch 124/150\n",
      "train loss: 0.0015, acc: 0.9637\n",
      "val loss: 0.0407, acc: 0.6472\n",
      "Epoch 125/150\n",
      "train loss: 0.0009, acc: 0.9788\n",
      "val loss: 0.0376, acc: 0.6385\n",
      "Epoch 126/150\n",
      "train loss: 0.0003, acc: 0.9941\n",
      "val loss: 0.0428, acc: 0.6414\n",
      "Epoch 127/150\n",
      "train loss: 0.0001, acc: 0.9989\n",
      "val loss: 0.0467, acc: 0.6531\n",
      "Epoch 128/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0518, acc: 0.6414\n",
      "Epoch 129/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0521, acc: 0.6443\n",
      "Epoch 130/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0524, acc: 0.6443\n",
      "Epoch 131/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0526, acc: 0.6443\n",
      "Epoch 132/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0529, acc: 0.6472\n",
      "Epoch 133/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0530, acc: 0.6472\n",
      "Epoch 134/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0530, acc: 0.6472\n",
      "Epoch 135/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0532, acc: 0.6501\n",
      "Epoch 136/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0532, acc: 0.6443\n",
      "Epoch 137/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0533, acc: 0.6414\n",
      "Epoch 138/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0534, acc: 0.6443\n",
      "Epoch 139/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0534, acc: 0.6472\n",
      "Epoch 140/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0532, acc: 0.6472\n",
      "Epoch 141/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0530, acc: 0.6472\n",
      "Epoch 142/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0527, acc: 0.6414\n",
      "Epoch 143/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0529, acc: 0.6472\n",
      "Epoch 144/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0528, acc: 0.6472\n",
      "Epoch 145/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0528, acc: 0.6472\n",
      "Epoch 146/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0527, acc: 0.6472\n",
      "Epoch 147/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0526, acc: 0.6501\n",
      "Epoch 148/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0525, acc: 0.6443\n",
      "Epoch 149/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0524, acc: 0.6443\n",
      "Epoch 150/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0523, acc: 0.6414\n",
      "Training complete in 31m 45s\n",
      "Best val Acc: 0.699708\n",
      "Best Epoch : 27\n",
      "Test Accuracy : 0.76\n",
      "                                   Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)                 1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)                0.993773  0.667638      0.68    125\n",
      "C[1, 16, 8]_K(3, 40)                0.889744  0.667638      0.70    128\n",
      "C[1, 32, 16, 8]_K(3, 8)             0.955311  0.688047      0.78     14\n",
      "C[1, 32, 16, 8]_K(3, 24)            0.915385  0.664723      0.76     13\n",
      "C[1, 32, 16, 8]_K(3, 40)            0.952015  0.661808      0.66     19\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)         0.863370  0.676385      0.72    150\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)        1.000000  0.723032      0.71     68\n",
      "C[1, 64, 32, 16, 8]_K(3, 40)        0.706593  0.699708      0.75    122\n",
      "C[1, 128, 64, 32, 16, 8]_K(3, 8)    0.886447  0.685131      0.66    100\n",
      "C[1, 128, 64, 32, 16, 8]_K(3, 24)   0.970330  0.705539      0.79    110\n",
      "C[1, 128, 64, 32, 16, 8]_K(3, 40)   0.987912  0.699708      0.76     27\n",
      "\n",
      "\n",
      "##### C[1, 256, 128, 64, 32, 16, 8]_K(3, 8) #####\n",
      "Input shape : torch.Size([1, 256, 22, 90]) and flattened : 506880\n",
      "Input shape : torch.Size([1, 128, 22, 45]) and flattened : 126720\n",
      "Input shape : torch.Size([1, 64, 22, 23]) and flattened : 32384\n",
      "Input shape : torch.Size([1, 32, 22, 12]) and flattened : 8448\n",
      "Input shape : torch.Size([1, 16, 22, 6]) and flattened : 2112\n",
      "Input shape : torch.Size([1, 8, 22, 3]) and flattened : 528\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 8)_O256): Conv2d(1, 256, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O128): Conv2d(256, 128, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O64): Conv2d(128, 64, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O32): Conv2d(64, 32, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O16): Conv2d(32, 16, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (CNN_K(3, 8)_O8): Conv2d(16, 8, kernel_size=(3, 8), stride=(1, 1), padding=(1, 4))\n",
      "  (fc1): Linear(in_features=528, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0115, acc: 0.5209\n",
      "val loss: 0.0127, acc: 0.4898\n",
      "Epoch 2/150\n",
      "train loss: 0.0106, acc: 0.5952\n",
      "val loss: 0.0125, acc: 0.5219\n",
      "Epoch 3/150\n",
      "train loss: 0.0095, acc: 0.6788\n",
      "val loss: 0.0128, acc: 0.5685\n",
      "Epoch 4/150\n",
      "train loss: 0.0067, acc: 0.8110\n",
      "val loss: 0.0168, acc: 0.5773\n",
      "Epoch 5/150\n",
      "train loss: 0.0044, acc: 0.8813\n",
      "val loss: 0.0225, acc: 0.5598\n",
      "Epoch 6/150\n",
      "train loss: 0.0029, acc: 0.9264\n",
      "val loss: 0.0243, acc: 0.5918\n",
      "Epoch 7/150\n",
      "train loss: 0.0011, acc: 0.9751\n",
      "val loss: 0.0316, acc: 0.5918\n",
      "Epoch 8/150\n",
      "train loss: 0.0007, acc: 0.9817\n",
      "val loss: 0.0312, acc: 0.5831\n",
      "Epoch 9/150\n",
      "train loss: 0.0007, acc: 0.9824\n",
      "val loss: 0.0393, acc: 0.5743\n",
      "Epoch 10/150\n",
      "train loss: 0.0012, acc: 0.9736\n",
      "val loss: 0.0400, acc: 0.5743\n",
      "Epoch 11/150\n",
      "train loss: 0.0012, acc: 0.9703\n",
      "val loss: 0.0305, acc: 0.6064\n",
      "Epoch 12/150\n",
      "train loss: 0.0003, acc: 0.9941\n",
      "val loss: 0.0374, acc: 0.5918\n",
      "Epoch 13/150\n",
      "train loss: 0.0001, acc: 0.9985\n",
      "val loss: 0.0390, acc: 0.5831\n",
      "Epoch 14/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0421, acc: 0.5889\n",
      "Epoch 15/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0431, acc: 0.5977\n",
      "Epoch 16/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0437, acc: 0.5918\n",
      "Epoch 17/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0444, acc: 0.5860\n",
      "Epoch 18/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0448, acc: 0.5831\n",
      "Epoch 19/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0451, acc: 0.5802\n",
      "Epoch 20/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0455, acc: 0.5773\n",
      "Epoch 21/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0458, acc: 0.5802\n",
      "Epoch 22/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0460, acc: 0.5802\n",
      "Epoch 23/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0462, acc: 0.5773\n",
      "Epoch 24/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0464, acc: 0.5773\n",
      "Epoch 25/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0466, acc: 0.5773\n",
      "Epoch 26/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0467, acc: 0.5743\n",
      "Epoch 27/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0468, acc: 0.5802\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0469, acc: 0.5802\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0469, acc: 0.5802\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0470, acc: 0.5743\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0471, acc: 0.5773\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0471, acc: 0.5743\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0472, acc: 0.5773\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.5773\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.5773\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.5773\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0474, acc: 0.5743\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0474, acc: 0.5743\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0474, acc: 0.5714\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0475, acc: 0.5714\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0475, acc: 0.5743\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0476, acc: 0.5773\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0475, acc: 0.5743\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0475, acc: 0.5802\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0475, acc: 0.5743\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0474, acc: 0.5743\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.5773\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.5773\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.5743\n",
      "Epoch 50/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0472, acc: 0.5773\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.5831\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0475, acc: 0.5743\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.5773\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0472, acc: 0.5773\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0472, acc: 0.5802\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0472, acc: 0.5802\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.5773\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.5714\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.5773\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0471, acc: 0.5773\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0472, acc: 0.5773\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0472, acc: 0.5773\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0472, acc: 0.5773\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0472, acc: 0.5773\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0472, acc: 0.5743\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0470, acc: 0.5860\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0471, acc: 0.5743\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0474, acc: 0.5743\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0471, acc: 0.5802\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.5802\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0469, acc: 0.5889\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0473, acc: 0.5802\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0469, acc: 0.5889\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0470, acc: 0.5802\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0470, acc: 0.5685\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0471, acc: 0.5831\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0465, acc: 0.5889\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0478, acc: 0.5831\n",
      "Epoch 79/150\n",
      "train loss: 0.0056, acc: 0.9264\n",
      "val loss: 0.0144, acc: 0.4898\n",
      "Epoch 80/150\n",
      "train loss: 0.0116, acc: 0.5176\n",
      "val loss: 0.0125, acc: 0.5044\n",
      "Epoch 81/150\n",
      "train loss: 0.0104, acc: 0.5967\n",
      "val loss: 0.0130, acc: 0.5044\n",
      "Epoch 82/150\n",
      "train loss: 0.0091, acc: 0.6908\n",
      "val loss: 0.0145, acc: 0.5131\n",
      "Epoch 83/150\n",
      "train loss: 0.0065, acc: 0.8242\n",
      "val loss: 0.0185, acc: 0.5131\n",
      "Epoch 84/150\n",
      "train loss: 0.0043, acc: 0.8842\n",
      "val loss: 0.0241, acc: 0.5277\n",
      "Epoch 85/150\n",
      "train loss: 0.0023, acc: 0.9392\n",
      "val loss: 0.0325, acc: 0.5335\n",
      "Epoch 86/150\n",
      "train loss: 0.0015, acc: 0.9667\n",
      "val loss: 0.0384, acc: 0.5248\n",
      "Epoch 87/150\n",
      "train loss: 0.0014, acc: 0.9652\n",
      "val loss: 0.0390, acc: 0.5015\n",
      "Epoch 88/150\n",
      "train loss: 0.0016, acc: 0.9641\n",
      "val loss: 0.0370, acc: 0.5364\n",
      "Epoch 89/150\n",
      "train loss: 0.0005, acc: 0.9897\n",
      "val loss: 0.0448, acc: 0.5073\n",
      "Epoch 90/150\n",
      "train loss: 0.0001, acc: 0.9982\n",
      "val loss: 0.0455, acc: 0.5306\n",
      "Epoch 91/150\n",
      "train loss: 0.0000, acc: 0.9996\n",
      "val loss: 0.0501, acc: 0.5306\n",
      "Epoch 92/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0515, acc: 0.5306\n",
      "Epoch 93/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0523, acc: 0.5219\n",
      "Epoch 94/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0528, acc: 0.5248\n",
      "Epoch 95/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0536, acc: 0.5248\n",
      "Epoch 96/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0540, acc: 0.5277\n",
      "Epoch 97/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0543, acc: 0.5248\n",
      "Epoch 98/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0545, acc: 0.5248\n",
      "Epoch 99/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0547, acc: 0.5248\n",
      "Epoch 100/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0550, acc: 0.5277\n",
      "Epoch 101/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0551, acc: 0.5219\n",
      "Epoch 102/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0553, acc: 0.5219\n",
      "Epoch 103/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0556, acc: 0.5248\n",
      "Epoch 104/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0558, acc: 0.5248\n",
      "Epoch 105/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0560, acc: 0.5248\n",
      "Epoch 106/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0560, acc: 0.5190\n",
      "Epoch 107/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0561, acc: 0.5219\n",
      "Epoch 108/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0562, acc: 0.5190\n",
      "Epoch 109/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0563, acc: 0.5190\n",
      "Epoch 110/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0565, acc: 0.5190\n",
      "Epoch 111/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0565, acc: 0.5190\n",
      "Epoch 112/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0564, acc: 0.5248\n",
      "Epoch 113/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0566, acc: 0.5190\n",
      "Epoch 114/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0566, acc: 0.5190\n",
      "Epoch 115/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0567, acc: 0.5248\n",
      "Epoch 116/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0568, acc: 0.5248\n",
      "Epoch 117/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0568, acc: 0.5219\n",
      "Epoch 118/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0569, acc: 0.5277\n",
      "Epoch 119/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0569, acc: 0.5277\n",
      "Epoch 120/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0570, acc: 0.5248\n",
      "Epoch 121/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0571, acc: 0.5219\n",
      "Epoch 122/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0570, acc: 0.5190\n",
      "Epoch 123/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0569, acc: 0.5277\n",
      "Epoch 124/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0570, acc: 0.5219\n",
      "Epoch 125/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0572, acc: 0.5306\n",
      "Epoch 126/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0568, acc: 0.5190\n",
      "Epoch 127/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0567, acc: 0.5248\n",
      "Epoch 128/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0569, acc: 0.5248\n",
      "Epoch 129/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0564, acc: 0.5248\n",
      "Epoch 130/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0564, acc: 0.5219\n",
      "Epoch 131/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0567, acc: 0.5219\n",
      "Epoch 132/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0567, acc: 0.5219\n",
      "Epoch 133/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0565, acc: 0.5102\n",
      "Epoch 134/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0562, acc: 0.5190\n",
      "Epoch 135/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0566, acc: 0.5277\n",
      "Epoch 136/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0567, acc: 0.5190\n",
      "Epoch 137/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0570, acc: 0.5248\n",
      "Epoch 138/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0567, acc: 0.5248\n",
      "Epoch 139/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0566, acc: 0.5190\n",
      "Epoch 140/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0560, acc: 0.5219\n",
      "Epoch 141/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0562, acc: 0.5219\n",
      "Epoch 142/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0555, acc: 0.5248\n",
      "Epoch 143/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0560, acc: 0.5131\n",
      "Epoch 144/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0565, acc: 0.5073\n",
      "Epoch 145/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0551, acc: 0.5219\n",
      "Epoch 146/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0558, acc: 0.4956\n",
      "Epoch 147/150\n",
      "train loss: 0.0135, acc: 0.6084\n",
      "val loss: 0.0121, acc: 0.5277\n",
      "Epoch 148/150\n",
      "train loss: 0.0110, acc: 0.5245\n",
      "val loss: 0.0121, acc: 0.5248\n",
      "Epoch 149/150\n",
      "train loss: 0.0101, acc: 0.6308\n",
      "val loss: 0.0128, acc: 0.5831\n",
      "Epoch 150/150\n",
      "train loss: 0.0083, acc: 0.7330\n",
      "val loss: 0.0163, acc: 0.5306\n",
      "Training complete in 13m 3s\n",
      "Best val Acc: 0.606414\n",
      "Best Epoch : 11\n",
      "Test Accuracy : 0.67\n",
      "                                       Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)                     1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)                    0.993773  0.667638      0.68    125\n",
      "C[1, 16, 8]_K(3, 40)                    0.889744  0.667638      0.70    128\n",
      "C[1, 32, 16, 8]_K(3, 8)                 0.955311  0.688047      0.78     14\n",
      "C[1, 32, 16, 8]_K(3, 24)                0.915385  0.664723      0.76     13\n",
      "C[1, 32, 16, 8]_K(3, 40)                0.952015  0.661808      0.66     19\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)             0.863370  0.676385      0.72    150\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)            1.000000  0.723032      0.71     68\n",
      "C[1, 64, 32, 16, 8]_K(3, 40)            0.706593  0.699708      0.75    122\n",
      "C[1, 128, 64, 32, 16, 8]_K(3, 8)        0.886447  0.685131      0.66    100\n",
      "C[1, 128, 64, 32, 16, 8]_K(3, 24)       0.970330  0.705539      0.79    110\n",
      "C[1, 128, 64, 32, 16, 8]_K(3, 40)       0.987912  0.699708      0.76     27\n",
      "C[1, 256, 128, 64, 32, 16, 8]_K(3, 8)   0.970330  0.606414      0.67     11\n",
      "\n",
      "\n",
      "##### C[1, 256, 128, 64, 32, 16, 8]_K(3, 24) #####\n",
      "Input shape : torch.Size([1, 256, 22, 90]) and flattened : 506880\n",
      "Input shape : torch.Size([1, 128, 22, 45]) and flattened : 126720\n",
      "Input shape : torch.Size([1, 64, 22, 23]) and flattened : 32384\n",
      "Input shape : torch.Size([1, 32, 22, 12]) and flattened : 8448\n",
      "Input shape : torch.Size([1, 16, 22, 6]) and flattened : 2112\n",
      "Input shape : torch.Size([1, 8, 22, 3]) and flattened : 528\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 24)_O256): Conv2d(1, 256, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O128): Conv2d(256, 128, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O64): Conv2d(128, 64, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O32): Conv2d(64, 32, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O16): Conv2d(32, 16, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (CNN_K(3, 24)_O8): Conv2d(16, 8, kernel_size=(3, 24), stride=(1, 1), padding=(1, 12))\n",
      "  (fc1): Linear(in_features=528, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n",
      "train loss: 0.0118, acc: 0.5088\n",
      "val loss: 0.0121, acc: 0.5481\n",
      "Epoch 2/150\n",
      "train loss: 0.0110, acc: 0.5154\n",
      "val loss: 0.0125, acc: 0.5015\n",
      "Epoch 3/150\n",
      "train loss: 0.0109, acc: 0.5403\n",
      "val loss: 0.0121, acc: 0.5219\n",
      "Epoch 4/150\n",
      "train loss: 0.0108, acc: 0.5531\n",
      "val loss: 0.0121, acc: 0.5481\n",
      "Epoch 5/150\n",
      "train loss: 0.0105, acc: 0.6062\n",
      "val loss: 0.0129, acc: 0.5714\n",
      "Epoch 6/150\n",
      "train loss: 0.0093, acc: 0.6663\n",
      "val loss: 0.0121, acc: 0.6297\n",
      "Epoch 7/150\n",
      "train loss: 0.0081, acc: 0.7527\n",
      "val loss: 0.0123, acc: 0.6414\n",
      "Epoch 8/150\n",
      "train loss: 0.0068, acc: 0.8004\n",
      "val loss: 0.0148, acc: 0.5977\n",
      "Epoch 9/150\n",
      "train loss: 0.0055, acc: 0.8421\n",
      "val loss: 0.0165, acc: 0.6472\n",
      "Epoch 10/150\n",
      "train loss: 0.0034, acc: 0.9084\n",
      "val loss: 0.0144, acc: 0.6764\n",
      "Epoch 11/150\n",
      "train loss: 0.0019, acc: 0.9590\n",
      "val loss: 0.0240, acc: 0.6443\n",
      "Epoch 12/150\n",
      "train loss: 0.0011, acc: 0.9758\n",
      "val loss: 0.0345, acc: 0.6472\n",
      "Epoch 13/150\n",
      "train loss: 0.0008, acc: 0.9813\n",
      "val loss: 0.0309, acc: 0.6501\n",
      "Epoch 14/150\n",
      "train loss: 0.0011, acc: 0.9758\n",
      "val loss: 0.0221, acc: 0.6531\n",
      "Epoch 15/150\n",
      "train loss: 0.0009, acc: 0.9799\n",
      "val loss: 0.0325, acc: 0.6531\n",
      "Epoch 16/150\n",
      "train loss: 0.0003, acc: 0.9949\n",
      "val loss: 0.0341, acc: 0.6472\n",
      "Epoch 17/150\n",
      "train loss: 0.0001, acc: 0.9989\n",
      "val loss: 0.0410, acc: 0.6414\n",
      "Epoch 18/150\n",
      "train loss: 0.0001, acc: 0.9993\n",
      "val loss: 0.0448, acc: 0.6531\n",
      "Epoch 19/150\n",
      "train loss: 0.0007, acc: 0.9802\n",
      "val loss: 0.0288, acc: 0.6327\n",
      "Epoch 20/150\n",
      "train loss: 0.0005, acc: 0.9883\n",
      "val loss: 0.0313, acc: 0.6356\n",
      "Epoch 21/150\n",
      "train loss: 0.0002, acc: 0.9945\n",
      "val loss: 0.0376, acc: 0.6560\n",
      "Epoch 22/150\n",
      "train loss: 0.0001, acc: 0.9985\n",
      "val loss: 0.0412, acc: 0.6618\n",
      "Epoch 23/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0427, acc: 0.6501\n",
      "Epoch 24/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0431, acc: 0.6443\n",
      "Epoch 25/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0436, acc: 0.6472\n",
      "Epoch 26/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0439, acc: 0.6472\n",
      "Epoch 27/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0440, acc: 0.6501\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0439, acc: 0.6501\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0441, acc: 0.6472\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0441, acc: 0.6472\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0441, acc: 0.6443\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0441, acc: 0.6472\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0441, acc: 0.6472\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0441, acc: 0.6472\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0441, acc: 0.6501\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0440, acc: 0.6472\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.0439, acc: 0.6501\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0438, acc: 0.6531\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0437, acc: 0.6501\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0436, acc: 0.6472\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0435, acc: 0.6472\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0434, acc: 0.6472\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0433, acc: 0.6472\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0431, acc: 0.6472\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0430, acc: 0.6472\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0430, acc: 0.6443\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0429, acc: 0.6443\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0428, acc: 0.6385\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0427, acc: 0.6356\n",
      "Epoch 50/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6443\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6443\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0426, acc: 0.6414\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6414\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6414\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6443\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6414\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6443\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6443\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0426, acc: 0.6414\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6414\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0422, acc: 0.6443\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6443\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6472\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6472\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0422, acc: 0.6443\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6472\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6501\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0422, acc: 0.6501\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0420, acc: 0.6501\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0422, acc: 0.6501\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0423, acc: 0.6414\n",
      "Epoch 72/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0421, acc: 0.6531\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0426, acc: 0.6501\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6327\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6385\n",
      "Epoch 76/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0420, acc: 0.6443\n",
      "Epoch 77/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0425, acc: 0.6385\n",
      "Epoch 78/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0421, acc: 0.6501\n",
      "Epoch 79/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0426, acc: 0.6443\n",
      "Epoch 80/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0420, acc: 0.6414\n",
      "Epoch 81/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0424, acc: 0.6327\n",
      "Epoch 82/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0414, acc: 0.6414\n",
      "Epoch 83/150\n",
      "train loss: 0.0012, acc: 0.9941\n",
      "val loss: 0.0802, acc: 0.5015\n",
      "Epoch 84/150\n",
      "train loss: 0.0128, acc: 0.5300\n",
      "val loss: 0.0123, acc: 0.5219\n",
      "Epoch 85/150\n",
      "train loss: 0.0105, acc: 0.5901\n",
      "val loss: 0.0115, acc: 0.6122\n",
      "Epoch 86/150\n",
      "train loss: 0.0097, acc: 0.6498\n",
      "val loss: 0.0113, acc: 0.6385\n",
      "Epoch 87/150\n",
      "train loss: 0.0088, acc: 0.7040\n",
      "val loss: 0.0110, acc: 0.6676\n",
      "Epoch 88/150\n",
      "train loss: 0.0085, acc: 0.7253\n",
      "val loss: 0.0114, acc: 0.6939\n",
      "Epoch 89/150\n",
      "train loss: 0.0078, acc: 0.7535\n",
      "val loss: 0.0111, acc: 0.6676\n",
      "Epoch 90/150\n",
      "train loss: 0.0074, acc: 0.7817\n",
      "val loss: 0.0113, acc: 0.6764\n",
      "Epoch 91/150\n",
      "train loss: 0.0070, acc: 0.7960\n",
      "val loss: 0.0116, acc: 0.6735\n",
      "Epoch 92/150\n",
      "train loss: 0.0057, acc: 0.8454\n",
      "val loss: 0.0125, acc: 0.6676\n",
      "Epoch 93/150\n",
      "train loss: 0.0054, acc: 0.8579\n",
      "val loss: 0.0118, acc: 0.6706\n",
      "Epoch 94/150\n",
      "train loss: 0.0034, acc: 0.9106\n",
      "val loss: 0.0201, acc: 0.6589\n",
      "Epoch 95/150\n",
      "train loss: 0.0028, acc: 0.9293\n",
      "val loss: 0.0224, acc: 0.6501\n",
      "Epoch 96/150\n",
      "train loss: 0.0019, acc: 0.9575\n",
      "val loss: 0.0282, acc: 0.6414\n",
      "Epoch 97/150\n",
      "train loss: 0.0011, acc: 0.9747\n",
      "val loss: 0.0297, acc: 0.6676\n",
      "Epoch 98/150\n",
      "train loss: 0.0012, acc: 0.9689\n",
      "val loss: 0.0277, acc: 0.6385\n",
      "Epoch 99/150\n",
      "train loss: 0.0006, acc: 0.9901\n",
      "val loss: 0.0338, acc: 0.6880\n",
      "Epoch 100/150\n",
      "train loss: 0.0008, acc: 0.9832\n",
      "val loss: 0.0366, acc: 0.6706\n",
      "Epoch 101/150\n",
      "train loss: 0.0011, acc: 0.9788\n",
      "val loss: 0.0289, acc: 0.6327\n",
      "Epoch 102/150\n",
      "train loss: 0.0001, acc: 0.9993\n",
      "val loss: 0.0383, acc: 0.6501\n",
      "Epoch 103/150\n",
      "train loss: 0.0000, acc: 0.9996\n",
      "val loss: 0.0422, acc: 0.6647\n",
      "Epoch 104/150\n",
      "train loss: 0.0001, acc: 0.9993\n",
      "val loss: 0.0463, acc: 0.6472\n",
      "Epoch 105/150\n",
      "train loss: 0.0000, acc: 0.9996\n",
      "val loss: 0.0451, acc: 0.6531\n",
      "Epoch 106/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0462, acc: 0.6531\n",
      "Epoch 107/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0471, acc: 0.6589\n",
      "Epoch 108/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0474, acc: 0.6618\n",
      "Epoch 109/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0475, acc: 0.6589\n",
      "Epoch 110/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0477, acc: 0.6618\n",
      "Epoch 111/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0479, acc: 0.6589\n",
      "Epoch 112/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0479, acc: 0.6560\n",
      "Epoch 113/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0480, acc: 0.6560\n",
      "Epoch 114/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0479, acc: 0.6589\n",
      "Epoch 115/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0480, acc: 0.6560\n",
      "Epoch 116/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0481, acc: 0.6531\n",
      "Epoch 117/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0481, acc: 0.6531\n",
      "Epoch 118/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0480, acc: 0.6589\n",
      "Epoch 119/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0479, acc: 0.6589\n",
      "Epoch 120/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0479, acc: 0.6589\n",
      "Epoch 121/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0480, acc: 0.6589\n",
      "Epoch 122/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0480, acc: 0.6676\n",
      "Epoch 123/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0481, acc: 0.6676\n",
      "Epoch 124/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0482, acc: 0.6647\n",
      "Epoch 125/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0482, acc: 0.6676\n",
      "Epoch 126/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0482, acc: 0.6618\n",
      "Epoch 127/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0483, acc: 0.6706\n",
      "Epoch 128/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0483, acc: 0.6822\n",
      "Epoch 129/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0482, acc: 0.6822\n",
      "Epoch 130/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0483, acc: 0.6676\n",
      "Epoch 131/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0483, acc: 0.6676\n",
      "Epoch 132/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0484, acc: 0.6735\n",
      "Epoch 133/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0484, acc: 0.6647\n",
      "Epoch 134/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0475, acc: 0.6676\n",
      "Epoch 135/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0480, acc: 0.6735\n",
      "Epoch 136/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0485, acc: 0.6764\n",
      "Epoch 137/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0484, acc: 0.6735\n",
      "Epoch 138/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0489, acc: 0.6706\n",
      "Epoch 139/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0488, acc: 0.6764\n",
      "Epoch 140/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0487, acc: 0.6764\n",
      "Epoch 141/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0483, acc: 0.6793\n",
      "Epoch 142/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0485, acc: 0.6764\n",
      "Epoch 143/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0486, acc: 0.6735\n",
      "Epoch 144/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0491, acc: 0.6880\n",
      "Epoch 145/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0487, acc: 0.6822\n",
      "Epoch 146/150\n",
      "train loss: 0.0000, acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.0488, acc: 0.6764\n",
      "Epoch 147/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0486, acc: 0.6793\n",
      "Epoch 148/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0492, acc: 0.6706\n",
      "Epoch 149/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0492, acc: 0.6735\n",
      "Epoch 150/150\n",
      "train loss: 0.0034, acc: 0.9542\n",
      "val loss: 0.0191, acc: 0.5802\n",
      "Training complete in 98m 45s\n",
      "Best val Acc: 0.693878\n",
      "Best Epoch : 88\n",
      "Test Accuracy : 0.78\n",
      "                                        Train_Acc   Val_Acc  Test_Acc  Epoch\n",
      "C[1, 16, 8]_K(3, 8)                      1.000000  0.661808      0.74    131\n",
      "C[1, 16, 8]_K(3, 24)                     0.993773  0.667638      0.68    125\n",
      "C[1, 16, 8]_K(3, 40)                     0.889744  0.667638      0.70    128\n",
      "C[1, 32, 16, 8]_K(3, 8)                  0.955311  0.688047      0.78     14\n",
      "C[1, 32, 16, 8]_K(3, 24)                 0.915385  0.664723      0.76     13\n",
      "C[1, 32, 16, 8]_K(3, 40)                 0.952015  0.661808      0.66     19\n",
      "C[1, 64, 32, 16, 8]_K(3, 8)              0.863370  0.676385      0.72    150\n",
      "C[1, 64, 32, 16, 8]_K(3, 24)             1.000000  0.723032      0.71     68\n",
      "C[1, 64, 32, 16, 8]_K(3, 40)             0.706593  0.699708      0.75    122\n",
      "C[1, 128, 64, 32, 16, 8]_K(3, 8)         0.886447  0.685131      0.66    100\n",
      "C[1, 128, 64, 32, 16, 8]_K(3, 24)        0.970330  0.705539      0.79    110\n",
      "C[1, 128, 64, 32, 16, 8]_K(3, 40)        0.987912  0.699708      0.76     27\n",
      "C[1, 256, 128, 64, 32, 16, 8]_K(3, 8)    0.970330  0.606414      0.67     11\n",
      "C[1, 256, 128, 64, 32, 16, 8]_K(3, 24)   0.725275  0.693878      0.78     88\n",
      "\n",
      "\n",
      "##### C[1, 256, 128, 64, 32, 16, 8]_K(3, 40) #####\n",
      "Input shape : torch.Size([1, 256, 22, 90]) and flattened : 506880\n",
      "Input shape : torch.Size([1, 128, 22, 45]) and flattened : 126720\n",
      "Input shape : torch.Size([1, 64, 22, 23]) and flattened : 32384\n",
      "Input shape : torch.Size([1, 32, 22, 12]) and flattened : 8448\n",
      "Input shape : torch.Size([1, 16, 22, 6]) and flattened : 2112\n",
      "Input shape : torch.Size([1, 8, 22, 3]) and flattened : 528\n",
      "Model architecture >>> CNN2D(\n",
      "  (MaxPool): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (ReLU): ReLU()\n",
      "  (Dropout): Dropout(p=0.5, inplace=False)\n",
      "  (CNN_K(3, 40)_O256): Conv2d(1, 256, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O128): Conv2d(256, 128, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O64): Conv2d(128, 64, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O32): Conv2d(64, 32, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O16): Conv2d(32, 16, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (CNN_K(3, 40)_O8): Conv2d(16, 8, kernel_size=(3, 40), stride=(1, 1), padding=(1, 20))\n",
      "  (fc1): Linear(in_features=528, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/150\n",
      "train loss: 0.0120, acc: 0.5095\n",
      "val loss: 0.0120, acc: 0.5569\n",
      "Epoch 2/150\n",
      "train loss: 0.0110, acc: 0.5179\n",
      "val loss: 0.0122, acc: 0.5423\n",
      "Epoch 3/150\n",
      "train loss: 0.0110, acc: 0.5242\n",
      "val loss: 0.0120, acc: 0.5569\n",
      "Epoch 4/150\n",
      "train loss: 0.0109, acc: 0.5407\n",
      "val loss: 0.0119, acc: 0.5627\n",
      "Epoch 5/150\n",
      "train loss: 0.0108, acc: 0.5535\n",
      "val loss: 0.0120, acc: 0.5481\n",
      "Epoch 6/150\n",
      "train loss: 0.0107, acc: 0.5692\n",
      "val loss: 0.0116, acc: 0.5714\n",
      "Epoch 7/150\n",
      "train loss: 0.0093, acc: 0.6747\n",
      "val loss: 0.0120, acc: 0.6327\n",
      "Epoch 8/150\n",
      "train loss: 0.0085, acc: 0.7278\n",
      "val loss: 0.0115, acc: 0.6239\n",
      "Epoch 9/150\n",
      "train loss: 0.0072, acc: 0.7872\n",
      "val loss: 0.0130, acc: 0.6385\n",
      "Epoch 10/150\n",
      "train loss: 0.0060, acc: 0.8297\n",
      "val loss: 0.0127, acc: 0.6531\n",
      "Epoch 11/150\n",
      "train loss: 0.0037, acc: 0.9051\n",
      "val loss: 0.0160, acc: 0.6385\n",
      "Epoch 12/150\n",
      "train loss: 0.0022, acc: 0.9454\n",
      "val loss: 0.0237, acc: 0.6327\n",
      "Epoch 13/150\n",
      "train loss: 0.0015, acc: 0.9637\n",
      "val loss: 0.0321, acc: 0.6385\n",
      "Epoch 14/150\n",
      "train loss: 0.0009, acc: 0.9791\n",
      "val loss: 0.0293, acc: 0.6327\n",
      "Epoch 15/150\n",
      "train loss: 0.0007, acc: 0.9835\n",
      "val loss: 0.0329, acc: 0.6064\n",
      "Epoch 16/150\n",
      "train loss: 0.0006, acc: 0.9857\n",
      "val loss: 0.0377, acc: 0.6268\n",
      "Epoch 17/150\n",
      "train loss: 0.0005, acc: 0.9879\n",
      "val loss: 0.0341, acc: 0.6210\n",
      "Epoch 18/150\n",
      "train loss: 0.0001, acc: 0.9985\n",
      "val loss: 0.0460, acc: 0.6297\n",
      "Epoch 19/150\n",
      "train loss: 0.0000, acc: 0.9993\n",
      "val loss: 0.0510, acc: 0.6210\n",
      "Epoch 20/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0527, acc: 0.6181\n",
      "Epoch 21/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0527, acc: 0.6239\n",
      "Epoch 22/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0526, acc: 0.6210\n",
      "Epoch 23/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0526, acc: 0.6268\n",
      "Epoch 24/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0525, acc: 0.6268\n",
      "Epoch 25/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0525, acc: 0.6268\n",
      "Epoch 26/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0524, acc: 0.6297\n",
      "Epoch 27/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0522, acc: 0.6327\n",
      "Epoch 28/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0521, acc: 0.6327\n",
      "Epoch 29/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0520, acc: 0.6327\n",
      "Epoch 30/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0519, acc: 0.6356\n",
      "Epoch 31/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0518, acc: 0.6356\n",
      "Epoch 32/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0516, acc: 0.6327\n",
      "Epoch 33/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0514, acc: 0.6356\n",
      "Epoch 34/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0512, acc: 0.6327\n",
      "Epoch 35/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0512, acc: 0.6385\n",
      "Epoch 36/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0510, acc: 0.6385\n",
      "Epoch 37/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0510, acc: 0.6385\n",
      "Epoch 38/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0508, acc: 0.6385\n",
      "Epoch 39/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0506, acc: 0.6385\n",
      "Epoch 40/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0505, acc: 0.6385\n",
      "Epoch 41/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0505, acc: 0.6414\n",
      "Epoch 42/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0506, acc: 0.6414\n",
      "Epoch 43/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0506, acc: 0.6385\n",
      "Epoch 44/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0505, acc: 0.6356\n",
      "Epoch 45/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0504, acc: 0.6356\n",
      "Epoch 46/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0503, acc: 0.6385\n",
      "Epoch 47/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0504, acc: 0.6356\n",
      "Epoch 48/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0504, acc: 0.6356\n",
      "Epoch 49/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0505, acc: 0.6356\n",
      "Epoch 50/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0504, acc: 0.6414\n",
      "Epoch 51/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0503, acc: 0.6443\n",
      "Epoch 52/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0504, acc: 0.6268\n",
      "Epoch 53/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0506, acc: 0.6327\n",
      "Epoch 54/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0508, acc: 0.6297\n",
      "Epoch 55/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0510, acc: 0.6297\n",
      "Epoch 56/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0508, acc: 0.6297\n",
      "Epoch 57/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0510, acc: 0.6268\n",
      "Epoch 58/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0506, acc: 0.6268\n",
      "Epoch 59/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0504, acc: 0.6239\n",
      "Epoch 60/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0507, acc: 0.6239\n",
      "Epoch 61/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0506, acc: 0.6181\n",
      "Epoch 62/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0510, acc: 0.6268\n",
      "Epoch 63/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0512, acc: 0.6297\n",
      "Epoch 64/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0504, acc: 0.6239\n",
      "Epoch 65/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0506, acc: 0.6152\n",
      "Epoch 66/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0506, acc: 0.6210\n",
      "Epoch 67/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0513, acc: 0.6181\n",
      "Epoch 68/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0511, acc: 0.6152\n",
      "Epoch 69/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0500, acc: 0.6181\n",
      "Epoch 70/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0498, acc: 0.6093\n",
      "Epoch 71/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0498, acc: 0.6152\n",
      "Epoch 72/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0492, acc: 0.6181\n",
      "Epoch 73/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0498, acc: 0.6122\n",
      "Epoch 74/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0507, acc: 0.6035\n",
      "Epoch 75/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0498, acc: 0.6152\n",
      "Epoch 76/150\n",
      "train loss: 0.0103, acc: 0.7143\n",
      "val loss: 0.0135, acc: 0.4927\n",
      "Epoch 77/150\n",
      "train loss: 0.0108, acc: 0.5575\n",
      "val loss: 0.0118, acc: 0.5627\n",
      "Epoch 78/150\n",
      "train loss: 0.0105, acc: 0.5850\n",
      "val loss: 0.0119, acc: 0.5948\n",
      "Epoch 79/150\n",
      "train loss: 0.0100, acc: 0.6227\n",
      "val loss: 0.0122, acc: 0.5656\n",
      "Epoch 80/150\n",
      "train loss: 0.0097, acc: 0.6516\n",
      "val loss: 0.0123, acc: 0.6268\n",
      "Epoch 81/150\n",
      "train loss: 0.0090, acc: 0.7040\n",
      "val loss: 0.0124, acc: 0.6035\n",
      "Epoch 82/150\n",
      "train loss: 0.0087, acc: 0.7121\n",
      "val loss: 0.0114, acc: 0.6706\n",
      "Epoch 83/150\n",
      "train loss: 0.0084, acc: 0.7253\n",
      "val loss: 0.0111, acc: 0.6414\n",
      "Epoch 84/150\n",
      "train loss: 0.0081, acc: 0.7484\n",
      "val loss: 0.0120, acc: 0.6501\n",
      "Epoch 85/150\n",
      "train loss: 0.0075, acc: 0.7751\n",
      "val loss: 0.0119, acc: 0.6501\n",
      "Epoch 86/150\n",
      "train loss: 0.0070, acc: 0.7960\n",
      "val loss: 0.0139, acc: 0.6035\n",
      "Epoch 87/150\n",
      "train loss: 0.0062, acc: 0.8286\n",
      "val loss: 0.0129, acc: 0.6385\n",
      "Epoch 88/150\n",
      "train loss: 0.0051, acc: 0.8641\n",
      "val loss: 0.0130, acc: 0.6356\n",
      "Epoch 89/150\n",
      "train loss: 0.0045, acc: 0.8864\n",
      "val loss: 0.0140, acc: 0.6268\n",
      "Epoch 90/150\n",
      "train loss: 0.0036, acc: 0.9081\n",
      "val loss: 0.0271, acc: 0.6327\n",
      "Epoch 91/150\n",
      "train loss: 0.0027, acc: 0.9297\n",
      "val loss: 0.0241, acc: 0.6064\n",
      "Epoch 92/150\n",
      "train loss: 0.0019, acc: 0.9480\n",
      "val loss: 0.0317, acc: 0.6356\n",
      "Epoch 93/150\n",
      "train loss: 0.0019, acc: 0.9535\n",
      "val loss: 0.0360, acc: 0.5569\n",
      "Epoch 94/150\n",
      "train loss: 0.0018, acc: 0.9575\n",
      "val loss: 0.0293, acc: 0.6210\n",
      "Epoch 95/150\n",
      "train loss: 0.0005, acc: 0.9905\n",
      "val loss: 0.0404, acc: 0.6443\n",
      "Epoch 96/150\n",
      "train loss: 0.0016, acc: 0.9623\n",
      "val loss: 0.0314, acc: 0.6443\n",
      "Epoch 97/150\n",
      "train loss: 0.0009, acc: 0.9788\n",
      "val loss: 0.0365, acc: 0.6152\n",
      "Epoch 98/150\n",
      "train loss: 0.0006, acc: 0.9821\n",
      "val loss: 0.0400, acc: 0.6327\n",
      "Epoch 99/150\n",
      "train loss: 0.0011, acc: 0.9751\n",
      "val loss: 0.0368, acc: 0.6064\n",
      "Epoch 100/150\n",
      "train loss: 0.0009, acc: 0.9802\n",
      "val loss: 0.0328, acc: 0.6152\n",
      "Epoch 101/150\n",
      "train loss: 0.0006, acc: 0.9890\n",
      "val loss: 0.0416, acc: 0.6414\n",
      "Epoch 102/150\n",
      "train loss: 0.0001, acc: 0.9993\n",
      "val loss: 0.0452, acc: 0.6093\n",
      "Epoch 103/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0472, acc: 0.6239\n",
      "Epoch 104/150\n",
      "train loss: 0.0000, acc: 1.0000\n",
      "val loss: 0.0475, acc: 0.6356\n",
      "Epoch 105/150\n"
     ]
    }
   ],
   "source": [
    "verbose=2\n",
    "\n",
    "for values in itertools.product(*map(params.get, keys)):\n",
    "    d = dict(zip(keys, values))    \n",
    "    description = 'C{}_K{}'.format(d['conv_channels'], d['kernel_size'][0])    \n",
    "    print('\\n\\n##### ' + description + ' #####')\n",
    "\n",
    "    # Define the architecture\n",
    "    model = CNN2D(input_size    = input_size,\n",
    "                  kernel_size   = d['kernel_size'], \n",
    "                  conv_channels = d['conv_channels'],\n",
    "                  dense_size    = 256,\n",
    "                  dropout       = 0.5)               \n",
    "    print(\"Model architecture >>>\", model)\n",
    "\n",
    "    # optimizer and the loss function definition \n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                 lr = learning_rate,\n",
    "                                 weight_decay = weight_decay)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # move the model to GPU/CPU\n",
    "    model.to(dev)  \n",
    "    criterion.to(dev)       \n",
    "\n",
    "    #******** Training loop *********    \n",
    "    best_model, train_losses, val_losses, train_accs, val_accs, info =\\\n",
    "        train_model(model, dat['dset_loaders'], dat['dset_sizes'], \n",
    "                    criterion, optimizer, dev, lr_scheduler = None, \n",
    "                    num_epochs = num_epochs, verbose = verbose)    \n",
    "\n",
    "    test_samples = 100\n",
    "    x_test = dat['test_data']['x_test'][:test_samples,:,:,:] \n",
    "    y_test = dat['test_data']['y_test'][:test_samples] \n",
    "    \n",
    "    # predict test data \n",
    "    preds = best_model(x_test.to(dev)) \n",
    "    preds_class = preds.data.max(1)[1]\n",
    "\n",
    "    # get the accuracy \n",
    "    corrects = torch.sum(preds_class == y_test.data.to(dev))     \n",
    "    test_acc = corrects.cpu().numpy()/x_test.shape[0]\n",
    "    print(\"Test Accuracy :\", test_acc) \n",
    "\n",
    "    # save results       \n",
    "    tab = dict(Train_Acc= train_accs[info['best_epoch']],\n",
    "               Val_Acc  = val_accs[info['best_epoch']],   \n",
    "               Test_Acc = test_acc, Epoch = info['best_epoch'] + 1)         \n",
    "\n",
    "    table.loc[description] = tab  \n",
    "    val_acc = np.max(val_accs)\n",
    "\n",
    "    print(table)\n",
    "    results[description] = dict(train_accs = train_accs, val_accs =  val_accs,                                \n",
    "                                ytrain = info['ytrain'], yval= info['yval'])      \n",
    "    \n",
    "    # save the best model weights\n",
    "    fname = 'm_' + iname + 'CNN_POOLED' + description + '_' + str(val_acc)[:4]\n",
    "    torch.save(best_model.state_dict(), fname) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rTable = dict(table = table)\n",
    "ij = str(np.random.randint(101))\n",
    "filename = iname + \"_CNNPOOLEDRES_\"+description +ij+ 'ConvDown' + str(ConvDOWN)         \n",
    "\n",
    "with open(filename, 'wb') as ffile:\n",
    "    pickle.dump(rTable, ffile)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rTable['table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demo single-file script to train a ConvNet on CIFAR10 using SoftHebb, an unsupervised, efficient and bio-plausible\n",
    "learning algorithm\n",
    "\"\"\"\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.utils import _pair\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class SoftHebbConv2d(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            kernel_size: int,\n",
    "            stride: int = 1,\n",
    "            padding: int = 0,\n",
    "            dilation: int = 1,\n",
    "            groups: int = 1,\n",
    "            t_invert: float = 12,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Simplified implementation of Conv2d learnt with SoftHebb; an unsupervised, efficient and bio-plausible\n",
    "        learning algorithm.\n",
    "        This simplified implementation omits certain configurable aspects, like using a bias, groups>1, etc. which can\n",
    "        be found in the full implementation in hebbconv.py\n",
    "        \"\"\"\n",
    "        super(SoftHebbConv2d, self).__init__()\n",
    "        assert groups == 1, \"Simple implementation does not support groups > 1.\"\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = _pair(kernel_size)\n",
    "        self.stride = _pair(stride)\n",
    "        self.dilation = _pair(dilation)\n",
    "        self.groups = groups\n",
    "        self.padding_mode = 'reflect'\n",
    "        self.F_padding = (padding, padding, padding, padding)\n",
    "        weight_range = 25 / math.sqrt((in_channels / groups) * kernel_size * kernel_size)\n",
    "        self.weight = nn.Parameter(weight_range * torch.randn((out_channels, in_channels // groups, *self.kernel_size)))\n",
    "        self.t_invert = torch.tensor(t_invert)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, self.F_padding, self.padding_mode)  # pad input\n",
    "        # perform conv, obtain weighted input u \\in [B, OC, OH, OW]\n",
    "        weighted_input = F.conv2d(x, self.weight, None, self.stride, 0, self.dilation, self.groups)\n",
    "\n",
    "        if self.training:\n",
    "            # ===== find post-synaptic activations y = sign(u)*softmax(u, dim=C), s(u)=1 - 2*I[u==max(u,dim=C)] =====\n",
    "            # Post-synaptic activation, for plastic update, is weighted input passed through a softmax.\n",
    "            # Non-winning neurons (those not with the highest activation) receive the negated post-synaptic activation.\n",
    "            batch_size, out_channels, height_out, width_out = weighted_input.shape\n",
    "            # Flatten non-competing dimensions (B, OC, OH, OW) -> (OC, B*OH*OW)\n",
    "            flat_weighted_inputs = weighted_input.transpose(0, 1).reshape(out_channels, -1)\n",
    "            # Compute the winner neuron for each batch element and pixel\n",
    "            flat_softwta_activs = torch.softmax(self.t_invert * flat_weighted_inputs, dim=0)\n",
    "            flat_softwta_activs = - flat_softwta_activs  # Turn all postsynaptic activations into anti-Hebbian\n",
    "            win_neurons = torch.argmax(flat_weighted_inputs, dim=0)  # winning neuron for each pixel in each input\n",
    "            competing_idx = torch.arange(flat_weighted_inputs.size(1))  # indeces of all pixel-input elements\n",
    "            # Turn winner neurons' activations back to hebbian\n",
    "            flat_softwta_activs[win_neurons, competing_idx] = - flat_softwta_activs[win_neurons, competing_idx]\n",
    "            softwta_activs = flat_softwta_activs.view(out_channels, batch_size, height_out, width_out).transpose(0, 1)\n",
    "            # ===== compute plastic update Δw = y*(x - u*w) = y*x - (y*u)*w =======================================\n",
    "            # Use Convolutions to apply the plastic update. Sweep over inputs with postynaptic activations.\n",
    "            # Each weighting of an input pixel & an activation pixel updates the kernel element that connected them in\n",
    "            # the forward pass.\n",
    "            yx = F.conv2d(\n",
    "                x.transpose(0, 1),  # (B, IC, IH, IW) -> (IC, B, IH, IW)\n",
    "                softwta_activs.transpose(0, 1),  # (B, OC, OH, OW) -> (OC, B, OH, OW)\n",
    "                padding=0,\n",
    "                stride=self.dilation,\n",
    "                dilation=self.stride,\n",
    "                groups=1\n",
    "            ).transpose(0, 1)  # (IC, OC, KH, KW) -> (OC, IC, KH, KW)\n",
    "\n",
    "            # sum over batch, output pixels: each kernel element will influence all batches and output pixels.\n",
    "            yu = torch.sum(torch.mul(softwta_activs, weighted_input), dim=(0, 2, 3))\n",
    "            delta_weight = yx - yu.view(-1, 1, 1, 1) * self.weight\n",
    "            delta_weight.div_(torch.abs(delta_weight).amax() + 1e-30)  # Scale [min/max , 1]\n",
    "            self.weight.grad = delta_weight  # store in grad to be used with common optimizers\n",
    "\n",
    "        return weighted_input\n",
    "\n",
    "\n",
    "class DeepSoftHebb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepSoftHebb, self).__init__()\n",
    "        # block 1\n",
    "        self.bn1 = nn.BatchNorm2d(3, affine=False)\n",
    "        self.conv1 = SoftHebbConv2d(in_channels=3, out_channels=96, kernel_size=5, padding=2, t_invert=1,)\n",
    "        self.activ1 = Triangle(power=0.7)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=4, stride=2, padding=1)\n",
    "        # block 2\n",
    "        self.bn2 = nn.BatchNorm2d(96, affine=False)\n",
    "        self.conv2 = SoftHebbConv2d(in_channels=96, out_channels=384, kernel_size=3, padding=1, t_invert=0.65,)\n",
    "        self.activ2 = Triangle(power=1.4)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=4, stride=2, padding=1)\n",
    "        # block 3\n",
    "        self.bn3 = nn.BatchNorm2d(384, affine=False)\n",
    "        self.conv3 = SoftHebbConv2d(in_channels=384, out_channels=1536, kernel_size=3, padding=1, t_invert=0.25,)\n",
    "        self.activ3 = Triangle(power=1.)\n",
    "        self.pool3 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # block 4\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classifier = nn.Linear(24576, 10)\n",
    "        self.classifier.weight.data = 0.11048543456039805 * torch.rand(10, 24576)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # block 1\n",
    "        out = self.pool1(self.activ1(self.conv1(self.bn1(x))))\n",
    "        # block 2\n",
    "        out = self.pool2(self.activ2(self.conv2(self.bn2(out))))\n",
    "        # block 3\n",
    "        out = self.pool3(self.activ3(self.conv3(self.bn3(out))))\n",
    "        # block 4\n",
    "        return self.classifier(self.dropout(self.flatten(out)))\n",
    "\n",
    "\n",
    "class Triangle(nn.Module):\n",
    "    def __init__(self, power: float = 1, inplace: bool = True):\n",
    "        super(Triangle, self).__init__()\n",
    "        self.inplace = inplace\n",
    "        self.power = power\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        input = input - torch.mean(input.data, axis=1, keepdims=True)\n",
    "        return F.relu(input, inplace=self.inplace) ** self.power\n",
    "\n",
    "\n",
    "class WeightNormDependentLR(optim.lr_scheduler._LRScheduler):\n",
    "    \"\"\"\n",
    "    Custom Learning Rate Scheduler for unsupervised training of SoftHebb Convolutional blocks.\n",
    "    Difference between current neuron norm and theoretical converged norm (=1) scales the initial lr.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, power_lr, last_epoch=-1, verbose=False):\n",
    "        self.optimizer = optimizer\n",
    "        self.initial_lr_groups = [group['lr'] for group in self.optimizer.param_groups]  # store initial lrs\n",
    "        self.power_lr = power_lr\n",
    "        super().__init__(optimizer, last_epoch, verbose)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if not self._get_lr_called_within_step:\n",
    "            warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
    "                          \"please use `get_last_lr()`.\", UserWarning)\n",
    "        new_lr = []\n",
    "        for i, group in enumerate(self.optimizer.param_groups):\n",
    "            for param in group['params']:\n",
    "                # difference between current neuron norm and theoretical converged norm (=1) scales the initial lr\n",
    "                # initial_lr * |neuron_norm - 1| ** 0.5\n",
    "                norm_diff = torch.abs(torch.linalg.norm(param.view(param.shape[0], -1), dim=1, ord=2) - 1) + 1e-10\n",
    "                new_lr.append(self.initial_lr_groups[i] * (norm_diff ** self.power_lr)[:, None, None, None])\n",
    "        return new_lr\n",
    "\n",
    "\n",
    "class TensorLRSGD(optim.SGD):\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step, using a non-scalar (tensor) learning rate.\n",
    "\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group['weight_decay']\n",
    "            momentum = group['momentum']\n",
    "            dampening = group['dampening']\n",
    "            nesterov = group['nesterov']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad\n",
    "                if weight_decay != 0:\n",
    "                    d_p = d_p.add(p, alpha=weight_decay)\n",
    "                if momentum != 0:\n",
    "                    param_state = self.state[p]\n",
    "                    if 'momentum_buffer' not in param_state:\n",
    "                        buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                    else:\n",
    "                        buf = param_state['momentum_buffer']\n",
    "                        buf.mul_(momentum).add_(d_p, alpha=1 - dampening)\n",
    "                    if nesterov:\n",
    "                        d_p = d_p.add(buf, alpha=momentum)\n",
    "                    else:\n",
    "                        d_p = buf\n",
    "\n",
    "                p.add_(-group['lr'] * d_p)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class CustomStepLR(StepLR):\n",
    "    \"\"\"\n",
    "    Custom Learning Rate schedule with step functions for supervised training of linear readout (classifier)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, nb_epochs):\n",
    "        threshold_ratios = [0.2, 0.35, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "        self.step_thresold = [int(nb_epochs * r) for r in threshold_ratios]\n",
    "        super().__init__(optimizer, -1, False)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch in self.step_thresold:\n",
    "            return [group['lr'] * 0.5\n",
    "                    for group in self.optimizer.param_groups]\n",
    "        return [group['lr'] for group in self.optimizer.param_groups]\n",
    "\n",
    "\n",
    "class FastCIFAR10(torchvision.datasets.CIFAR10):\n",
    "    \"\"\"\n",
    "    Improves performance of training on CIFAR10 by removing the PIL interface and pre-loading on the GPU (2-3x speedup).\n",
    "\n",
    "    Taken from https://github.com/y0ast/pytorch-snippets/tree/main/fast_mnist\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        device = kwargs.pop('device', \"cpu\")\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.data = torch.tensor(self.data, dtype=torch.float, device=device).div_(255)\n",
    "        self.data = torch.movedim(self.data, -1, 1)  # -> set dim to: (batch, channels, height, width)\n",
    "        self.targets = torch.tensor(self.targets, device=device)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        index : int\n",
    "            Index of the element to be returned\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            tuple: (image, target) where target is the index of the target class\n",
    "        \"\"\"\n",
    "        img = self.data[index]\n",
    "        target = self.targets[index]\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "# Main training loop CIFAR10\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda:0')\n",
    "    model = DeepSoftHebb()\n",
    "    model.to(device)\n",
    "\n",
    "    unsup_optimizer = TensorLRSGD([\n",
    "        {\"params\": model.conv1.parameters(), \"lr\": -0.08, },  # SGD does descent, so set lr to negative\n",
    "        {\"params\": model.conv2.parameters(), \"lr\": -0.005, },\n",
    "        {\"params\": model.conv3.parameters(), \"lr\": -0.01, },\n",
    "    ], lr=0)\n",
    "    unsup_lr_scheduler = WeightNormDependentLR(unsup_optimizer, power_lr=0.5)\n",
    "\n",
    "    sup_optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "    sup_lr_scheduler = CustomStepLR(sup_optimizer, nb_epochs=50)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    trainset = FastCIFAR10('./data', train=True, download=True)\n",
    "    unsup_trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True, )\n",
    "    sup_trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, )\n",
    "\n",
    "    testset = FastCIFAR10('./data', train=False)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False)\n",
    "\n",
    "    # Unsupervised training with SoftHebb\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(unsup_trainloader, 0):\n",
    "        inputs, _ = data\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        unsup_optimizer.zero_grad()\n",
    "\n",
    "        # forward + update computation\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        # optimize\n",
    "        unsup_optimizer.step()\n",
    "        unsup_lr_scheduler.step()\n",
    "\n",
    "    # Supervised training of classifier\n",
    "    # set requires grad false and eval mode for all modules but classifier\n",
    "    unsup_optimizer.zero_grad()\n",
    "    model.conv1.requires_grad = False\n",
    "    model.conv2.requires_grad = False\n",
    "    model.conv3.requires_grad = False\n",
    "    model.conv1.eval()\n",
    "    model.conv2.eval()\n",
    "    model.conv3.eval()\n",
    "    model.bn1.eval()\n",
    "    model.bn2.eval()\n",
    "    model.bn3.eval()\n",
    "    for epoch in range(50):\n",
    "        model.classifier.train()\n",
    "        model.dropout.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(sup_trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            sup_optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            sup_optimizer.step()\n",
    "\n",
    "            # compute training statistics\n",
    "            running_loss += loss.item()\n",
    "            if epoch % 10 == 0 or epoch == 49:\n",
    "                total += labels.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        sup_lr_scheduler.step()\n",
    "        # Evaluation on test set\n",
    "        if epoch % 10 == 0 or epoch == 49:\n",
    "            print(f'Accuracy of the network on the train images: {100 * correct // total} %')\n",
    "            print(f'[{epoch + 1}] loss: {running_loss / total:.3f}')\n",
    "\n",
    "            # on the test set\n",
    "            model.eval()\n",
    "            running_loss = 0.\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "            with torch.no_grad():\n",
    "                for data in testloader:\n",
    "                    images, labels = data\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    # calculate outputs by running images through the network\n",
    "                    outputs = model(images)\n",
    "                    # the class with the highest energy is what we choose as prediction\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "            print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')\n",
    "            print(f'test loss: {running_loss / total:.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
